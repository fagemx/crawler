#!/usr/bin/env python3
"""
æœ€çµ‚è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦ - ä½¿ç”¨å·²é©—è­‰æœ‰æ•ˆçš„ headers
"""
import requests
import json
import time
import re
import random
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

class FinalReaderSolution:
    def __init__(self):
        self.base_url = "http://localhost:8880"
        
        # å·²é©—è­‰æœ‰æ•ˆçš„ headers é…ç½®
        self.optimal_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'x-wait-for-selector': 'article',
            'x-timeout': '25'
        }
        
    def normalize_content(self, content):
        """æ¨™æº–åŒ–å…§å®¹è™•ç† NBSP"""
        content = content.replace('\u00a0', ' ')  # NBSP
        content = content.replace('\u2002', ' ')  # En space
        content = content.replace('\u2003', ' ')  # Em space
        content = re.sub(r' +', ' ', content)
        return content
    
    def extract_views(self, content):
        """æå–è§€çœ‹æ•¸ - ä½¿ç”¨å¢å¼·çš„æ­£å‰‡è¡¨é”å¼"""
        content = self.normalize_content(content)
        
        patterns = [
            r'Thread\s*={6}\s*([0-9,\.]+[KMB]?)\s*views?',  # Thread ====== 313K views
            r'Thread\s*={6}\s*([0-9,\.]+[KMB]?)',           # Thread ====== 313K
            r'(\d+(?:\.\d+)?[KMB]?)\s*views?',              # 313K views
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                return match.group(1)
        return None
    
    def extract_content(self, content):
        """æå–ä¸»è¦å…§å®¹"""
        lines = content.split('\n')
        
        # å°‹æ‰¾å…§å®¹é–‹å§‹ä½ç½®
        content_start = -1
        for i, line in enumerate(lines):
            if 'Markdown Content:' in line:
                content_start = i + 1
                break
        
        if content_start == -1:
            return None
        
        # æå–å…§å®¹ç›´åˆ°é‡åˆ°å…¶ä»–çµæ§‹
        content_lines = []
        for i in range(content_start, len(lines)):
            line = lines[i].strip()
            if line and not line.startswith('[![Image') and not line.startswith('[Image'):
                content_lines.append(line)
                if len(content_lines) >= 10:  # å–å‰å¹¾è¡Œä½œç‚ºä¸»è¦å…§å®¹
                    break
        
        return '\n'.join(content_lines) if content_lines else None
    
    def fetch_post_data(self, url, request_id=None):
        """ä½¿ç”¨æœ€ä½³åŒ–é…ç½®ç²å–è²¼æ–‡æ•¸æ“š"""
        try:
            response = requests.get(
                f"{self.base_url}/{url}", 
                headers=self.optimal_headers, 
                timeout=60
            )
            
            if response.status_code != 200:
                return {
                    'success': False,
                    'error': f"HTTP {response.status_code}",
                    'url': url,
                    'request_id': request_id
                }
            
            content = response.text
            
            # æå–è§€çœ‹æ•¸å’Œå…§å®¹
            views = self.extract_views(content)
            main_content = self.extract_content(content)
            
            return {
                'success': True,
                'url': url,
                'request_id': request_id,
                'views': views,
                'content': main_content,
                'content_length': len(content),
                'has_views': views is not None,
                'has_content': main_content is not None,
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'url': url,
                'request_id': request_id
            }
    
    def test_single_url(self, url):
        """æ¸¬è©¦å–®å€‹ URL"""
        print(f"ğŸ” æ¸¬è©¦: {url.split('/')[-1]}")
        
        result = self.fetch_post_data(url, "single-test")
        
        if result['success']:
            print(f"âœ… æˆåŠŸ!")
            print(f"   è§€çœ‹æ•¸: {result['views'] or 'âŒ æœªæ‰¾åˆ°'}")
            print(f"   å…§å®¹: {result['content'][:100] + '...' if result['content'] else 'âŒ æœªæ‰¾åˆ°'}")
            print(f"   å…§å®¹é•·åº¦: {result['content_length']:,} å­—ç¬¦")
        else:
            print(f"âŒ å¤±æ•—: {result['error']}")
        
        return result
    
    def test_parallel_processing(self, urls, max_workers=3):
        """æ¸¬è©¦ä¸¦è¡Œè™•ç†"""
        print(f"\nğŸš€ ä¸¦è¡Œè™•ç†æ¸¬è©¦ (ä½µç™¼æ•¸: {max_workers})")
        print("=" * 60)
        
        results = []
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            futures = []
            for i, url in enumerate(urls):
                future = executor.submit(self.fetch_post_data, url, f"parallel-{i+1}")
                futures.append(future)
            
            # æ”¶é›†çµæœ
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
                
                # é¡¯ç¤ºé€²åº¦
                completed = len(results)
                total = len(urls)
                progress = completed / total * 100
                
                if result['success']:
                    views_status = f"âœ… {result['views']}" if result['views'] else "âŒ ç„¡è§€çœ‹æ•¸"
                    content_status = "âœ…" if result['content'] else "âŒ"
                    print(f"ğŸ“Š {completed}/{total} ({progress:.1f}%) | {result['request_id']} | {views_status} | å…§å®¹: {content_status}")
                else:
                    print(f"ğŸ“Š {completed}/{total} ({progress:.1f}%) | {result['request_id']} | âŒ {result['error']}")
        
        end_time = time.time()
        
        # çµ±è¨ˆçµæœ
        successful = [r for r in results if r['success']]
        with_views = [r for r in successful if r['has_views']]
        with_content = [r for r in successful if r['has_content']]
        
        total_count = len(results)
        success_count = len(successful)
        views_count = len(with_views)
        content_count = len(with_content)
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¸¦è¡Œè™•ç†çµæœç¸½çµ")
        print("=" * 60)
        print(f"â±ï¸ ç¸½è€—æ™‚: {end_time - start_time:.1f} ç§’")
        print(f"ğŸï¸ å¹³å‡é€Ÿåº¦: {total_count / (end_time - start_time):.2f} URL/ç§’")
        print(f"âœ… è«‹æ±‚æˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
        print(f"ğŸ‘€ è§€çœ‹æ•¸æå–ç‡: {views_count}/{total_count} ({views_count/total_count*100:.1f}%)")
        print(f"ğŸ“„ å…§å®¹æå–ç‡: {content_count}/{total_count} ({content_count/total_count*100:.1f}%)")
        
        # é¡¯ç¤ºæˆåŠŸæ¡ˆä¾‹
        if with_views:
            print(f"\nğŸ¯ æˆåŠŸæå–è§€çœ‹æ•¸çš„è²¼æ–‡:")
            for r in with_views:
                post_id = r['url'].split('/')[-1]
                print(f"   â€¢ {post_id}: {r['views']}")
        
        # é¡¯ç¤ºå¤±æ•—åŸå› 
        failed = [r for r in results if not r['success']]
        if failed:
            print(f"\nâŒ å¤±æ•—åŸå› çµ±è¨ˆ:")
            errors = {}
            for r in failed:
                error = r['error']
                errors[error] = errors.get(error, 0) + 1
            
            for error, count in errors.items():
                print(f"   â€¢ {error}: {count} æ¬¡")
        
        # ä¿å­˜çµæœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"final_solution_test_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump({
                'test_name': 'æœ€çµ‚è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦',
                'timestamp': datetime.now().isoformat(),
                'headers_used': self.optimal_headers,
                'max_workers': max_workers,
                'total_time': end_time - start_time,
                'success_rate': success_count/total_count*100,
                'views_extraction_rate': views_count/total_count*100,
                'results': results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜: {filename}")
        
        return views_count/total_count >= 0.8  # å¦‚æœè§€çœ‹æ•¸æå–ç‡ >= 80% å°±ç®—æˆåŠŸ

def main():
    # æ¸¬è©¦ URL åˆ—è¡¨
    test_urls = [
        'https://www.threads.com/@ttshow.tw/post/DMfOVeqSkM5',  # å·²é©—è­‰æœ‰è§€çœ‹æ•¸
        'https://www.threads.com/@ttshow.tw/post/DIfkbgLSjO3',
        'https://www.threads.com/@ttshow.tw/post/DL_vyT-RZQ6',
    ]
    
    solution = FinalReaderSolution()
    
    print("ğŸ¯ æœ€çµ‚è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦")
    print("=" * 80)
    print("ä½¿ç”¨å·²é©—è­‰çš„æœ€ä½³ headers é…ç½®:")
    print(json.dumps(solution.optimal_headers, indent=2, ensure_ascii=False))
    print("=" * 80)
    
    # 1. å…ˆæ¸¬è©¦å–®å€‹ URL
    print("\nğŸ” å–®å€‹ URL æ¸¬è©¦")
    print("-" * 40)
    single_result = solution.test_single_url(test_urls[0])
    
    if single_result['success'] and single_result['has_views']:
        print("\nâœ… å–®å€‹æ¸¬è©¦æˆåŠŸï¼é–‹å§‹ä¸¦è¡Œæ¸¬è©¦...")
        
        # 2. æ¸¬è©¦ä¸¦è¡Œè™•ç†
        success = solution.test_parallel_processing(test_urls, max_workers=3)
        
        if success:
            print("\nğŸ‰ æœ€çµ‚è§£æ±ºæ–¹æ¡ˆæ¸¬è©¦æˆåŠŸï¼")
            print("ğŸ’¡ å»ºè­°å°‡é€™äº› headers æ•´åˆåˆ°æ‚¨çš„ä¸»ç¨‹å¼ä¸­:")
            print("```python")
            print("headers = {")
            for key, value in solution.optimal_headers.items():
                print(f"    '{key}': '{value}',")
            print("}")
            print("```")
        else:
            print("\nâš ï¸ ä¸¦è¡Œæ¸¬è©¦ä»éœ€èª¿æ•´ï¼Œå»ºè­°é™ä½ä½µç™¼æ•¸æˆ–å¢åŠ å»¶é²")
    else:
        print("\nâŒ å–®å€‹æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Reader æœå‹™ç‹€æ…‹")

if __name__ == '__main__':
    main()