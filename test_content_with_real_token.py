"""
ä½¿ç”¨çœŸå¯¦çš„ LSD token æ¸¬è©¦å…§å®¹æŸ¥è©¢
"""

import asyncio
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Optional

import sys
sys.path.append(str(Path(__file__).parent))

# ç›´æ¥å¾æˆåŠŸçš„å¯¦ä¾‹ä¸­å¾©åˆ¶å¿…è¦éƒ¨åˆ†
from test_full_post_strategy import ThreadsFullPostFetcher

async def test_content_queries_with_real_token():
    """ä½¿ç”¨çœŸå¯¦ LSD token æ¸¬è©¦å…§å®¹æŸ¥è©¢"""
    print("ğŸš€ ä½¿ç”¨çœŸå¯¦ LSD token æ¸¬è©¦å…§å®¹æŸ¥è©¢...")
    
    # è®€å–èªè­‰
    from common.config import get_auth_file_path
    auth_file_path = get_auth_file_path()
    
    # å‰µå»º fetcher å¯¦ä¾‹
    fetcher = ThreadsFullPostFetcher(auth_file_path)
    
    try:
        # æ­¥é©Ÿ1: ç²å–çœŸå¯¦çš„ LSD token (å¾ GraphQL éŸ¿æ‡‰ä¸­)
        print("   ğŸ”‘ ç²å–çœŸå¯¦ LSD token...")
        test_url = "https://www.threads.com/@star_shining0828/post/DMyvZJRz5Cz"
        pk, captured_pks = await fetcher.extract_pk_from_gate_page(test_url)
        
        if not fetcher.lsd_token:
            print("   âŒ ç„¡æ³•ç²å– LSD token")
            return
        
        print(f"   âœ… æˆåŠŸç²å– LSD token: {fetcher.lsd_token[:10]}...")
        
        # æ­¥é©Ÿ2: æ¸¬è©¦å„ç¨®å…§å®¹æŸ¥è©¢ doc_id
        print("\nğŸ§ª ä½¿ç”¨çœŸå¯¦ token æ¸¬è©¦å…§å®¹æŸ¥è©¢...")
        
        # æ“´å±•çš„ doc_id æ¸¬è©¦åˆ—è¡¨
        test_doc_ids = [
            "7428920450586442",  # SingleThreadQuery
            "7248604598467997",  # BarcelonaPostPageContentQuery  
            "7439738349112860",  # ProfileThreadsTabQuery
            "6981243555252543",  # BarcelonaPostPageFeedMediaQuery
            "7127871700615871",  # BarcelonaPostPageDirectQuery
            "7268729639845570",  # ThreadQuery
            "7395825420492230",  # MediaQuery
            "7396485793756116",  # BarcelonaPostPageRefetchableDirectQuery
            "25924527474041776", # è¼ƒæ–°çš„æŸ¥è©¢ID
            "8523948474355533",  # å¦ä¸€å€‹å¯èƒ½çš„ID
            # æ·»åŠ ä¸€äº›å¯èƒ½çš„æ–° ID
            "8234567890123456",
            "7567890123456789",
            "6789012345678901",
        ]
        
        test_pk = pk  # ä½¿ç”¨çœŸå¯¦çš„ PK
        valid_doc_ids = []
        
        for doc_id in test_doc_ids:
            print(f"\n   ğŸ§ª æ¸¬è©¦ doc_id: {doc_id}")
            
            # æ¸¬è©¦æ–°æ ¼å¼è®Šæ•¸
            try:
                variables = json.dumps({
                    "postID_pk": test_pk,
                    "withShallowTree": False,
                    "includePromotedPosts": False
                })
                
                data = f"lsd={fetcher.lsd_token}&doc_id={doc_id}&variables={variables}"
                headers = {"x-fb-lsd": fetcher.lsd_token}
                
                response = await fetcher.http_client.post(
                    "https://www.threads.com/graphql/query",
                    data=data,
                    headers=headers
                )
                
                print(f"      æ–°æ ¼å¼: HTTP {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        result = response.json()
                        print(f"      ğŸ“‹ éŸ¿æ‡‰éµ: {list(result.keys())}")
                        
                        # å¦‚æœæœ‰éŒ¯èª¤ï¼Œé¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
                        if "errors" in result:
                            errors = result["errors"]
                            print(f"      âŒ éŒ¯èª¤è¨Šæ¯: {errors[:1]}")  # åªé¡¯ç¤ºç¬¬ä¸€å€‹éŒ¯èª¤
                        
                        if "data" in result and result["data"]:
                            data_keys = list(result["data"].keys())
                            print(f"      ğŸ“‹ data éµ: {data_keys}")
                            
                            # æª¢æŸ¥å„ç¨®å¯èƒ½çš„å…§å®¹çµæ§‹
                            content_found = False
                            
                            if "media" in result["data"]:
                                media = result["data"]["media"]
                                if media:
                                    print(f"      âœ… æ‰¾åˆ° media å…§å®¹!")
                                    print(f"         åª’é«”é¡å‹: {media.get('__typename')}")
                                    if "caption" in media:
                                        caption_text = media.get("caption", {}).get("text", "")
                                        print(f"         å…§å®¹é•·åº¦: {len(caption_text)}")
                                        print(f"         å…§å®¹é è¦½: {caption_text[:100]}...")
                                    content_found = True
                            
                            elif "containing_thread" in result["data"]:
                                thread = result["data"]["containing_thread"]
                                if thread and "thread_items" in thread:
                                    print(f"      âœ… æ‰¾åˆ° thread_items å…§å®¹!")
                                    content_found = True
                            
                            elif "post" in result["data"]:
                                post = result["data"]["post"]
                                if post:
                                    print(f"      âœ… æ‰¾åˆ° post å…§å®¹!")
                                    content_found = True
                            
                            if content_found:
                                valid_doc_ids.append((doc_id, "new_format", result))
                                print(f"      ğŸ‰ æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ (æ–°æ ¼å¼): {doc_id}")
                                
                                # ä¿å­˜éŸ¿æ‡‰ç”¨æ–¼åˆ†æ
                                debug_file = Path(f"valid_content_response_{doc_id}_{datetime.now().strftime('%H%M%S')}.json")
                                with open(debug_file, 'w', encoding='utf-8') as f:
                                    json.dump(result, f, indent=2, ensure_ascii=False)
                                print(f"      ğŸ“ å·²ä¿å­˜éŸ¿æ‡‰åˆ°: {debug_file}")
                            else:
                                print(f"      âš ï¸ æœ‰éŸ¿æ‡‰ä½†ç„¡è­˜åˆ¥çš„å…§å®¹çµæ§‹")
                        else:
                            print(f"      âŒ ç©º data æˆ–éŒ¯èª¤éŸ¿æ‡‰")
                    except Exception as e:
                        print(f"      âŒ è§£æéŸ¿æ‡‰å¤±æ•—: {e}")
                        
                elif response.status_code == 400:
                    print(f"      âŒ 400 éŒ¯èª¤ - å¯èƒ½æ˜¯éŒ¯èª¤çš„è®Šæ•¸æ ¼å¼")
                elif response.status_code == 401:
                    print(f"      âŒ 401 éŒ¯èª¤ - èªè­‰å•é¡Œ")
                elif response.status_code == 500:
                    print(f"      âŒ 500 éŒ¯èª¤ - ä¼ºæœå™¨éŒ¯èª¤")
                else:
                    print(f"      âŒ å…¶ä»–éŒ¯èª¤: {response.status_code}")
                    
            except Exception as e:
                print(f"      âŒ æ–°æ ¼å¼æ¸¬è©¦å¤±æ•—: {e}")
                
            # å¦‚æœæ–°æ ¼å¼å¤±æ•—ï¼Œæ¸¬è©¦èˆŠæ ¼å¼
            if doc_id in ["7428920450586442", "7248604598467997", "7439738349112860"]:
                try:
                    variables = json.dumps({
                        "postID": test_pk,
                        "includePromotedPosts": False
                    })
                    
                    data = f"lsd={fetcher.lsd_token}&doc_id={doc_id}&variables={variables}"
                    headers = {"x-fb-lsd": fetcher.lsd_token}
                    
                    response = await fetcher.http_client.post(
                        "https://www.threads.com/graphql/query",
                        data=data,
                        headers=headers
                    )
                    
                    print(f"      èˆŠæ ¼å¼: HTTP {response.status_code}")
                    
                    if response.status_code == 200:
                        try:
                            result = response.json()
                            if ("data" in result and result["data"] and 
                                any(key in result["data"] for key in ["media", "containing_thread", "post"])):
                                valid_doc_ids.append((doc_id, "old_format", result))
                                print(f"      ğŸ‰ æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ (èˆŠæ ¼å¼): {doc_id}")
                        except:
                            pass
                            
                except Exception as e:
                    print(f"      âŒ èˆŠæ ¼å¼æ¸¬è©¦å¤±æ•—: {e}")
        
        # å ±å‘Šçµæœ
        print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
        if valid_doc_ids:
            print(f"   âœ… æ‰¾åˆ° {len(valid_doc_ids)} å€‹æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢:")
            for doc_id, format_type, _ in valid_doc_ids:
                print(f"      ğŸ¯ {doc_id} ({format_type})")
            
            # ä½¿ç”¨ç¬¬ä¸€å€‹æœ‰æ•ˆçš„ doc_id é€²è¡Œå®Œæ•´æ¸¬è©¦
            best_doc_id, best_format, best_response = valid_doc_ids[0]
            print(f"\nğŸ§ª ä½¿ç”¨æœ€ä½³ doc_id {best_doc_id} é€²è¡Œå®Œæ•´æ¸¬è©¦...")
            
            # åˆ†æéŸ¿æ‡‰çµæ§‹
            if "data" in best_response and "media" in best_response["data"]:
                media = best_response["data"]["media"]
                print(f"   ğŸ“ åª’é«”å…§å®¹åˆ†æ:")
                print(f"      é¡å‹: {media.get('__typename')}")
                print(f"      ID: {media.get('id')}")
                
                if "caption" in media:
                    caption = media["caption"]
                    if caption:
                        text = caption.get("text", "")
                        print(f"      æ–‡å­—å…§å®¹: {len(text)} å­—ç¬¦")
                        print(f"      å…§å®¹é è¦½: {text[:200]}...")
                
                if "image_versions2" in media:
                    images = media["image_versions2"]
                    if images and "candidates" in images:
                        candidates = images["candidates"]
                        print(f"      åœ–ç‰‡: {len(candidates)} å€‹ç‰ˆæœ¬")
                        for i, candidate in enumerate(candidates[:3]):
                            print(f"         åœ–ç‰‡ {i+1}: {candidate.get('width')}x{candidate.get('height')} - {candidate.get('url', '')[:50]}...")
                
                if "video_versions" in media:
                    videos = media["video_versions"]
                    print(f"      å½±ç‰‡: {len(videos)} å€‹ç‰ˆæœ¬")
                    
            return best_doc_id
            
        else:
            print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢")
            return None
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None
    
    finally:
        await fetcher.close()

async def main():
    """ä¸»å‡½æ•¸"""
    doc_id = await test_content_queries_with_real_token()
    if doc_id:
        print(f"\nğŸ‰ æ‰¾åˆ°æœ€ä½³å…§å®¹æŸ¥è©¢ doc_id: {doc_id}")
        print(f"ğŸ’¡ è«‹å°‡æ­¤ doc_id æ›´æ–°åˆ° test_full_post_strategy.py ä¸­")
    else:
        print(f"\nğŸ˜ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ doc_id")

if __name__ == "__main__":
    asyncio.run(main())