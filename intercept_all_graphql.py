"""
æ””æˆªæ‰€æœ‰ GraphQL è«‹æ±‚ï¼Œå°‹æ‰¾å…§å®¹ç›¸é—œçš„æŸ¥è©¢
"""

import asyncio
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List

import sys
sys.path.append(str(Path(__file__).parent))

from playwright.async_api import async_playwright
from common.config import get_auth_file_path

# ä½¿ç”¨ä¸€å€‹æ›´ç©©å®šçš„æ¸¬è©¦ç›®æ¨™ï¼ˆä¾‹å¦‚ Threads å®˜æ–¹å¸³è™Ÿï¼‰
TEST_URL = "https://www.threads.net/@threads/post/DMxtXaggxsL"

async def intercept_all_graphql_requests():
    """æ””æˆªæ‰€æœ‰ GraphQL è«‹æ±‚"""
    print("ğŸ” æ””æˆªæ‰€æœ‰ GraphQL è«‹æ±‚...")
    
    auth_file_path = get_auth_file_path()
    
    all_requests = []
    all_responses = []
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=False,  # è¨­ç‚º False ä¾¿æ–¼è§€å¯Ÿ
            args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-blink-features=AutomationControlled"]
        )
        
        context = await browser.new_context(
            storage_state=str(auth_file_path),
            user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1",
            viewport={"width": 375, "height": 812},
            locale="zh-TW",
            bypass_csp=True
        )
        
        await context.add_init_script(
            "Object.defineProperty(navigator,'webdriver',{get:()=>undefined})"
        )
        
        page = await context.new_page()
        
        # æ””æˆªæ‰€æœ‰è«‹æ±‚
        async def request_handler(request):
            url = request.url.lower()
            if "/graphql" in url:
                qname = request.headers.get("x-fb-friendly-name", "Unknown")
                all_requests.append({
                    "url": request.url,
                    "method": request.method,
                    "query_name": qname,
                    "headers": dict(request.headers),
                    "post_data": request.post_data if request.method == "POST" else None,
                    "timestamp": datetime.now().isoformat()
                })
                print(f"   ğŸ“¤ ç™¼é€: {qname}")
        
        # æ””æˆªæ‰€æœ‰éŸ¿æ‡‰
        async def response_handler(response):
            url = response.url.lower()
            if "/graphql" in url and response.status == 200:
                qname = response.request.headers.get("x-fb-friendly-name", "Unknown")
                try:
                    data = await response.json()
                    all_responses.append({
                        "url": response.url,
                        "query_name": qname,
                        "data": data,
                        "timestamp": datetime.now().isoformat(),
                        "request_headers": dict(response.request.headers)
                    })
                    
                    # å¿«é€Ÿåˆ†æéŸ¿æ‡‰å…§å®¹
                    content_indicators = []
                    
                    if "data" in data and data["data"]:
                        data_obj = data["data"]
                        
                        # æª¢æŸ¥æ˜¯å¦åŒ…å«åª’é«”å…§å®¹
                        if "media" in data_obj:
                            content_indicators.append("has_media")
                        if "containing_thread" in data_obj:
                            content_indicators.append("has_thread")
                        if any("text" in str(data_obj).lower() and len(str(data_obj)) > 1000 for _ in [1]):
                            content_indicators.append("has_long_text")
                        if "caption" in str(data_obj):
                            content_indicators.append("has_caption")
                        if "image_versions" in str(data_obj):
                            content_indicators.append("has_images")
                        if "video_versions" in str(data_obj):
                            content_indicators.append("has_videos")
                    
                    indicator_text = ", ".join(content_indicators) if content_indicators else "no_content"
                    print(f"   ğŸ“¥ éŸ¿æ‡‰: {qname} ({indicator_text})")
                    
                    # å¦‚æœçœ‹èµ·ä¾†åƒå…§å®¹éŸ¿æ‡‰ï¼Œä¿å­˜è©³ç´°ä¿¡æ¯
                    if any(indicator in content_indicators for indicator in ["has_media", "has_caption", "has_images", "has_videos"]):
                        print(f"      ğŸ¯ å¯èƒ½çš„å…§å®¹éŸ¿æ‡‰ï¼")
                        debug_file = Path(f"potential_content_{qname}_{datetime.now().strftime('%H%M%S')}.json")
                        with open(debug_file, 'w', encoding='utf-8') as f:
                            json.dump({
                                "query_name": qname,
                                "request_post_data": response.request.post_data,
                                "response_data": data
                            }, f, indent=2, ensure_ascii=False)
                        print(f"      ğŸ“ å·²ä¿å­˜åˆ°: {debug_file}")
                    
                except Exception as e:
                    print(f"   âŒ è§£æéŸ¿æ‡‰å¤±æ•—: {e}")
        
        page.on("request", request_handler)
        page.on("response", response_handler)
        
        # å°èˆªåˆ°é é¢
        print(f"   ğŸŒ å°èˆªåˆ°: {TEST_URL}")
        await page.goto(TEST_URL, wait_until="networkidle", timeout=60000)
        
        # ç­‰å¾…åˆå§‹åŠ è¼‰
        await asyncio.sleep(5)
        
        # å˜—è©¦ä¸€äº›ç”¨æˆ¶æ“ä½œä¾†è§¸ç™¼æ›´å¤šè«‹æ±‚
        print(f"   ğŸ–±ï¸ å˜—è©¦ç”¨æˆ¶æ“ä½œ...")
        
        # æ»¾å‹•
        for i in range(3):
            await page.evaluate("window.scrollTo(0, window.scrollY + 300)")
            await asyncio.sleep(1)
        
        # å˜—è©¦é»æ“Šä¸€äº›å…ƒç´ ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            # å˜—è©¦é»æ“Šè²¼æ–‡å±•é–‹
            more_button = page.locator('text="æ›´å¤š"').first
            if await more_button.count() > 0:
                await more_button.click()
                await asyncio.sleep(2)
        except:
            pass
        
        try:
            # å˜—è©¦é»æ“Šç•™è¨€å€åŸŸ
            comments_area = page.locator('[aria-label*="ç•™è¨€"], [aria-label*="comment"]').first
            if await comments_area.count() > 0:
                await comments_area.hover()
                await asyncio.sleep(2)
        except:
            pass
        
        # æœ€å¾Œç­‰å¾…
        await asyncio.sleep(3)
        
        await browser.close()
    
    # åˆ†æçµæœ
    print(f"\nğŸ“Š åˆ†æçµæœ:")
    print(f"   ğŸ“¤ ç¸½è«‹æ±‚æ•¸: {len(all_requests)}")
    print(f"   ğŸ“¥ ç¸½éŸ¿æ‡‰æ•¸: {len(all_responses)}")
    
    # æŒ‰æŸ¥è©¢åç¨±åˆ†çµ„
    query_names = {}
    for req in all_requests:
        qname = req["query_name"]
        if qname not in query_names:
            query_names[qname] = {"requests": 0, "responses": 0}
        query_names[qname]["requests"] += 1
    
    for resp in all_responses:
        qname = resp["query_name"]
        if qname in query_names:
            query_names[qname]["responses"] += 1
    
    print(f"\nğŸ“‹ æŸ¥è©¢çµ±è¨ˆ:")
    for qname, stats in sorted(query_names.items()):
        print(f"   {qname}: {stats['requests']} è«‹æ±‚, {stats['responses']} éŸ¿æ‡‰")
    
    # å˜—è©¦å¾è«‹æ±‚ä¸­æå– doc_id
    print(f"\nğŸ” æå–çš„ doc_id:")
    doc_ids = set()
    for req in all_requests:
        if req["post_data"]:
            try:
                # å˜—è©¦å¾ POST æ•¸æ“šä¸­æå– doc_id
                post_data = req["post_data"]
                if "doc_id=" in post_data:
                    match = re.search(r'doc_id=(\d+)', post_data)
                    if match:
                        doc_id = match.group(1)
                        doc_ids.add((doc_id, req["query_name"]))
            except:
                pass
    
    for doc_id, qname in sorted(doc_ids):
        print(f"   {doc_id} ({qname})")
    
    # ä¿å­˜å®Œæ•´çµæœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = Path(f"all_graphql_intercept_{timestamp}.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "test_url": TEST_URL,
            "requests": all_requests,
            "responses": all_responses,
            "query_statistics": query_names,
            "extracted_doc_ids": list(doc_ids)
        }, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ“ å®Œæ•´çµæœå·²ä¿å­˜è‡³: {output_file}")
    
    return list(doc_ids)

async def main():
    """ä¸»å‡½æ•¸"""
    doc_ids = await intercept_all_graphql_requests()
    
    if doc_ids:
        print(f"\nğŸ¯ ç™¼ç¾çš„ doc_id:")
        for doc_id, qname in doc_ids:
            print(f"   {doc_id} - {qname}")
        print(f"\nğŸ’¡ è«‹å˜—è©¦ä½¿ç”¨é€™äº› doc_id ä¾†ç²å–å…§å®¹")
    else:
        print(f"\nğŸ˜ æœªç™¼ç¾æ–°çš„ doc_id")

if __name__ == "__main__":
    asyncio.run(main())