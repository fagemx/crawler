"""
å°‹æ‰¾æ­£ç¢ºçš„å…§å®¹æŸ¥è©¢ doc_id
å¾é é¢çš„ JS æ–‡ä»¶ä¸­æå–
"""

import asyncio
import re
import httpx
from pathlib import Path
from datetime import datetime
from typing import Optional, List

# å°å…¥èªè­‰
import sys
sys.path.append(str(Path(__file__).parent))
from common.config import get_auth_file_path
import json

async def find_content_doc_id():
    """å¾å¤šå€‹ä¾†æºå°‹æ‰¾å…§å®¹æŸ¥è©¢çš„ doc_id"""
    
    # è®€å–èªè­‰
    auth_file_path = get_auth_file_path()
    auth_data = json.loads(auth_file_path.read_text())
    cookies = {c["name"]: c["value"] for c in auth_data["cookies"]}
    
    headers = {
        "user-agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1",
        "accept": "*/*",
    }
    
    async with httpx.AsyncClient(cookies=cookies, headers=headers, timeout=30.0) as client:
        print("ğŸ” å°‹æ‰¾å…§å®¹æŸ¥è©¢ doc_id...")
        
        # ç­–ç•¥1: åˆ†æé é¢ä¸­çš„ JS æ–‡ä»¶
        print("\nğŸ“„ ç­–ç•¥1: åˆ†æä¸»é é¢ä¸­çš„ JS æ–‡ä»¶...")
        try:
            response = await client.get("https://www.threads.com/")
            if response.status_code == 200:
                html = response.text
                
                # å°‹æ‰¾ JS æ–‡ä»¶å¼•ç”¨
                js_files = re.findall(r'src="([^"]*\.js[^"]*)"', html)
                print(f"   æ‰¾åˆ° {len(js_files)} å€‹ JS æ–‡ä»¶")
                
                for i, js_url in enumerate(js_files[:5]):  # åªæª¢æŸ¥å‰5å€‹
                    if js_url.startswith('/'):
                        js_url = "https://www.threads.com" + js_url
                    
                    print(f"   ğŸ” æª¢æŸ¥ JS æ–‡ä»¶ {i+1}: {js_url}")
                    try:
                        js_response = await client.get(js_url)
                        if js_response.status_code == 200:
                            js_content = js_response.text
                            
                            # æœå°‹ doc_id æ¨¡å¼
                            patterns = [
                                r'"([A-Za-z0-9]*PostPage[^"]*)":\s*\{\s*id:\s*"(\d{15,19})"',
                                r'"([A-Za-z0-9]*Thread[^"]*)":\s*\{\s*id:\s*"(\d{15,19})"',
                                r'"([A-Za-z0-9]*Media[^"]*)":\s*\{\s*id:\s*"(\d{15,19})"',
                                r'(\w+):\s*\{\s*id:\s*"(\d{15,19})"[^}]*media[^}]*\}',
                            ]
                            
                            for pattern in patterns:
                                matches = re.findall(pattern, js_content)
                                if matches:
                                    print(f"      âœ… æ‰¾åˆ°æŸ¥è©¢: {matches[:3]}")  # åªé¡¯ç¤ºå‰3å€‹
                    except:
                        continue
                        
        except Exception as e:
            print(f"   âŒ ç­–ç•¥1å¤±æ•—: {e}")
        
        # ç­–ç•¥2: å˜—è©¦å·²çŸ¥çš„å‚™ç”¨ doc_id åˆ—è¡¨
        print("\nğŸ¯ ç­–ç•¥2: æ¸¬è©¦å·²çŸ¥çš„å‚™ç”¨ doc_id...")
        
        # æ“´å±•çš„ doc_id åˆ—è¡¨ï¼ˆå¾ç¶²è·¯ä¸Šæ”¶é›†çš„ï¼‰
        known_doc_ids = [
            "7428920450586442",  # SingleThreadQuery
            "7248604598467997",  # BarcelonaPostPageContentQuery  
            "7439738349112860",  # ProfileThreadsTabQuery
            "6981243555252543",  # BarcelonaPostPageFeedMediaQuery
            "7127871700615871",  # BarcelonaPostPageDirectQuery
            "7268729639845570",  # ThreadQuery
            "7395825420492230",  # MediaQuery
            "7396485793756116",  # BarcelonaPostPageRefetchableDirectQuery
            "25924527474041776", # è¼ƒæ–°çš„æŸ¥è©¢ID
            "8523948474355533",  # å¦ä¸€å€‹å¯èƒ½çš„ID
        ]
        
        test_pk = "3689219480905289907"  # æˆ‘å€‘å·²çŸ¥çš„æœ‰æ•ˆ PK
        
        for doc_id in known_doc_ids:
            print(f"   ğŸ§ª æ¸¬è©¦ doc_id: {doc_id}")
            try:
                # æ¸¬è©¦æ–°æ ¼å¼
                variables = json.dumps({
                    "postID_pk": test_pk,
                    "withShallowTree": False,
                    "includePromotedPosts": False
                })
                
                # æˆ‘å€‘éœ€è¦ä¸€å€‹å‡çš„ LSD token ä¾†æ¸¬è©¦
                fake_lsd = "test123"
                data = f"lsd={fake_lsd}&doc_id={doc_id}&variables={variables}"
                
                test_response = await client.post(
                    "https://www.threads.com/graphql/query",
                    data=data,
                    headers={"x-fb-lsd": fake_lsd}
                )
                
                print(f"      HTTP {test_response.status_code}")
                
                # åˆ†æéŸ¿æ‡‰
                if test_response.status_code == 200:
                    try:
                        result = test_response.json()
                        if "data" in result and result["data"]:
                            if "media" in result["data"]:
                                print(f"      âœ… æ‰¾åˆ°æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢: {doc_id}")
                                print(f"         éŸ¿æ‡‰åŒ…å« media æ•¸æ“š")
                                return doc_id
                            else:
                                print(f"      âš ï¸ æœ‰éŸ¿æ‡‰ä½†ç„¡ media: {list(result.get('data', {}).keys())}")
                        else:
                            print(f"      âŒ ç©ºéŸ¿æ‡‰æˆ–éŒ¯èª¤")
                    except:
                        print(f"      âŒ ç„¡æ³•è§£æ JSON éŸ¿æ‡‰")
                elif test_response.status_code == 400:
                    print(f"      âŒ 400 éŒ¯èª¤ (å¯èƒ½æ˜¯éŒ¯èª¤çš„ variables æ ¼å¼)")
                elif test_response.status_code == 401:
                    print(f"      âŒ 401 éŒ¯èª¤ (èªè­‰å•é¡Œ)")
                else:
                    print(f"      âŒ å…¶ä»–éŒ¯èª¤")
                    
            except Exception as e:
                print(f"      âŒ æ¸¬è©¦å¤±æ•—: {e}")
        
        # ç­–ç•¥3: å˜—è©¦èˆŠæ ¼å¼è®Šæ•¸
        print("\nğŸ”„ ç­–ç•¥3: å˜—è©¦èˆŠæ ¼å¼è®Šæ•¸...")
        
        for doc_id in known_doc_ids[:3]:  # åªæ¸¬è©¦å‰3å€‹
            print(f"   ğŸ§ª æ¸¬è©¦èˆŠæ ¼å¼ doc_id: {doc_id}")
            try:
                # æ¸¬è©¦èˆŠæ ¼å¼
                variables = json.dumps({
                    "postID": test_pk,
                    "includePromotedPosts": False
                })
                
                fake_lsd = "test123"
                data = f"lsd={fake_lsd}&doc_id={doc_id}&variables={variables}"
                
                test_response = await client.post(
                    "https://www.threads.com/graphql/query",
                    data=data,
                    headers={"x-fb-lsd": fake_lsd}
                )
                
                print(f"      HTTP {test_response.status_code}")
                
                if test_response.status_code == 200:
                    try:
                        result = test_response.json()
                        if "data" in result and result["data"] and "media" in result["data"]:
                            print(f"      âœ… èˆŠæ ¼å¼æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢: {doc_id}")
                            return doc_id
                    except:
                        pass
                        
            except Exception as e:
                print(f"      âŒ æ¸¬è©¦å¤±æ•—: {e}")
        
        print("\nâŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ doc_id")
        return None

async def main():
    """ä¸»å‡½æ•¸"""
    doc_id = await find_content_doc_id()
    if doc_id:
        print(f"\nğŸ‰ æ‰¾åˆ°æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ doc_id: {doc_id}")
    else:
        print(f"\nğŸ˜ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å…§å®¹æŸ¥è©¢ doc_id")

if __name__ == "__main__":
    asyncio.run(main())