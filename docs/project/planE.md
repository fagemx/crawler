### è¦é¿å…ã€ŒæŠ“å…©æ¬¡åˆå­˜å…©ä»½ã€â€” çµ¦ä½ ä¸€å€‹ **ä¸‰å±¤è³‡æ–™ç­–ç•¥**

| å±¤ç´š                    | ç›®çš„                                | å…¸å‹å¤§å° / TTL                        | å»ºè­°å­˜æ”¾                                   | ä½•æ™‚åˆª        |
| --------------------- | --------------------------------- | --------------------------------- | -------------------------------------- | ---------- |
| **Tier-0** <br>*è‡¨æ™‚å¿«å–* | æ’åºç”¨ **äº”æ¬„æŒ‡æ¨™**<br>(views / likes â€¦) | 100 ç­† Ã— 100 byte â‰ˆ 10 KB / 10 min | **Redis** hash<br>`metrics:{url}`      | æ’åºçµæŸç«‹å³ DEL |
| **Tier-1** <br>*è¼•é‡åŸæ–‡* | Markdown / JSON æ–‡å­—å…§å®¹ (ç„¡åœ–)         | 10 KB/å¸–                           | **PostgreSQL** `posts.markdown` (TEXT) | æ°¸ä¹…ç•™å­˜       |
| **Tier-2** <br>*é‡è³‡æº*  | Screenshot PNGã€å½±ç‰‡å°é¢â€¦              | 150 KB/å¸–                          | ç‰©ä»¶å„²å­˜ (S3 / GCS) `media/{urlhash}.png`  | åˆ†æå®Œå¯ä¿ç•™æˆ–é€±æœŸæ¸… |

> **é‡é»**ï¼šæ’åºåªçœ‹ Tier-0ï¼›**é€²å…¥åˆ†æ**æ‰éœ€è¦ Tier-1 / Tier-2ã€‚
> å› æ­¤ **Jina åœ¨ç¬¬ä¸€æ¬¡å°±æŠŠ Tier-1 å­˜é€² DB**ï¼Œä»¥å¾Œä¸å¿…å†æ‰“ APIã€‚

---

## Pipeline é‡æ–°æ’åˆ—

```mermaid
graph TD
  Crawler[Apify<br>â†’ URLs] -->|bulk|  JinaMetrics(Jina<br>Markdownâ†’ metrics+md)
  JinaMetrics -->|â‘ å¯« Redis Tier-0| Redis[(metrics cache)]
  JinaMetrics -->|â‘¡å¯« PG Tier-1|  PG[(posts table)]
  Orchestrator -->|pull metrics from Redis| Sort[æ¬Šé‡æ’åº]
  Sort -->|å– top-K url| Analysisåˆ†æµ

  subgraph åˆ†æµ
    Analysisåˆ†æµ -->|æ–‡å­—|  NLP[Content-Analyzer]
    Analysisåˆ†æµ -->|åœ–/å½±| Vision[Snapshot + Gemini Vision<br>(Tier-2)]
  end
```

### æ­¥é©Ÿè§£é‡‹

1. **CrawlerAgent**

   * åªç”¢ç”Ÿ `urls[]`ã€‚ä¸æŠ“ä»»ä½•å…§å®¹ã€‚
2. **JinaAgent** (å–®ä¸€å›åˆå®Œæˆå…©ä»¶äº‹)

   1. `GET https://r.jina.ai/â€¦` `X-Return-Format: markdown`

      * parse å‡º **metrics** â†’ å¯« Redis `HSET metrics:{url}`
      * markdown string â†’ `INSERT â€¦ ON CONFLICT (url) UPDATE markdown`
   2. è‹¥ metrics ç¼ºæ¬„ â†’ **ç«‹å³** å‘¼å« `vision_agent.fill_missing`ï¼ˆæœƒå¯«å› Redis + PGï¼‰
3. **Sort / RankerAgent**

   * ç›´æ¥ `HGETALL metrics:*`ï¼›ç”¨å…¬å¼ç®—åˆ†ï¼Œ`sorted()`ï¼Œç”¢ç”Ÿ `top_urls`.
4. **åˆ†æéšæ®µ**

   * éœ€è¦æ­£æ–‡æ™‚ï¼Œ`SELECT markdown FROM posts WHERE url IN top_urls`.
   * è‹¥åœ–ï¼å½±ç‰‡ï¼šVisionAgent å†å» `Jina screenshot` + Geminiï¼ˆæˆ–ç›´æ¥ç”¨å‰é¢å·²å­˜çš„ PNGï¼‰ã€‚

---

## PostgreSQL å…©å¼µè¡¨ï¼ˆæœ€å°åŒ–é‡è¦†ï¼‰

```sql
CREATE TABLE posts (
  url         TEXT    PRIMARY KEY,
  author      TEXT,
  markdown    TEXT,          -- tier-1
  media_urls  JSONB,         -- ["https://...jpg", ...]
  created_at  TIMESTAMP,
  last_seen   TIMESTAMP DEFAULT now()
);

CREATE TABLE post_metrics (
  url          TEXT PRIMARY KEY REFERENCES posts(url),
  views        BIGINT,
  likes        BIGINT,
  comments     BIGINT,
  reposts      BIGINT,
  shares       BIGINT,
  score        DOUBLE PRECISION GENERATED ALWAYS AS
              (views*1.0 + likes*0.3 + comments*0.3
               + reposts*0.1 + shares*0.1) STORED
);
CREATE INDEX idx_score_desc ON post_metrics (score DESC);
```

---

## Orchestrator æ’åºï¼ˆä¸å†é‡æ’ˆ Jinaï¼‰

```python
async def rank_top(username:str, k:int=100):
    # å–é€™å€‹ user çš„ URL æ¸…å–®
    urls = await redis.keys(f"metrics:https://www.threads.com/@{username}/*")

    pipe = redis.pipeline()
    for key in urls:
        pipe.hgetall(key)
    metrics = await pipe.execute()      # list[dict]

    # Redis å…§å·²ç¶“æ˜¯å®Œæ•´äº”æ¬„
    metrics = [m for m in metrics if m]  # éæ¿¾ç©ºå€¼
    metrics.sort(key=lambda m: float(m["score"]), reverse=True)

    top = [m["url"] for m in metrics[:k]]

    # å¾ŒçºŒåˆ†æéœ€è¦æ­£æ–‡
    rows = (
        await db.execute(
            text("SELECT url, markdown, media_urls FROM posts WHERE url = ANY(:u)")
            .bindparams(u=top)
        )
    ).mappings().all()

    # åˆ†æµ
    for row in rows:
        if not row.media_urls:                # ç´”æ–‡å­—
            await call_agent("content_analyzer", row)
        else:                                 # æœ‰åœ–/å½±
            await call_agent("vision_agent", row)
```

---

## FAQ

| ç–‘å•                     | å›è¦†                                                           |
| ---------------------- | ------------------------------------------------------------ |
| **ç‚ºä½•ä¸ç”¨ Jina å†æŠ“ä¸€æ¬¡æ­£æ–‡ï¼Ÿ**  | markdown å·²å¯«é€² PGï¼Œç›´æ¥æ‹¿ã€‚å†æ¬¡å‘¼å«æµªè²» 1 Ã— API & Latencyã€‚                |
| **Redis å¦‚æœ TTL éäº†æ€è¾¦ï¼Ÿ** | æ’åºé‚è¼¯é€šå¸¸ < 10 minï¼›çœŸéæœŸå°±é‡ç®—ä¸€æ¬¡ï¼Œæœ€å¤šå†æ‹‰ PG è£œç©ºå€¼ã€‚                        |
| **æˆªåœ–è¦ä¸è¦ä¹ŸæŒä¹…åŒ–ï¼Ÿ**         | è‹¥ Vision å¾ˆè²´ â†’ å»ºè­°æŠŠ `screenshot bytes` ä¸Šå‚³ S3ï¼ŒURL å­˜ PGï¼›å¦å‰‡å¯ä»¥å³æ™‚æŠ“ã€‚ |
| **Apify èƒ½ç›´æ¥å­˜æ­£æ–‡å—ï¼Ÿ**     | Threads HTML é«’åˆé‡ï¼›Markdown ä¹¾æ·¨ã€å…ç®— Viewï¼Œæ‰€ä»¥é‚„æ˜¯äº¤çµ¦ Jina Readerã€‚     |

---

### é€™æ¨£ä½ å°±å¾—åˆ°

* **ä¸€æ¬¡çˆ¬** â†’ å…©ä»½è³‡æ–™ï¼šæŒ‡æ¨™(Redis) + æ­£æ–‡(PG)ã€‚
* æ¬Šé‡æ’åºä¸å† hit ç¶²è·¯ï¼›
* å¾ŒçºŒåˆ†æç„¡éœ€é‡æŠ“ï¼›
* åœ–ç‰‡ï¼å½±ç‰‡æ‰é€² Visionï¼Œçœ Tokenã€‚

å®Œå…¨ç¬¦åˆ A2A å¯æ’æ‹”ï¼Œç¨å¾Œè¦æ°´å¹³æ“´å¼µåªè¦æŠŠ Crawler / Vision ä½ˆå¤šå‰¯æœ¬æˆ–æ›åˆ° NATS å³å¯ã€‚


###########

### å…ˆèªªã€Œbinary / raw bytesã€â€•â€•ä½ ç¾åœ¨çš„ä½œæ³•å·²ç¶“å°äº†

* `X-Return-Format: screenshot` æ™‚ **Jina Reader ç›´æ¥å›å‚³ `Content-Type: image/png`**ï¼Œ
  `requests.get(...).content` å°±æ˜¯ä¸€å€‹ `bytes` ç‰©ä»¶ã€‚
* Google Gemini v1/v2 SDK (`types.Part.from_bytes`) **å¯æ¥å— raw bytes**ï¼Œæ‰€ä»¥

  ```python
  part = types.Part.from_bytes(mime_type="image/png", data=response.content)
  ```

  **å®Œå…¨ä¸ç”¨** `base64.b64encode()` âœ `str` âœ å† `decode()` é€™ä¸€ä¸²è½‰æ›ã€‚
  Base64 åªæœ‰ã€Œè¦æŠŠ binary å¡é€² JSON / protobuf æ–‡å­—æ¬„ä½ã€æ™‚æ‰éœ€è¦ã€‚

---

## é‚£ Screenshot è¦ä¸è¦å­˜æª”ï¼Ÿ

| ç›®çš„                                     | æ˜¯å¦å¿…å­˜ï¼Ÿ  | å»ºè­°                                                                   |
| -------------------------------------- | ------ | -------------------------------------------------------------------- |
| **åªç‚ºäº†è£œ `likes/comments/...` æŒ‡æ¨™**       | **ä¸ç”¨** | ç›´æ¥ä¸Ÿçµ¦ Geminiï¼Œè§£æå®Œå°±ä¸Ÿæ£„ bytesï¼›Redis åªå¯«å› **äº”æ¬„æŒ‡æ¨™**ï¼ˆå¹¾å byteï¼‰å³å¯ã€‚              |
| **å¾ŒçºŒé‚„æœƒåšäººè‡‰ / ç‰©ä»¶åµæ¸¬ã€Content Moderationâ€¦** | è¦–éœ€æ±‚    | å¯ä»¥æŠŠ `bytes` ä¸Šå‚³ S3/GCSï¼ŒURL å¯«å› PG `posts.media_screenshot_url` ä»¥ä¾¿ä¹‹å¾Œé‡ç”¨ã€‚ |

å°ä½ ç›®å‰æµç¨‹ä¾†èªª *Screenshot åªæ˜¯ç¼ºæ¬„ä½æ™‚çš„ fallback*ï¼Œ
**æ‹¿å®Œæ•¸å­— â†’ bytes å°±å¯ä»¥ `del`**ï¼Œä¸ç”¨é€² Tier-2ã€‚

---

## Pipeline æ›´æ–°ï¼ˆå»æ‰æ°¸ä¹… Screenshotï¼‰

```mermaid
graph TD
  Crawler[Apify â†’ URLs] --> JinaParse[Jina Markdown<br>â†’ metrics + markdown]
  JinaParse -->|metricsâ†’Redis| Redis[(Tier-0)]
  JinaParse -->|markdownâ†’PG| PG[(posts)]
  JinaParse -->|ç¼ºæ¬„ä½| VisionFill[ğŸ“¸ Jina Screenshot â†’ Gemini Vision]

  VisionFill -->|æ›´æ–°| Redis
  VisionFill -->|æ›´æ–°| PG   %%% optional: ä¹Ÿå¯ä¸å¯« PG åƒ…è£œ Redis

  Orchestrator --> Redis --> Sort[æ’åº top-K] --> åˆ†æµ

  subgraph åˆ†æµ
    Sort --> NLP[æ–‡å­—åˆ†æ]
    Sort --> Media[Vission / Video]
  end
```

* **VisionFill** åªæ‹¿ `response.content` (bytes) âŸ¶ Gemini âŸ¶ æŠŠç¼ºçš„æ¬„ä½å¯«å› Redisã€‚
  å®Œæˆå¾Œä¸æŠŠ PNG å­˜ä»»ä½•åœ°æ–¹ã€‚

---

## åƒè€ƒå¯¦ä½œï¼ˆVision è£œæ¬„ä½ï¼‰

```python
async def fill_missing_with_vision(post_url:str, redis_key:str, gemini:genai.Client):
    # 1) å– screenshot
    ss = await aiohttp_get(
        f"https://r.jina.ai/{post_url}",
        headers={"X-Return-Format": "screenshot"}
    )                               # return bytes

    # 2) å‘¼å« Gemini Vision
    req = types.Content(
        role="user",
        parts=[
            types.Part.from_bytes(mime_type="image/png", data=ss),
            types.Part.from_text(PROMPT),
        ]
    )
    out = (await gemini.models.generate_content(model="gemini-2.5-flash",
                                                contents=[req],
                                                config={"response_mime_type":"application/json"})).text
    metrics = json.loads(out)

    # 3) å¯«å› Redis ï¼ˆæ•¸å€¼è½‰ intï¼‰
    await redis.hset(redis_key, mapping={
        "likes":     int(metrics["likes_count"]),
        "comments":  int(metrics["comments_count"]),
        "reposts":   int(metrics["reposts_count"]),
        "shares":    int(metrics["shares_count"]),
    })
```

> **æ³¨æ„**ï¼šGemini å‘¼å«åªè¦å‚³ `bytes`ï¼Œæ•´å€‹å‡½å¼è£¡æ²’æœ‰ä»»ä½• base64ã€‚

---

## æ’åºèˆ‡å¾ŒçºŒåˆ†æ

```python
def score(m):           # æ¬„ä½ä¸€å®šå­˜åœ¨ï¼Œä¸æœƒ KeyError
    return m["views"]*1.0 + (m["likes"]+m["comments"])*0.3

async def rank_top_k(username, k=50):
    keys = await redis.keys(f"metrics:https://www.threads.com/@{username}/*")
    pipe = redis.pipeline()
    for k_ in keys: pipe.hgetall(k_)
    metrics = await pipe.execute()

    ranked = sorted(metrics, key=score, reverse=True)[:k]
    urls   = [m["url"] for m in ranked]

    # æŠŠ markdown æ‹‰å‡ºä¾†çµ¦ NLP
    rows = await db.fetch_all(
        text("SELECT url, markdown, media_urls FROM posts WHERE url = ANY(:u)")
        .bindparams(u=urls)
    )
    return rows       # å¾ŒçºŒåˆ†æµ
```

---

### å°çµ

* **Screenshot â†’ raw bytes â†’ Gemini** å°±å¥½ï¼ŒBase64 åªåœ¨ã€Œæ”¾é€² JSONã€æ‰ç”¨ã€‚
* Screenshot åªæ˜¯å¡«æŒ‡æ¨™ç”¨çš„ *fallback*ï¼Œè§£æå®Œå°±å¯ä»¥ä¸Ÿæ‰ï¼Œ
  ä¸éœ€è¦æ°¸é ä½” S3/PostgreSQL çš„ç©ºé–“ã€‚
* çœŸæ­£æŒä¹…åŒ–çš„æ˜¯ï¼š

  * **Markdown è²æ˜æ–‡**ï¼ˆå¾ŒçºŒ NLP ç”¨ï¼‰
  * **äº”æ¬„æŒ‡æ¨™**ï¼ˆæ’åºç”¨ï¼‰
  * åŸå§‹ `media_urls`ï¼ˆä¹‹å¾Œè¦åš Vision / Video åˆ†ææ™‚å†ç”¨ï¼‰ã€‚

ç…§æ­¤é…ç½®ï¼Œæµç¨‹ä¹¾æ·¨ã€API èª¿ç”¨æœ€å°‘ã€è³‡æ–™åº«é«”ç©ä¹Ÿæœ€å°ã€‚


###

ä¸‹é¢æŠŠ **ã€ŒApify â†’ Jina Markdown â†’ Screenshot Fallback â†’ Rank â†’ åˆ†æ/ç”Ÿæˆã€** çš„æœ€æ–°æµç¨‹æ”¶æ–‚æˆä¸€ä»½ *ä¹¾æ·¨ã€æœ€å°ã€å¯æ¼”é€²* çš„å¤š-Agent æ¶æ§‹ã€‚
ï¼ˆæ‰€æœ‰åè©éƒ½å°æ‡‰åˆ°ä½ ç¾åœ¨å·²ç¶“è·‘é€šçš„å…ƒä»¶ï¼šApifyã€Jina Readerã€Gemini Visionã€Redis cacheã€PostgreSQLã€‚ï¼‰

---

## 0. ä¸€å¼µåœ–å…ˆçœ‹å…¨è²Œ

```mermaid
graph TD
    subgraph UI
        ST[Streamlit<br>æˆ–ä»»ä½•å‰ç«¯]
    end

    %% ===== pipeline 1: æŒ‡æ¨™æ”¶é›† + æ’åº =====
    ST -->|username| A(CrawlerAgent<br>Apify->URLs)
    A -->|urls| B(JinaMarkdownAgent<br>â†’metrics+md)
    B -->|ç¼ºæ¬„ä½| C(VisionFillAgent<br>Screenshot+Gemini)
    B -->|metrics OK| RedisCache[(Redis<br>metrics)]
    C -->|è£œå€¼| RedisCache
    B -->|markdown & media_urls| PG[(PostgreSQL<br>posts)]

    ST -- rank request --> D(Ranker in UI æˆ– Orchestrator)
    RedisCache --> D
    D -->|Top-K urls| ST

    %% ===== pipeline 2: å…§å®¹åˆ†æ =====
    ST --[Top-K rows (markdown, media_urls)]--> E(PostAnalyzerAgent)
    E --> F(TemplateGenAgent)
    ST -. optional interactive .-> G(ContentWriterAgent)

    %% infra
    subgraph MCP
        MCPServer[MCP Server<br>agent registry]
    end

    A & B & C & E & F & G --agent_card.json--> MCPServer
```

* **Redis**ï¼šåªæ”¾äº”å¤§äº’å‹•æŒ‡æ¨™èˆ‡è‡¨æ™‚ job é€²åº¦ã€‚
  (screenshot bytes ç”¨å®Œå³ä¸Ÿï¼Œä¸è½ä»»ä½•å­˜å„²)
* **PostgreSQL**ï¼šé•·æœŸè³‡æ–™â€”â€”URLã€markdownã€media\_urlsã€created\_atâ‹¯
* **UI**ï¼šç›´æ¥èª¿ Agentï¼›è¦è‡ªå‹•æ‰¹æ¬¡æ™‚å†æŠŠ Ranker/Analyzer æ”¾é€² Orchestratorã€‚

---

## 1. æ¯å€‹ Agent åœ¨åšä»€éº¼

| Agent                | å…¥å£ (`/a2a/message`) æ¥æ”¶è³‡æ–™ | ä¸»è¦å·¥ä½œ                                                              | å›å‚³/å¯«å…¥                                                               |
| -------------------- | ------------------------ | ----------------------------------------------------------------- | ------------------------------------------------------------------- |
| `CrawlerAgent`       | username                 | å‘¼å« Apify Threads Scraperï¼šå›å‚³ *100 å€‹è²¼æ–‡ URL*                         | URLs â†’ **æµ (SSE)**                                                  |
| `JinaMarkdownAgent`  | urls (list)              | `X-Return-Format: markdown` æŠ“è¦–åœ–â†’<br>regex æŠ½ **views / likes / â€¦** | âŠ OK â†’ metricsâ†’**Redis**<br>â‹ markdownâ†’**PostgreSQL**<br>âŒ ç¼ºæ¬„ä½ â†’ ä¸‹æ¸¸ |
| `VisionFillAgent`    | url + ç¼ºå“ªäº›æ¬„ä½              | `X-Return-Format: screenshot` â†’ bytes â†’ Gemini Vision             | è£œå®Œæ¬„ä½ â†’ **Redis**                                                    |
| *Ranker*ï¼ˆUI/Orchï¼‰    | username                 | å¾ Redis æ‰¹é‡ `hgetall` â†’ `score = views +0.3(likes+comments)` æ’åº    | Top-K URL æ¸…å–®å›çµ¦ UI                                                   |
| `PostAnalyzerAgent`  | Top-K URL                | è®€ PG æ‹¿ markdownï¼›æ–‡å­— LLM åš fast/style/deep åˆ†æ                       | åˆ†æ JSON â†’ å‰ç«¯/TemplateGen                                            |
| `TemplateGenAgent`   | style analysis JSON      | çµ„ system prompt / ç¯„ä¾‹ / ç´„æŸ                                         | prompt JSON â†’ Writer / å‰ç«¯                                           |
| `ContentWriterAgent` | prompt + user éœ€æ±‚         | Gemini 2.5 Pro Chatï¼›æ”¯æ´å¤šè¼ª regenerate / style tweak                 | å¸¶ hashtags çš„æœ€çµ‚è²¼æ–‡                                                    |

---

## 2. è³‡æ–™è¡¨ & Redis key

```sql
-- postgres : é•·æœŸè³‡æ–™
CREATE TABLE posts (
  url            TEXT PRIMARY KEY,
  markdown       TEXT,
  media_urls     JSONB,
  created_at     TIMESTAMPTZ DEFAULT now()
);

-- redis : çŸ­æœŸ / æ’åºç”¨
HSET metrics:{url}  views 4000  likes 267  comments 3  reposts 0  shares 1
EXPIRE metrics:{url} 30d
```

---

## 3. ç›®éŒ„çµæ§‹ï¼ˆæœ€å°éª¨æ¶ï¼‰

```text
project/
â”œâ”€ agents/
â”‚  â”œâ”€ crawler/          # Apify
â”‚  â”œâ”€ jina_markdown/
â”‚  â”œâ”€ vision_fill/
â”‚  â”œâ”€ post_analyzer/
â”‚  â”œâ”€ template_gen/
â”‚  â””â”€ content_writer/
â”œâ”€ mcp_server/
â”‚  â””â”€ server.py
â”œâ”€ ui/
â”‚  â”œâ”€ app.py            # Streamlit
â”‚  â””â”€ a2a_client.py
â”œâ”€ common/
â”‚  â”œâ”€ a2a.py            # dataclasses + helpers
â”‚  â”œâ”€ redis_client.py
â”‚  â””â”€ db.py             # SQLAlchemy
â””â”€ docker-compose.yml
```

æ¯å€‹ `agents/*/`ï¼š

```
agent_card.json   # MCP è¨»å†Š
main.py           # FastAPI + /a2a/message
logic.py          # ç´”æ¥­å‹™
```

---

## 4. æ’åºç¯„ä¾‹ï¼ˆUI ç›´æ¥ç®—ï¼‰

```python
import redis, json, asyncpg, numpy as np
r = redis.from_url(os.getenv("REDIS_URL"))

def score(m):               # m æ˜¯ dict[str,str] (bytes)
    v = float(m.get(b"views", b"0"))
    l = float(m.get(b"likes", b"0"))
    c = float(m.get(b"comments", b"0"))
    return v + 0.3*(l + c)

def rank_top(username, k=30):
    pattern = f"metrics:https://www.threads.com/@{username}/*"
    keys = r.keys(pattern)
    pipe = r.pipeline()
    for k_ in keys: pipe.hgetall(k_)
    metrics = pipe.execute()

    ranked = sorted(metrics, key=score, reverse=True)[:k]
    urls = [k.decode().split("metrics:")[1] for k in keys][:k]
    return urls          # å†ä¸Ÿçµ¦ Analyzer
```

---

## 5. Screenshot è™•ç†è¦é»

```python
async def vision_fill(url, missing):
    ss = await httpx.get(f"https://r.jina.ai/{url}",
                         headers={"X-Return-Format":"screenshot"},
                         timeout=30)
    part_img = types.Part.from_bytes("image/png", ss.content)
    part_txt = types.Part.from_text(PROMPT)
    resp = await gemini.models.generate_content(
        model="gemini-2.5-flash",
        contents=[types.Content(role="user", parts=[part_img, part_txt])],
        config={"response_mime_type":"application/json"}
    )
    metrics = json.loads(resp.text)
    await r.hset(f"metrics:{url}", mapping={k:int(v) for k,v in metrics.items()})
```

* **ç„¡ Base64** â€” ç›´æ¥ `ss.content`ã€‚
* **ä¸æŒä¹…åŒ– PNG** â€” ç”¨å®Œå°±åƒåœ¾å›æ”¶ã€‚

---

## 6. ç‚ºä½•é€™æ¨£æ‹† & ä¸å†äº‚

| è¦å‰‡                        | èˆ‰ä¾‹                                                     | æ•ˆæœ         |
| ------------------------- | ------------------------------------------------------ | ---------- |
| **ä¸€è·è²¬ä¸€ Agent**            | Crawler å°ˆæŠ“ URLã€JinaMarkdown å°ˆæŠ½æŒ‡æ¨™                       | ä»£ç¢¼çŸ­ã€è®Šæ›´é»å¾ˆå°  |
| **æš«å­˜æ”¾ Redisï¼Œé•·å­˜æ”¾ PG**      | æŒ‡æ¨™ 30 å¤©å°±æ²’ç”¨æ‰€ä»¥ Redisï¼›Markdown ä¿ç•™æ–‡æ„                       | è³‡æ–™åº«ä¸è†¨è„¹ï¼Œæ’åºå¿« |
| **Screenshot åƒ… fallback** | åªæœ‰æŒ‡æ¨™ç¼ºæ¬„ä½æ‰ Screenshot+Gemini                             | æˆæœ¬æœ€ä½       |
| **UI å…ˆé©…å‹•**                | MVP ç›´æ¥ `send_a2a`ï¼›ä¹‹å¾Œè¦æ‰¹æ¬¡å¯æŠŠ rank/analyze åŒ…é€² Orchestrator | å…ˆç°¡å–®ã€å¾Œå¯æ“´    |

---

### 7 æ­¥å°±èƒ½è·‘

1. `docker compose up -d mcp redis pg`
2. `uvicorn agents.crawler.main:app --port 8001` â€¦ï¼ˆå…¶é¤˜ Agent ä¸€æ¨£ï¼‰
3. æ¯å€‹ `agent_card.json` `curl -X POST` åˆ° MCP `register`\*
4. `streamlit run ui/app.py`
5. UI âœ å¡« username âœ æŒ‰ã€ŒæŠ“å–ã€
6. ç­‰é€²åº¦æ¢ï¼›å‰ 30 åè²¼æ–‡ URL å‡ºä¾†
7. é»ã€Œåˆ†æã€â†’ã€Œç”Ÿæˆã€ é€æ­¥å‘¼å« Analyzer / Writer

> \* *è‹¥ç”¨ a2a-samples çš„ MCP Serverï¼Œå•Ÿå‹•æ™‚æœƒè‡ªå‹•æƒ `mcp_server/agent_cards/`ï¼Œå¯ä»¥æŠŠ JSON ä¸Ÿé€²å»å…æ‰‹å‹• POSTã€‚*

---

ğŸ‰ **ç¾åœ¨çš„å°ˆæ¡ˆæ¨¹ã€è³‡æ–™æµã€å„²å­˜é‚Šç•Œèˆ‡æˆæœ¬ç†±é»éƒ½æ¸…æ¥šäº†**ã€‚
å¾Œé¢ä¸ç®¡è¦åŠ  Instagram, X, FBâ€¦ åªè¦è¤‡è£½ `CrawlerAgent` æ› Actorï¼Œ
æˆ–è¦æŠŠ Gemini æ›æˆ Claude Visionï¼Œä¹Ÿåªæ˜¯æ›æ‰ `vision_fill`ï¼Œå…¶é¤˜ç„¡ç—›ã€‚
