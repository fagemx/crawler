"""
èª¿è©¦ Playwright Crawler çš„åŸå§‹æŠ“å–æ•¸æ“š
æŸ¥çœ‹ GraphQL å›æ‡‰çµæ§‹ï¼Œæ‰¾å‡º shares_count ç‚º null çš„åŸå› 
"""
import sys
import json
from pathlib import Path
sys.path.append('.')

from agents.playwright_crawler.playwright_logic import first_of, FIELD_MAP

def debug_crawl_data():
    """åˆ†ææœ€æ–°çš„çˆ¬èŸ²æ•¸æ“š"""
    debug_dir = Path("agents/playwright_crawler/debug")
    
    # æ‰¾åˆ°æœ€æ–°çš„çˆ¬èŸ²æ•¸æ“šæª”æ¡ˆ
    crawl_files = list(debug_dir.glob("crawl_data_*.json"))
    if not crawl_files:
        print("âŒ æ‰¾ä¸åˆ°çˆ¬èŸ²æ•¸æ“šæª”æ¡ˆ")
        return
    
    latest_file = max(crawl_files, key=lambda f: f.stat().st_mtime)
    print(f"ğŸ“ è®€å–æª”æ¡ˆ: {latest_file}")
    
    with open(latest_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"ğŸ“Š ç¸½å…± {data['total_found']} å€‹è²¼æ–‡ï¼Œåˆ†æå‰ 3 å€‹...")
    
    # åˆ†æå‰å¹¾å€‹è²¼æ–‡çš„ shares_count å•é¡Œ
    for i, post in enumerate(data['posts'][:3]):
        print(f"\n--- è²¼æ–‡ {i+1}: {post['url']} ---")
        print(f"çµæœ: likes={post['likes_count']}, comments={post['comments_count']}, reposts={post['reposts_count']}, shares={post['shares_count']}")
        
        # å¦‚æœ shares_count æ˜¯ nullï¼Œæˆ‘å€‘éœ€è¦çœ‹åŸå§‹æ•¸æ“š
        if post['shares_count'] is None:
            print("âš ï¸  shares_count æ˜¯ nullï¼Œéœ€è¦æª¢æŸ¥åŸå§‹ GraphQL æ•¸æ“š")

def debug_raw_graphql():
    """æª¢æŸ¥åŸå§‹çš„ GraphQL æ””æˆªæ•¸æ“š"""
    debug_dir = Path("agents/playwright_crawler/debug")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ sample_thread_item.json
    sample_file = debug_dir / "sample_thread_item.json"
    if sample_file.exists():
        print(f"ğŸ“ åˆ†æç¯„ä¾‹ GraphQL æ•¸æ“š: {sample_file}")
        
        with open(sample_file, 'r', encoding='utf-8') as f:
            thread_item = json.load(f)
        
        print(f"ğŸ“Š GraphQL å›æ‡‰çµæ§‹åˆ†æ:")
        analyze_post_structure(thread_item, "thread_item")
    else:
        print("âŒ æ‰¾ä¸åˆ° sample_thread_item.json")

def analyze_post_structure(data, path="", max_depth=3, current_depth=0):
    """éæ­¸åˆ†æ JSON çµæ§‹ï¼Œå°‹æ‰¾å¯èƒ½çš„ shares/repost ç›¸é—œæ¬„ä½"""
    if current_depth > max_depth:
        return
    
    if isinstance(data, dict):
        for key, value in data.items():
            current_path = f"{path}.{key}" if path else key
            
            # å°‹æ‰¾èˆ‡ shares/repost ç›¸é—œçš„æ¬„ä½
            if any(keyword in key.lower() for keyword in ['share', 'repost', 'forward']):
                print(f"ğŸ” æ‰¾åˆ°ç›¸é—œæ¬„ä½: {current_path} = {value}")
            
            # å°‹æ‰¾æ•¸å­—æ¬„ä½ï¼ˆå¯èƒ½æ˜¯è¨ˆæ•¸ï¼‰
            if isinstance(value, (int, float)) and value > 0:
                if any(keyword in key.lower() for keyword in ['count', 'num', 'total']):
                    print(f"ğŸ”¢ æ•¸å­—æ¬„ä½: {current_path} = {value}")
            
            # ç¹¼çºŒéæ­¸
            if isinstance(value, (dict, list)) and current_depth < max_depth:
                analyze_post_structure(value, current_path, max_depth, current_depth + 1)
    
    elif isinstance(data, list) and len(data) > 0:
        # åªåˆ†æåˆ—è¡¨çš„ç¬¬ä¸€å€‹å…ƒç´ 
        analyze_post_structure(data[0], f"{path}[0]", max_depth, current_depth)

def test_field_map():
    """æ¸¬è©¦ FIELD_MAP ä¸­çš„ share_count è·¯å¾‘"""
    debug_dir = Path("agents/playwright_crawler/debug")
    sample_file = debug_dir / "sample_thread_item.json"
    
    if not sample_file.exists():
        print("âŒ æ‰¾ä¸åˆ° sample_thread_item.json")
        return
    
    with open(sample_file, 'r', encoding='utf-8') as f:
        thread_item = json.load(f)
    
    print(f"ğŸ§ª æ¸¬è©¦ FIELD_MAP ä¸­çš„ share_count è·¯å¾‘:")
    
    # æ¨¡æ“¬ parse_post_data ä¸­çš„é‚è¼¯
    post = find_post_dict(thread_item)
    if not post:
        print("âŒ æ‰¾ä¸åˆ° post å­—å…¸")
        return
    
    share_count_paths = FIELD_MAP["share_count"]
    print(f"ğŸ“‹ share_count è·¯å¾‘: {share_count_paths}")
    
    for path in share_count_paths:
        try:
            result = first_of(post, path)
            print(f"  âœ… è·¯å¾‘ {path}: {result}")
        except Exception as e:
            print(f"  âŒ è·¯å¾‘ {path}: éŒ¯èª¤ - {e}")
    
    # æœ€çµ‚çµæœ
    final_share_count = first_of(post, *share_count_paths) or 0
    print(f"ğŸ¯ æœ€çµ‚ share_count: {final_share_count}")
    
    # åŒæ¨£æ¸¬è©¦ repost_count
    if "repost_count" in FIELD_MAP:
        repost_count_paths = FIELD_MAP["repost_count"]
        print(f"ğŸ“‹ repost_count è·¯å¾‘: {repost_count_paths}")
        final_repost_count = first_of(post, *repost_count_paths) or 0
        print(f"ğŸ¯ æœ€çµ‚ repost_count: {final_repost_count}")

def find_post_dict(data):
    """å¾ GraphQL å›æ‡‰ä¸­æ‰¾åˆ° post å­—å…¸"""
    # é€™è£¡éœ€è¦å¯¦ç¾èˆ‡ playwright_logic.py ä¸­ç›¸åŒçš„é‚è¼¯
    if isinstance(data, dict):
        # æª¢æŸ¥æ˜¯å¦æ˜¯ post ç‰©ä»¶
        if 'pk' in data or 'id' in data:
            return data
        
        # éæ­¸æœå°‹
        for value in data.values():
            result = find_post_dict(value)
            if result:
                return result
    
    elif isinstance(data, list):
        for item in data:
            result = find_post_dict(item)
            if result:
                return result
    
    return None

if __name__ == "__main__":
    print("ğŸ” èª¿è©¦ Playwright Crawler çš„ shares_count å•é¡Œ")
    print("=" * 60)
    
    # 1. æª¢æŸ¥è™•ç†å¾Œçš„çˆ¬èŸ²æ•¸æ“š
    debug_crawl_data()
    
    print("\n" + "=" * 60)
    
    # 2. åˆ†æåŸå§‹ GraphQL çµæ§‹
    debug_raw_graphql()
    
    print("\n" + "=" * 60)
    
    # 3. æ¸¬è©¦ FIELD_MAP è·¯å¾‘
    test_field_map() 