"""
ç¨ç«‹æ¸¬è©¦ GraphQL æŠ“å–å–®å‰‡è²¼æ–‡è©³ç´°æ•¸æ“š
ä¸ä¾è³´ Dockerï¼Œå°ˆé–€æ¸¬è©¦è®šã€åˆ†äº«ã€ç•™è¨€ç­‰æ•¸æ“š
"""

import sys
import asyncio
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# Windows asyncio ä¿®å¾©
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

from playwright.async_api import async_playwright, Page

# å°å…¥å¿…è¦çš„è§£æå‡½æ•¸
sys.path.append(str(Path(__file__).parent))
from common.config import get_auth_file_path
from common.utils import first_of, parse_thread_item

# --- æ¸¬è©¦è¨­å®š ---
TEST_POST_URLS = [
    "https://www.threads.com/@star_shining0828/post/DMyvZJRz5Cz",  # æ¸¬è©¦è²¼æ–‡1 - æ•¸å­—å‹ç€è¦½æ•¸
    "https://www.threads.com/@star_shining0828/post/DMxwLDUy4JD",  # æ¸¬è©¦è²¼æ–‡2 - è¬å‹ç€è¦½æ•¸  
    "https://www.threads.com/@star_shining0828/post/DMwKpQlThM8",  # æ¸¬è©¦è²¼æ–‡3 - å°‘é‡ç€è¦½æ•¸
]

# æ ¹æ“šèª¿è©¦çµæœå„ªåŒ–çš„æ¬„ä½å°ç…§è¡¨
FIELD_MAP = {
    "like_count": [
        "like_count",  # âœ… ç¢ºèªï¼šdata.data.posts[0].like_count
        "likeCount", 
        ["feedback_info", "aggregated_like_count"],
        ["like_info", "count"]
    ],
    "comment_count": [
        ["text_post_app_info", "direct_reply_count"],  # âœ… ç¢ºèªï¼šç²¾ç¢ºåŒ¹é…
        "comment_count", "commentCount",
        ["reply_info", "count"]
    ],
    "share_count": [
        ["text_post_app_info", "reshare_count"],  # âœ… ç¢ºèªï¼šç²¾ç¢ºåŒ¹é…
        "reshareCount", "share_count", "shareCount"
    ],
    "repost_count": [
        ["text_post_app_info", "repost_count"],  # âœ… ç¢ºèªï¼šç²¾ç¢ºåŒ¹é…
        "repostCount", "repost_count"
    ],
    "content": [
        ["caption", "text"],
        "caption", "text", "content"
    ],
    "author": [
        ["user", "username"], 
        ["owner", "username"],
        ["user", "handle"]
    ],
    "created_at": [
        "taken_at", "taken_at_timestamp", 
        "publish_date", "created_time"
    ],
    "post_id": [
        "pk", "id", "post_id"
    ],
    "code": [
        "code", "shortcode", "media_code"
    ],
    "view_count": [
        ["feedback_info", "view_count"],
        ["video_info", "play_count"],
        "view_count",
        "views",
        "impression_count"
    ],
}

# GraphQL æŸ¥è©¢æ­£å‰‡
GRAPHQL_RE = re.compile(r"/graphql/query")

def extract_post_code_from_url(url: str) -> str:
    """å¾ URL ä¸­æå–è²¼æ–‡ä»£ç¢¼"""
    match = re.search(r'/post/([A-Za-z0-9_-]+)', url)
    return match.group(1) if match else ""

def find_post_node(payload: Any, target_post_url: str = "") -> Optional[Dict]:
    """
    å¾ä»»ä½• Threads JSON è² è¼‰è£¡éè¿´æ‰¾å‡ºå–®ç¯‡è²¼æ–‡ç‰©ä»¶
    æ”¯æ´ HTML ç›´åµŒæ¨¡å¼å’Œ Gate é  GraphQL æ¨¡å¼
    """
    if isinstance(payload, dict):
        t = payload.get("__typename", "")
        
        # â‘  ç›´æ¥å°±æ˜¯è²¼æ–‡ç‰©ä»¶ - æ”¯æ´æ‰€æœ‰ XDT é¡å‹
        if (t.startswith("XDT") or 
            t.endswith(("TextPost", "Photo", "Video", "Media"))):
            print(f"   ğŸ¯ æ‰¾åˆ°è²¼æ–‡ç‰©ä»¶: {t}")
            return payload
        
        # â‘¡ Gate é å®Œæ•´ç‰ˆï¼šdata.media çµæ§‹
        if "media" in payload and isinstance(payload["media"], dict):
            media_obj = payload["media"]
            media_type = media_obj.get("__typename", "")
            if (media_type.startswith("XDT") or 
                media_type.endswith(("TextPost", "Photo", "Video", "Media"))):
                print(f"   ğŸ¯ åœ¨ Gate é  data.media ä¸­æ‰¾åˆ°è²¼æ–‡: {media_type}")
                return media_obj
        
        # â‘¢ Gate é æ‰¹æ¬¡è¨ˆæ•¸ï¼šdata.data.posts[] (æ ¹æ“š post code åŒ¹é…æ­£ç¢ºçš„è²¼æ–‡)
        if "posts" in payload and isinstance(payload["posts"], list):
            posts_list = payload["posts"]
            if posts_list and len(posts_list) > 0:
                target_code = extract_post_code_from_url(target_post_url) if target_post_url else ""
                
                print(f"   ğŸ” åœ¨ {len(posts_list)} å€‹æ‰¹æ¬¡è²¼æ–‡ä¸­å°‹æ‰¾ç›®æ¨™: {target_code}")
                
                for i, post in enumerate(posts_list):
                    if isinstance(post, dict):
                        # æª¢æŸ¥æ˜¯å¦æœ‰é—œéµçš„è¨ˆæ•¸æ¬„ä½
                        has_counts = (
                            "like_count" in post or 
                            "text_post_app_info" in post
                        )
                        
                        if has_counts:
                            post_code = post.get("code", "")
                            pk = post.get("pk", "")
                            like_count = post.get("like_count", 0)
                            
                            print(f"      ğŸ“ è²¼æ–‡ {i}: code={post_code}, pk={pk}, è®š={like_count}")
                            
                            # å¦‚æœæœ‰ç›®æ¨™ä»£ç¢¼ï¼Œå„ªå…ˆåŒ¹é…
                            if target_code and post_code == target_code:
                                print(f"   ğŸ¯ æ‰¾åˆ°ç›®æ¨™è²¼æ–‡ (ç´¢å¼• {i}): {post_code}")
                                return post
                            # å¦‚æœæ²’æœ‰ç›®æ¨™ä»£ç¢¼ï¼Œå–ç¬¬ä¸€å€‹æœ‰æ•ˆçš„
                            elif not target_code and i == 0:
                                print(f"   ğŸ¯ ä½¿ç”¨ç¬¬ä¸€å€‹æ‰¹æ¬¡è²¼æ–‡ (ç´¢å¼• {i})")
                                return post
                
                # å¦‚æœæ²’æ‰¾åˆ°åŒ¹é…çš„ï¼Œä½†æœ‰ç›®æ¨™ä»£ç¢¼ï¼Œçµ¦å‡ºè­¦å‘Š
                if target_code:
                    print(f"   âš ï¸ æœªæ‰¾åˆ°åŒ¹é…ä»£ç¢¼ {target_code} çš„è²¼æ–‡ï¼Œä½¿ç”¨ç¬¬ä¸€å€‹")
                    first_valid = next((post for post in posts_list if isinstance(post, dict) and ("like_count" in post or "text_post_app_info" in post)), None)
                    if first_valid:
                        return first_valid
        
        # â‘£ èˆŠå¼ thread_items çµæ§‹ (HTML ç›´åµŒæ¨¡å¼)
        if "thread_items" in payload:
            items = payload["thread_items"]
            if items and len(items) > 0:
                post = items[0].get("post") or items[0]
                if post:
                    print(f"   ğŸ¯ åœ¨ thread_items ä¸­æ‰¾åˆ°è²¼æ–‡")
                    return post
        
        # â‘¤ ä¸€èˆ¬éè¿´æœå°‹
        for v in payload.values():
            found = find_post_node(v)
            if found:
                return found
                
    elif isinstance(payload, list):
        for item in payload:
            found = find_post_node(item)
            if found:
                return found
    
    return None

def parse_single_post_data(post_data: Dict[str, Any], username: str) -> Dict[str, Any]:
    """
    è§£æå–®å‰‡è²¼æ–‡çš„è©³ç´°æ•¸æ“š - çµ±ä¸€è™•ç† HTML ç›´åµŒå’Œ GraphQL å…©ç¨®æ¨¡å¼
    """
    # ç›´æ¥ä½¿ç”¨å‚³å…¥çš„ post æ•¸æ“šï¼Œä¸å†éœ€è¦ parse_thread_item
    post = post_data
    
    if not post:
        print(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ post ç‰©ä»¶")
        return {}

    # æå–æ‰€æœ‰æ¬„ä½
    result = {
        "post_id": first_of(post, *FIELD_MAP["post_id"]),
        "code": first_of(post, *FIELD_MAP["code"]),
        "author": first_of(post, *FIELD_MAP["author"]) or username,
        "content": first_of(post, *FIELD_MAP["content"]) or "",
        "like_count": first_of(post, *FIELD_MAP["like_count"]) or 0,
        "comment_count": first_of(post, *FIELD_MAP["comment_count"]) or 0,
        "share_count": first_of(post, *FIELD_MAP["share_count"]) or 0,
        "repost_count": first_of(post, *FIELD_MAP["repost_count"]) or 0,
        "view_count": first_of(post, *FIELD_MAP["view_count"]) or 0,
        "created_at": first_of(post, *FIELD_MAP["created_at"]),
        "raw_keys": list(post.keys()),  # èª¿è©¦ç”¨ï¼šé¡¯ç¤ºæ‰€æœ‰å¯ç”¨æ¬„ä½
        "typename": post.get("__typename"),  # èª¿è©¦ç”¨ï¼šé¡¯ç¤ºç‰©ä»¶é¡å‹
    }
    
    # è™•ç†æ™‚é–“æˆ³
    if result["created_at"] and isinstance(result["created_at"], (int, float)):
        result["created_at_formatted"] = datetime.fromtimestamp(result["created_at"]).isoformat()
    
    return result

async def handle_graphql_or_html(page: Page, post_url: str, username: str, context) -> Optional[Dict[str, Any]]:
    """
    çµ±ä¸€è™•ç† HTML ç›´åµŒæ¨¡å¼å’Œ Gate é  GraphQL æ¨¡å¼
    """
    print(f"   ğŸŒ å°èˆªåˆ°: {post_url}")
    await page.goto(post_url, wait_until="networkidle", timeout=60000)
    
    # æª¢æŸ¥é é¢å…§å®¹
    html = await page.content()
    
    # å…ˆç­‰å¾…ä¸€ä¸‹ï¼Œç¢ºä¿é é¢å®Œå…¨è¼‰å…¥
    await asyncio.sleep(2)
    
    # å†æ¬¡ç²å–é é¢å…§å®¹
    html = await page.content()
    
    print(f"   ğŸ” é é¢é•·åº¦: {len(html)} å­—ç¬¦")
    print(f"   ğŸ” __NEXT_DATA__ æª¢æŸ¥: {'âœ… å­˜åœ¨' if '__NEXT_DATA__' in html else 'âŒ ä¸å­˜åœ¨'}")
    
    # æ¨¡å¼1: HTML ç›´åµŒè³‡æ–™ (__NEXT_DATA__ å­˜åœ¨)
    if "__NEXT_DATA__" in html:
        print(f"   âœ… æª¢æ¸¬åˆ° HTML ç›´åµŒæ¨¡å¼")
        try:
            # æå– __NEXT_DATA__ - ä½¿ç”¨æ›´å¯¬é¬†çš„æ­£å‰‡
            next_data_patterns = [
                r'<script id="__NEXT_DATA__"[^>]*>(.*?)</script>',
                r'__NEXT_DATA__["\']?\s*[:=]\s*({.*?})\s*[;,]?',
                r'window\.__NEXT_DATA__\s*=\s*({.*?});'
            ]
            
            data = None
            for pattern in next_data_patterns:
                next_data_match = re.search(pattern, html, re.DOTALL)
                if next_data_match:
                    try:
                        data = json.loads(next_data_match.group(1))
                        print(f"   ğŸ“¦ æˆåŠŸè§£æ __NEXT_DATA__ (æ¨¡å¼: {pattern[:20]}...)")
                        break
                    except json.JSONDecodeError:
                        continue
            
            if data:
                # ä½¿ç”¨çµ±ä¸€çš„ find_post_node æ‰¾è²¼æ–‡
                post = find_post_node(data, post_url)
                if post:
                    print(f"   âœ… å¾ HTML ç›´åµŒæ‰¾åˆ°è²¼æ–‡ç‰©ä»¶")
                    print(f"   ğŸ·ï¸ ç‰©ä»¶é¡å‹: {post.get('__typename', 'Unknown')}")
                    return {"source": "html_embedded", "post": post}
                else:
                    print(f"   âŒ åœ¨ __NEXT_DATA__ ä¸­æ‰¾ä¸åˆ°è²¼æ–‡ç‰©ä»¶")
                    # ä¿å­˜èª¿è©¦æ•¸æ“š
                    debug_file = Path(f"debug_next_data_{datetime.now().strftime('%H%M%S')}.json")
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, indent=2, ensure_ascii=False)
                    print(f"   ğŸ“ å·²ä¿å­˜èª¿è©¦æ•¸æ“šåˆ°: {debug_file}")
                    
                    # é¡¯ç¤ºå¯ç”¨çš„é ‚å±¤éµä»¥ä¾¿èª¿è©¦
                    if isinstance(data, dict):
                        print(f"   ğŸ” __NEXT_DATA__ é ‚å±¤éµ: {list(data.keys())}")
            else:
                print(f"   âŒ æ‰¾åˆ° __NEXT_DATA__ æ¨™è¨˜ä½†ç„¡æ³•æå–æœ‰æ•ˆçš„ JSON")
                # ä¿å­˜ä¸€å°æ®µ HTML ä¾›èª¿è©¦
                html_snippet = html[html.find("__NEXT_DATA__"):html.find("__NEXT_DATA__") + 1000]
                print(f"   ğŸ” HTML ç‰‡æ®µ: {html_snippet[:200]}...")
                
        except Exception as e:
            print(f"   âŒ è§£æ __NEXT_DATA__ å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    # æ¨¡å¼2: Gate é  / éœ€è¦ GraphQL API
    else:
        print(f"   ğŸšª æª¢æ¸¬åˆ° Gate é æ¨¡å¼ï¼Œç­‰å¾… GraphQL API...")
        
        # è¨­ç½® GraphQL æ””æˆªå™¨ - åˆ†åˆ¥å­˜å„²å®Œæ•´ç‰ˆå’Œè¨ˆæ•¸ç‰ˆ
        captured_full = []     # å®Œæ•´å…§å®¹éŸ¿æ‡‰ (æœ‰ data.media)
        captured_counts = []   # å‹•æ…‹è¨ˆæ•¸éŸ¿æ‡‰ (åªæœ‰ counts)
        
        async def response_handler(response):
            url = response.url.lower()
            qname = response.request.headers.get("x-fb-friendly-name", "")
            is_graphql = "/graphql" in url and response.status == 200
            
            if not is_graphql:
                return
                
            try:
                data = await response.json()
                
                # â¶ å„ªå…ˆæª¢æŸ¥ data.mediaï¼šå®Œæ•´ç‰ˆä¸€å®šæœƒæœ‰ media
                if find_post_node(data, post_url):
                    print(f"   ğŸŸ¢ æ””æˆªåˆ°å®Œæ•´å…§å®¹æŸ¥è©¢: {qname or url}")
                    captured_full.append({
                        "data": data, 
                        "qname": qname,
                        "url": response.url
                    })
                # ï¿½â‘¡  æª¢æŸ¥æ˜¯å¦ç‚ºå‹•æ…‹è¨ˆæ•¸æŸ¥è©¢
                elif ("posts" in str(data) and "text_post_app_info" in str(data)) or "DynamicPostCountsSubscriptionQuery" in qname:
                    print(f"   ğŸŸ¡ æ””æˆªåˆ°å‹•æ…‹è¨ˆæ•¸æŸ¥è©¢: {qname}")
                    captured_counts.append({
                        "data": data,
                        "qname": qname,
                        "url": response.url
                    })
                else:
                    print(f"   ğŸ” æ””æˆªåˆ°å…¶ä»– GraphQL: {qname or 'Unknown'}")
                    
            except Exception as e:
                print(f"   âš ï¸ ç„¡æ³•è§£æ GraphQL éŸ¿æ‡‰: {e}")
        
        # æ–°å¢ï¼šè‡ªå‹•è£œæ‰“å®Œæ•´å…§å®¹ API çš„å‡½æ•¸
        async def fetch_full_post_by_pk(context, pk: str, typename: str = "XDTTextPost") -> Optional[Dict]:
            """æ ¹æ“š pk è‡ªå‹•è£œæ‰“å®Œæ•´å…§å®¹ API"""
            DOC_IDS = {
                "XDTTextPost": "7248604598467997",
                "XDTPhoto": "7205124739579889", 
                "XDTVideo": "7110719515677565",
            }
            doc_id = DOC_IDS.get(typename, DOC_IDS["XDTTextPost"])
            variables = json.dumps({"postID": pk, "includePromotedPosts": False})
            
            try:
                print(f"   ğŸ”„ è£œæ‰“å®Œæ•´å…§å®¹ API (pk: {pk}, type: {typename})")
                response = await context.request.post(
                    "https://www.threads.com/graphql/query",
                    data={"doc_id": doc_id, "variables": variables},
                    headers={"x-ig-app-id": "238260118697367"}
                )
                data = await response.json()
                post = find_post_node(data, "")
                if post:
                    print(f"   âœ… æˆåŠŸè£œç²å®Œæ•´å…§å®¹")
                    return post
                else:
                    print(f"   âŒ è£œæ‰“ API æœªæ‰¾åˆ°è²¼æ–‡å…§å®¹")
            except Exception as e:
                print(f"   âŒ è£œæ‰“ API å¤±æ•—: {e}")
            return None
        
        page.on("response", response_handler)
        
        # å˜—è©¦å¤šç¨®æ–¹å¼è§¸ç™¼ GraphQL è«‹æ±‚
        actions = [
            lambda: page.evaluate("window.scrollTo(0, 100)"),
            lambda: page.evaluate("window.scrollTo(0, 300)"),
            lambda: page.reload(),
            lambda: page.click("body") if page.locator("body").count() > 0 else None,
        ]
        
        for i, action in enumerate(actions):
            try:
                print(f"   ğŸ”„ å˜—è©¦è§¸ç™¼ GraphQL è«‹æ±‚ ({i+1}/{len(actions)})...")
                if action:
                    await action()
                await asyncio.sleep(3)
                
                if captured_full or captured_counts:
                    break
                    
            except Exception as e:
                print(f"   âš ï¸ å‹•ä½œ {i+1} å¤±æ•—: {e}")
                continue
        
        # ç§»é™¤äº‹ä»¶ç›£è½å™¨
        page.remove_listener("response", response_handler)
        
        # æ™ºèƒ½åˆ†æå’Œåˆä½µéŸ¿æ‡‰
        total_responses = len(captured_full) + len(captured_counts)
        print(f"   âœ… æˆåŠŸæ””æˆªåˆ° {total_responses} å€‹ GraphQL éŸ¿æ‡‰")
        print(f"      ğŸŸ¢ å®Œæ•´å…§å®¹éŸ¿æ‡‰: {len(captured_full)} å€‹")
        print(f"      ğŸŸ¡ å‹•æ…‹è¨ˆæ•¸éŸ¿æ‡‰: {len(captured_counts)} å€‹")
        
        final_post = None
        source_type = "unknown"
        query_name = "Unknown"
        
        # ç­–ç•¥1: å„ªå…ˆä½¿ç”¨å®Œæ•´å…§å®¹éŸ¿æ‡‰
        if captured_full:
            full_resp = captured_full[0]
            final_post = find_post_node(full_resp["data"], post_url)
            if final_post:
                print(f"   ğŸ¯ ä½¿ç”¨å®Œæ•´å…§å®¹: {full_resp['qname']}")
                source_type = "full"
                query_name = full_resp["qname"]
                
                # å¦‚æœæœ‰è¨ˆæ•¸æ•¸æ“šï¼Œåˆä½µæœ€æ–°çš„è¨ˆæ•¸
                if captured_counts:
                    count_post = find_post_node(captured_counts[0]["data"], post_url)
                    if count_post:
                        print(f"   ğŸ”„ åˆä½µæœ€æ–°è¨ˆæ•¸æ•¸æ“š...")
                        # ç”¨è¨ˆæ•¸ç‰ˆçš„æ•¸å­—è¦†è“‹å®Œæ•´ç‰ˆ
                        for key in ["like_count", "text_post_app_info"]:
                            if key in count_post:
                                final_post[key] = count_post[key]
                                print(f"      â†» æ›´æ–° {key}")
        
        # ç­–ç•¥2: å›é€€åˆ°è¨ˆæ•¸ç‰ˆï¼Œä¸¦å˜—è©¦è£œæ‰“å®Œæ•´å…§å®¹ API
        elif captured_counts:
            count_resp = captured_counts[0]
            count_post = find_post_node(count_resp["data"], post_url)
            if count_post:
                print(f"   ğŸŸ¡ ä½¿ç”¨è¨ˆæ•¸ç‰ˆ: {count_resp['qname']}")
                
                # å˜—è©¦å¾è¨ˆæ•¸æ•¸æ“šä¸­æå– pk å’Œé¡å‹
                pk = count_post.get("pk") or count_post.get("id")
                typename = count_post.get("__typename", "XDTTextPost")
                
                if pk:
                    print(f"   ğŸ”„ å˜—è©¦è£œæ‰“å®Œæ•´å…§å®¹ API...")
                    full_post_data = await fetch_full_post_by_pk(context, str(pk), typename)
                    
                    if full_post_data:
                        # æˆåŠŸè£œç²å®Œæ•´å…§å®¹ï¼Œåˆä½µæ•¸æ“š
                        print(f"   âœ… æˆåŠŸåˆä½µ å®Œæ•´å…§å®¹ + æœ€æ–°è¨ˆæ•¸")
                        # ç”¨è¨ˆæ•¸ç‰ˆçš„æ•¸å­—è¦†è“‹å®Œæ•´ç‰ˆ 
                        for key in ["like_count", "text_post_app_info"]:
                            if key in count_post:
                                full_post_data[key] = count_post[key]
                        
                        final_post = full_post_data
                        source_type = "merged"
                        query_name = f"{count_resp['qname']} + APIè£œç²"
                    else:
                        # è£œç²å¤±æ•—ï¼Œåªèƒ½ä½¿ç”¨è¨ˆæ•¸ç‰ˆ
                        print(f"   âš ï¸ è£œç²å¤±æ•—ï¼Œåƒ…ä½¿ç”¨è¨ˆæ•¸æ•¸æ“š")
                        final_post = count_post
                        source_type = "counts_only"
                        query_name = count_resp["qname"]
                else:
                    print(f"   âŒ è¨ˆæ•¸æ•¸æ“šä¸­æ‰¾ä¸åˆ° pkï¼Œç„¡æ³•è£œç²å®Œæ•´å…§å®¹")
                    final_post = count_post
                    source_type = "counts_only"
                    query_name = count_resp["qname"]
        
        if final_post:
            return {
                "source": "graphql_api",
                "post": final_post,
                "query_name": query_name,
                "source_type": source_type
            }
        
        # å¦‚æœæ²’æ‰¾åˆ°è²¼æ–‡ï¼Œä¿å­˜èª¿è©¦æ•¸æ“š
        all_responses = captured_full + captured_counts
        if all_responses:
            print(f"   âŒ åœ¨æ‰€æœ‰ {len(all_responses)} å€‹ GraphQL å›æ‡‰ä¸­éƒ½æ‰¾ä¸åˆ°è²¼æ–‡ç‰©ä»¶")
            debug_file = Path(f"debug_graphql_responses_{datetime.now().strftime('%H%M%S')}.json")
            with open(debug_file, 'w', encoding='utf-8') as f:
                json.dump(all_responses, f, indent=2, ensure_ascii=False)
            print(f"   ğŸ“ å·²ä¿å­˜æ‰€æœ‰éŸ¿æ‡‰æ•¸æ“šåˆ°: {debug_file}")
        else:
            print(f"   âŒ æ²’æœ‰æ””æˆªåˆ°ä»»ä½• GraphQL éŸ¿æ‡‰")
            print(f"   ğŸ’¡ å»ºè­°æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–èªè­‰ç‹€æ…‹")
    
    return None

async def test_single_post_graphql(post_url: str, auth_file_path: Path) -> Optional[Dict[str, Any]]:
    """
    æ¸¬è©¦å–®å‰‡è²¼æ–‡çš„æ•¸æ“šæŠ“å– - æ”¯æ´é›™æ¨¡å¼
    """
    print(f"\nğŸ” æ¸¬è©¦è²¼æ–‡: {post_url}")
    
    # å¾URLæå–username
    parts = post_url.split("/")
    username = parts[3].replace("@", "") if len(parts) > 3 else "unknown"
    print(f"   ğŸ‘¤ ç”¨æˆ¶: {username}")
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=False,  # è¨­ç‚º False ä»¥ä¾¿è§€å¯Ÿ
            args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-blink-features=AutomationControlled"]
        )
        
        context = await browser.new_context(
            storage_state=str(auth_file_path),
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
            viewport={"width": 1920, "height": 1080},
            locale="zh-TW",
            bypass_csp=True
        )
        
        # éš±è— webdriver å±¬æ€§
        await context.add_init_script(
            "Object.defineProperty(navigator,'webdriver',{get:()=>undefined})"
        )
        
        page = await context.new_page()
        
        # ä½¿ç”¨çµ±ä¸€çš„è™•ç†å‡½æ•¸
        result = await handle_graphql_or_html(page, post_url, username, context)
        
        await browser.close()
        
        if result:
            post_data = result["post"]
            source = result["source"]
            query_name = result.get("query_name", "Unknown")
            source_type = result.get("source_type", "unknown")
            
            print(f"\nğŸ“Š æ•¸æ“šä¾†æº: {source}")
            print(f"   ğŸ” æŸ¥è©¢åç¨±: {query_name}")
            print(f"   ğŸ“‹ ä¾†æºé¡å‹: {source_type}")
            print(f"   ğŸ”„ é–‹å§‹è§£æè²¼æ–‡æ•¸æ“š...")
            
            # è§£æè²¼æ–‡æ•¸æ“š
            parsed = parse_single_post_data(post_data, username)
            
            if parsed:
                print(f"\nâœ… è§£ææˆåŠŸ:")
                print(f"   ID: {parsed.get('post_id')}")
                print(f"   é¡å‹: {parsed.get('typename')}")
                print(f"   ä½œè€…: {parsed.get('author')}")
                print(f"   è®šæ•¸: {parsed.get('like_count'):,}")
                print(f"   ç•™è¨€æ•¸: {parsed.get('comment_count'):,}")
                print(f"   åˆ†äº«æ•¸: {parsed.get('share_count'):,}")
                print(f"   è½‰ç™¼æ•¸: {parsed.get('repost_count'):,}")
                print(f"   ç€è¦½æ•¸: {parsed.get('view_count'):,}")
                print(f"   å…§å®¹é•·åº¦: {len(parsed.get('content', ''))}")
                print(f"   å…§å®¹é è¦½: {parsed.get('content', '')[:100]}...")
                print(f"   å¯ç”¨æ¬„ä½æ•¸é‡: {len(parsed.get('raw_keys', []))}")
                print(f"   å¯ç”¨æ¬„ä½: {parsed.get('raw_keys', [])[:10]}...")  # åªé¡¯ç¤ºå‰10å€‹
                
                # åŠ å…¥è©³ç´°ä¾†æºè³‡è¨Š
                parsed["data_source"] = source
                parsed["query_name"] = query_name
                parsed["source_type"] = source_type
                return {f"{source}_{source_type}_result": parsed}
            else:
                print(f"   âŒ è§£æè²¼æ–‡æ•¸æ“šå¤±æ•—")
        else:
            print(f"   âŒ æœªèƒ½ç²å–åˆ°è²¼æ–‡æ•¸æ“š")
    
    return None

async def main():
    """
    ä¸»æ¸¬è©¦å‡½æ•¸
    """
    print("ğŸš€ GraphQL å–®å‰‡è²¼æ–‡æ¸¬è©¦é–‹å§‹...")
    
    # æª¢æŸ¥èªè­‰æª”æ¡ˆ
    auth_file_path = get_auth_file_path()
    if not auth_file_path.exists():
        print(f"âŒ èªè­‰æª”æ¡ˆä¸å­˜åœ¨: {auth_file_path}")
        print("   è«‹å…ˆåŸ·è¡Œ save_auth.py ç”Ÿæˆèªè­‰æª”æ¡ˆ")
        return
    
    print(f"âœ… ä½¿ç”¨èªè­‰æª”æ¡ˆ: {auth_file_path}")
    
    # æ¸¬è©¦æ¯å€‹è²¼æ–‡
    all_results = {}
    
    for i, post_url in enumerate(TEST_POST_URLS):
        print(f"\n{'='*50}")
        print(f"æ¸¬è©¦ {i+1}/{len(TEST_POST_URLS)}")
        
        try:
            results = await test_single_post_graphql(post_url, auth_file_path)
            if results:
                all_results[post_url] = results
            else:
                print(f"âŒ æœªèƒ½ç²å–åˆ°æ•¸æ“š")
                
        except Exception as e:
            print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
        
        # å»¶é²é¿å…åçˆ¬èŸ²
        if i < len(TEST_POST_URLS) - 1:
            print(f"   â³ å»¶é² 3 ç§’...")
            await asyncio.sleep(3)
    
    # ä¿å­˜çµæœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    result_file = Path(f"graphql_test_results_{timestamp}.json")
    
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"\nğŸ¯ æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ“ çµæœå·²ä¿å­˜è‡³: {result_file}")
    print(f"ğŸ“Š æˆåŠŸæ¸¬è©¦è²¼æ–‡æ•¸: {len(all_results)}")

if __name__ == "__main__":
    asyncio.run(main())