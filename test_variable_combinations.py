"""
æ¸¬è©¦ä¸åŒçš„è®Šæ•¸çµ„åˆä¾†æ‰¾åˆ°æ­£ç¢ºçš„å…§å®¹æŸ¥è©¢æ ¼å¼
"""

import asyncio
import json
import httpx
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List

import sys
sys.path.append(str(Path(__file__).parent))

from playwright.async_api import async_playwright
from common.config import get_auth_file_path

# æ¸¬è©¦è²¼æ–‡
TEST_POST_URL = "https://www.threads.com/@star_shining0828/post/DMyvZJRz5Cz"
TARGET_PK = "3689219480905289907"

async def get_real_lsd_token():
    """å¿«é€Ÿç²å– LSD token"""
    auth_file_path = get_auth_file_path()
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            storage_state=str(auth_file_path),
            user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15",
            viewport={"width": 375, "height": 812}
        )
        
        page = await context.new_page()
        lsd_token = None
        
        async def response_handler(response):
            nonlocal lsd_token
            if "/graphql" in response.url.lower() and response.status == 200:
                try:
                    post_data = response.request.post_data
                    if post_data and "fb_dtsg=" in post_data:
                        import urllib.parse
                        for part in post_data.split('&'):
                            if part.startswith('fb_dtsg='):
                                lsd_token = urllib.parse.unquote(part.split('=', 1)[1])
                                break
                except:
                    pass
        
        page.on("response", response_handler)
        await page.goto("https://www.threads.com/@threads", wait_until="networkidle")
        await asyncio.sleep(3)
        await browser.close()
    
    return lsd_token

async def test_variable_combination(variables: Dict[str, Any], description: str):
    """æ¸¬è©¦ç‰¹å®šçš„è®Šæ•¸çµ„åˆ"""
    print(f"\nğŸ§ª æ¸¬è©¦: {description}")
    
    # ç²å–èªè­‰
    auth_file_path = get_auth_file_path()
    auth_data = json.loads(auth_file_path.read_text())
    cookies = {cookie['name']: cookie['value'] for cookie in auth_data.get('cookies', [])}
    
    lsd_token = await get_real_lsd_token()
    if not lsd_token:
        print("   âŒ ç„¡æ³•ç²å– LSD token")
        return False
    
    # æ§‹å»ºè«‹æ±‚æ•¸æ“š
    request_data = {
        "av": "17841476182615522",
        "__user": "0",
        "__a": "1",
        "__req": "1",
        "dpr": "3",
        "__ccg": "EXCELLENT",
        "__rev": "1025400969",
        "fb_dtsg": lsd_token,
        "jazoest": "26410",
        "lsd": lsd_token,
        "fb_api_caller_class": "RelayModern",
        "fb_api_req_friendly_name": "BarcelonaPostPageRefetchableDirectQuery",
        "variables": json.dumps(variables),
        "server_timestamps": "true",
        "doc_id": "24061215210199287"
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15",
        "Accept": "*/*",
        "Content-Type": "application/x-www-form-urlencoded",
        "X-FB-Friendly-Name": "BarcelonaPostPageRefetchableDirectQuery",
        "X-FB-LSD": lsd_token,
        "Origin": "https://www.threads.com",
        "Referer": TEST_POST_URL,
    }
    
    # ç™¼é€è«‹æ±‚
    async with httpx.AsyncClient(cookies=cookies, timeout=30.0) as client:
        try:
            response = await client.post(
                "https://www.threads.com/api/graphql",
                data=request_data,
                headers=headers
            )
            
            print(f"   ğŸ“¡ HTTP {response.status_code}")
            
            if response.status_code == 200:
                try:
                    result = response.json()
                    
                    if "errors" in result:
                        print(f"   âŒ éŒ¯èª¤: {result['errors'][:1]}")
                        return False
                    
                    if "data" in result:
                        data = result["data"]
                        if data and "data" in data and data["data"]:
                            print(f"   âœ… æˆåŠŸç²å–æœ‰æ•ˆæ•¸æ“šï¼")
                            
                            # å¿«é€Ÿåˆ†æçµæ§‹
                            inner_data = data["data"]
                            if "edges" in inner_data:
                                edges_count = len(inner_data["edges"])
                                print(f"   ğŸ“ æ‰¾åˆ° {edges_count} å€‹ edges")
                                
                                # æª¢æŸ¥æ˜¯å¦æœ‰æˆ‘å€‘è¦çš„è²¼æ–‡
                                found_target = False
                                for edge in inner_data["edges"]:
                                    if "node" in edge and "thread_items" in edge["node"]:
                                        for item in edge["node"]["thread_items"]:
                                            if "post" in item and item["post"].get("pk") == TARGET_PK:
                                                found_target = True
                                                post = item["post"]
                                                
                                                # æª¢æŸ¥å…§å®¹
                                                caption = post.get("caption", {})
                                                content_text = caption.get("text", "") if caption else ""
                                                
                                                # æª¢æŸ¥åª’é«”
                                                has_images = "image_versions2" in post or "carousel_media" in post
                                                has_videos = "video_versions" in post
                                                
                                                print(f"   ğŸ¯ æ‰¾åˆ°ç›®æ¨™è²¼æ–‡ï¼")
                                                print(f"      ğŸ“ å…§å®¹é•·åº¦: {len(content_text)} å­—ç¬¦")
                                                print(f"      ğŸ–¼ï¸ æœ‰åœ–ç‰‡: {has_images}")
                                                print(f"      ğŸ¥ æœ‰å½±ç‰‡: {has_videos}")
                                                
                                                # ä¿å­˜æˆåŠŸçš„çµ„åˆ
                                                success_file = Path(f"successful_variables_{datetime.now().strftime('%H%M%S')}.json")
                                                with open(success_file, 'w', encoding='utf-8') as f:
                                                    json.dump({
                                                        "description": description,
                                                        "variables": variables,
                                                        "post_data": post
                                                    }, f, indent=2, ensure_ascii=False)
                                                print(f"      ğŸ“ å·²ä¿å­˜æˆåŠŸçµ„åˆåˆ°: {success_file}")
                                                
                                                return True
                                
                                if not found_target:
                                    print(f"   âš ï¸ æœ‰æ•¸æ“šä½†æœªæ‰¾åˆ°ç›®æ¨™è²¼æ–‡")
                            else:
                                print(f"   âš ï¸ æœ‰ data ä½†çµæ§‹ä¸ç¬¦é æœŸ: {list(inner_data.keys())}")
                        else:
                            print(f"   âŒ data.data ç‚ºç©ºæˆ– null")
                    else:
                        print(f"   âŒ éŸ¿æ‡‰ä¸­ç„¡ data æ¬„ä½")
                    
                    return False
                
                except Exception as e:
                    print(f"   âŒ è§£æå¤±æ•—: {e}")
                    return False
            else:
                print(f"   âŒ HTTP éŒ¯èª¤: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"   âŒ è«‹æ±‚å¤±æ•—: {e}")
            return False

async def main():
    """æ¸¬è©¦å¤šç¨®è®Šæ•¸çµ„åˆ"""
    print("ğŸš€ æ¸¬è©¦å¤šç¨®è®Šæ•¸çµ„åˆ...")
    
    # æ¸¬è©¦çµ„åˆ 1: æœ€ç°¡åŒ–ç‰ˆæœ¬
    simple_vars = {
        "postID": TARGET_PK,
        "is_logged_in": True
    }
    
    # æ¸¬è©¦çµ„åˆ 2: åŠ ä¸Šåˆ†é åƒæ•¸
    pagination_vars = {
        "postID": TARGET_PK,
        "is_logged_in": True,
        "first": 10,
        "after": None,
        "before": None,
        "last": None
    }
    
    # æ¸¬è©¦çµ„åˆ 3: åŠ ä¸Šæ’åº
    sorted_vars = {
        "postID": TARGET_PK,
        "is_logged_in": True,
        "first": 10,
        "sort_order": "TOP"
    }
    
    # æ¸¬è©¦çµ„åˆ 4: æ ¸å¿ƒ relay åƒæ•¸
    core_relay_vars = {
        "postID": TARGET_PK,
        "is_logged_in": True,
        "first": 4,
        "sort_order": "TOP",
        "__relay_internal__pv__BarcelonaIsLoggedInrelayprovider": True,
        "__relay_internal__pv__BarcelonaIsCrawlerrelayprovider": False
    }
    
    # æ¸¬è©¦çµ„åˆ 5: å®Œæ•´åƒæ•¸ï¼ˆå¾æ””æˆªè¤‡è£½ï¼‰
    full_vars = {
        "after": None,
        "before": None,
        "first": 4,
        "is_logged_in": True,
        "last": None,
        "postID": TARGET_PK,
        "sort_order": "TOP",
        "__relay_internal__pv__BarcelonaIsLoggedInrelayprovider": True,
        "__relay_internal__pv__BarcelonaHasSelfReplyContextrelayprovider": False,
        "__relay_internal__pv__BarcelonaShouldShowFediverseM1Featuresrelayprovider": True,
        "__relay_internal__pv__BarcelonaHasInlineReplyComposerrelayprovider": False,
        "__relay_internal__pv__BarcelonaHasEventBadgerelayprovider": False,
        "__relay_internal__pv__BarcelonaIsSearchDiscoveryEnabledrelayprovider": False,
        "__relay_internal__pv__IsTagIndicatorEnabledrelayprovider": True,
        "__relay_internal__pv__BarcelonaOptionalCookiesEnabledrelayprovider": True,
        "__relay_internal__pv__BarcelonaHasSelfThreadCountrelayprovider": False,
        "__relay_internal__pv__BarcelonaHasSpoilerStylingInforelayprovider": True,
        "__relay_internal__pv__BarcelonaHasDeepDiverelayprovider": False,
        "__relay_internal__pv__BarcelonaQuotedPostUFIEnabledrelayprovider": False,
        "__relay_internal__pv__BarcelonaHasTopicTagsrelayprovider": True,
        "__relay_internal__pv__BarcelonaIsCrawlerrelayprovider": False,
        "__relay_internal__pv__BarcelonaHasDisplayNamesrelayprovider": False,
        "__relay_internal__pv__BarcelonaCanSeeSponsoredContentrelayprovider": False,
        "__relay_internal__pv__BarcelonaShouldShowFediverseM075Featuresrelayprovider": True,
        "__relay_internal__pv__BarcelonaImplicitTrendsGKrelayprovider": False,
        "__relay_internal__pv__BarcelonaIsInternalUserrelayprovider": False,
        "__relay_internal__pv__BarcelonaInlineComposerEnabledrelayprovider": False
    }
    
    # ä¾åºæ¸¬è©¦
    test_cases = [
        (simple_vars, "æœ€ç°¡åŒ–ç‰ˆæœ¬"),
        (pagination_vars, "åŠ ä¸Šåˆ†é åƒæ•¸"),
        (sorted_vars, "åŠ ä¸Šæ’åºåƒæ•¸"),
        (core_relay_vars, "æ ¸å¿ƒ relay åƒæ•¸"),
        (full_vars, "å®Œæ•´åƒæ•¸é›†")
    ]
    
    for variables, description in test_cases:
        success = await test_variable_combination(variables, description)
        if success:
            print(f"\nğŸ‰ æ‰¾åˆ°æˆåŠŸçµ„åˆ: {description}")
            break
        await asyncio.sleep(1)  # é¿å…éæ–¼é »ç¹çš„è«‹æ±‚
    else:
        print(f"\nğŸ˜ æ‰€æœ‰çµ„åˆéƒ½å¤±æ•—äº†")
        print(f"ğŸ’¡ å¯èƒ½éœ€è¦æª¢æŸ¥:")
        print(f"   1. postID æ˜¯å¦æ­£ç¢º")
        print(f"   2. æ˜¯å¦éœ€è¦å…¶ä»–å¿…è¦åƒæ•¸")
        print(f"   3. API ç«¯é»æˆ– doc_id æ˜¯å¦è®Šæ›´")

if __name__ == "__main__":
    asyncio.run(main())