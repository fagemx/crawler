"""
æœ€çµ‚å®Œæ•´çš„å…§å®¹æå–å™¨
çµåˆè¨ˆæ•¸æŸ¥è©¢å’Œå…§å®¹æŸ¥è©¢ï¼Œç²å–å®Œæ•´çš„è²¼æ–‡æ•¸æ“š
"""

import asyncio
import json
import httpx
import urllib.parse
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple

import sys
sys.path.append(str(Path(__file__).parent))

from playwright.async_api import async_playwright
from common.config import get_auth_file_path

# æ¸¬è©¦è²¼æ–‡
TEST_POST_URL = "https://www.threads.com/@star_shining0828/post/DMyvZJRz5Cz"
TARGET_PK = "3689219480905289907"

class FinalContentExtractor:
    """æœ€çµ‚å®Œæ•´çš„å…§å®¹æå–å™¨"""
    
    def __init__(self):
        self.counts_query_captured = False
        self.counts_headers = {}
        self.counts_payload = ""
        self.counts_doc_id = ""
        
        self.auth_header = ""
        self.lsd_token = ""
    
    async def intercept_counts_query(self):
        """æ””æˆªè¨ˆæ•¸æŸ¥è©¢ï¼ˆå·²çŸ¥å¯ä»¥ç²å–ç›®æ¨™è²¼æ–‡ï¼‰"""
        print("ğŸ¯ æ””æˆªè¨ˆæ•¸æŸ¥è©¢...")
        
        auth_file_path = get_auth_file_path()
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=False)
            context = await browser.new_context(
                storage_state=str(auth_file_path),
                user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15",
                viewport={"width": 375, "height": 812},
                locale="zh-TW"
            )
            
            page = await context.new_page()
            
            async def response_handler(response):
                friendly_name = response.request.headers.get("x-fb-friendly-name", "")
                
                # æ””æˆªè¨ˆæ•¸æŸ¥è©¢
                if "useBarcelonaBatchedDynamicPostCountsSubscriptionQuery" in friendly_name:
                    print(f"   ğŸ¯ æ””æˆªåˆ°è¨ˆæ•¸æŸ¥è©¢: {friendly_name}")
                    
                    # æª¢æŸ¥æ˜¯å¦åŒ…å«ç›®æ¨™è²¼æ–‡
                    try:
                        data = await response.json()
                        data_str = json.dumps(data, ensure_ascii=False)
                        
                        if TARGET_PK in data_str:
                            print(f"   âœ… ç¢ºèªåŒ…å«ç›®æ¨™è²¼æ–‡ï¼")
                            
                            # å®Œæ•´ä¿å­˜è«‹æ±‚ä¿¡æ¯
                            self.counts_headers = dict(response.request.headers)
                            self.counts_payload = response.request.post_data
                            
                            if self.counts_payload and "doc_id=" in self.counts_payload:
                                self.counts_doc_id = self.counts_payload.split("doc_id=")[1].split("&")[0]
                            
                            self.auth_header = self.counts_headers.get("authorization", "")
                            self.lsd_token = self.counts_headers.get("x-fb-lsd", "")
                            
                            print(f"   ğŸ“‹ doc_id: {self.counts_doc_id}")
                            print(f"   ğŸ”‘ Authorization: {'æ˜¯' if self.auth_header else 'å¦'}")
                            print(f"   ğŸ« LSD: {self.lsd_token[:10] if self.lsd_token else 'ç„¡'}...")
                            
                            # æ‰“å°å®Œæ•´è«‹æ±‚ä¿¡æ¯
                            print("\n======= COUNTS QUERY RAW REQUEST =======")
                            print("PAYLOAD:")
                            print(self.counts_payload)
                            print("\nKEY HEADERS:")
                            for key in ["x-fb-lsd", "x-ig-app-id", "authorization", "x-csrftoken", "x-asbd-id"]:
                                if key in self.counts_headers:
                                    print(f"{key}: {self.counts_headers[key]}")
                            print("=========================================\n")
                            
                            self.counts_query_captured = True
                        else:
                            print(f"   â­ï¸ ä¸åŒ…å«ç›®æ¨™è²¼æ–‡")
                    except Exception as e:
                        print(f"   âŒ è§£æéŸ¿æ‡‰å¤±æ•—: {e}")
            
            page.on("response", response_handler)
            
            # å°èˆªåˆ°é é¢
            print(f"   ğŸŒ å°èˆªåˆ°: {TEST_POST_URL}")
            await page.goto(TEST_POST_URL, wait_until="networkidle", timeout=60000)
            await asyncio.sleep(5)
            
            # å¦‚æœæ²’æ””æˆªåˆ°ï¼Œå˜—è©¦æ»¾å‹•
            if not self.counts_query_captured:
                print(f"   ğŸ“œ å˜—è©¦æ»¾å‹•è§¸ç™¼æ›´å¤šæŸ¥è©¢...")
                await page.evaluate("window.scrollTo(0, 300)")
                await asyncio.sleep(3)
            
            await browser.close()
        
        return self.counts_query_captured
    
    async def get_auth_from_cookies(self) -> Optional[str]:
        """å¾ cookies ç²å– Authorization"""
        auth_file_path = get_auth_file_path()
        auth_data = json.loads(auth_file_path.read_text())
        cookies = {cookie['name']: cookie['value'] for cookie in auth_data.get('cookies', [])}
        
        if 'ig_set_authorization' in cookies:
            auth_value = cookies['ig_set_authorization']
            if auth_value and not auth_value.startswith('Bearer'):
                return f"Bearer {auth_value}"
            return auth_value
        
        if 'sessionid' in cookies:
            sessionid = cookies['sessionid']
            return f"Bearer IGT:2:{sessionid}"
        
        return None
    
    async def extract_complete_post_data(self, target_pk: str = TARGET_PK) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨æ””æˆªåˆ°çš„è¨ˆæ•¸æŸ¥è©¢æå–å®Œæ•´è²¼æ–‡æ•¸æ“š"""
        if not self.counts_query_captured:
            print("âŒ æ²’æœ‰æ””æˆªåˆ°è¨ˆæ•¸æŸ¥è©¢")
            return None
        
        print(f"\nğŸ¬ ä½¿ç”¨è¨ˆæ•¸æŸ¥è©¢æå–å®Œæ•´æ•¸æ“š...")
        
        # ç²å– cookies
        auth_file_path = get_auth_file_path()
        auth_data = json.loads(auth_file_path.read_text())
        cookies = {cookie['name']: cookie['value'] for cookie in auth_data.get('cookies', [])}
        
        # æº–å‚™ headersï¼ˆå®Œå…¨è¤‡è£½ï¼‰
        headers = self.counts_headers.copy()
        for header_to_remove in ["host", "content-length", "accept-encoding"]:
            headers.pop(header_to_remove, None)
        
        # ç¢ºä¿æœ‰ Authorization
        if not headers.get("authorization"):
            auth_from_cookies = await self.get_auth_from_cookies()
            if auth_from_cookies:
                headers["authorization"] = auth_from_cookies
                print(f"   âœ… å¾ cookies è£œå…… Authorization")
        
        # æº–å‚™ payloadï¼ˆå®Œå…¨è¤‡è£½ï¼Œåªæ›¿æ› PKï¼‰
        payload = self.counts_payload
        if target_pk != TARGET_PK:
            payload = payload.replace(TARGET_PK, target_pk)
            print(f"   ğŸ”„ æ›¿æ› PK: {TARGET_PK} â†’ {target_pk}")
        
        # ç™¼é€è«‹æ±‚
        async with httpx.AsyncClient(
            headers=headers,
            cookies=cookies,
            timeout=30.0,
            follow_redirects=True,
            http2=True
        ) as client:
            try:
                response = await client.post(
                    "https://www.threads.com/graphql/query",
                    data=payload
                )
                
                print(f"   ğŸ“¡ HTTP {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        result = response.json()
                        
                        if "errors" in result:
                            print(f"   âŒ GraphQL éŒ¯èª¤: {result['errors'][:1]}")
                            return None
                        
                        if "data" in result and result["data"]:
                            data = result["data"]
                            
                            # è§£æ batch posts çµæ§‹
                            if "data" in data and "posts" in data["data"]:
                                posts = data["data"]["posts"]
                                print(f"   ğŸ“ æ‰¾åˆ° {len(posts)} å€‹è²¼æ–‡")
                                
                                # æ‰¾åˆ°ç›®æ¨™è²¼æ–‡
                                target_post = None
                                for post in posts:
                                    if post.get("pk") == target_pk:
                                        target_post = post
                                        break
                                
                                if target_post:
                                    print(f"   ğŸ¯ æ‰¾åˆ°ç›®æ¨™è²¼æ–‡ï¼")
                                    return await self._extract_post_details(target_post)
                                else:
                                    print(f"   âŒ æœªæ‰¾åˆ°ç›®æ¨™è²¼æ–‡ (PK: {target_pk})")
                                    found_pks = [p.get("pk", "unknown") for p in posts[:3]]
                                    print(f"   ğŸ“‹ æ‰¾åˆ°çš„ PK: {found_pks}")
                            else:
                                print(f"   âŒ æ„å¤–çš„æ•¸æ“šçµæ§‹: {list(data.keys())}")
                        else:
                            print(f"   âŒ ç„¡æ•ˆéŸ¿æ‡‰")
                        
                        return None
                    
                    except Exception as e:
                        print(f"   âŒ è§£æéŸ¿æ‡‰å¤±æ•—: {e}")
                        return None
                
                else:
                    print(f"   âŒ HTTP éŒ¯èª¤: {response.status_code}")
                    return None
            
            except Exception as e:
                print(f"   âŒ è«‹æ±‚å¤±æ•—: {e}")
                return None
    
    async def _extract_post_details(self, post: Dict[str, Any]) -> Dict[str, Any]:
        """å¾è²¼æ–‡æ•¸æ“šä¸­æå–è©³ç´°ä¿¡æ¯"""
        # åŸºæœ¬ä¿¡æ¯
        pk = post.get("pk", "")
        code = post.get("code", "")
        
        # å…§å®¹
        caption = post.get("caption", {}) or {}
        content = caption.get("text", "") if caption else ""
        
        # è¨ˆæ•¸
        like_count = post.get("like_count", 0)
        text_info = post.get("text_post_app_info", {}) or {}
        comment_count = text_info.get("direct_reply_count", 0)
        repost_count = text_info.get("repost_count", 0)
        share_count = text_info.get("reshare_count", 0)
        
        # ç”¨æˆ¶ä¿¡æ¯
        user = post.get("user", {}) or {}
        username = user.get("username", "")
        
        # åª’é«”ä¿¡æ¯
        images = []
        videos = []
        
        # å–®ä¸€åœ–ç‰‡/å½±ç‰‡
        if "image_versions2" in post and post["image_versions2"]:
            candidates = post["image_versions2"].get("candidates", [])
            if candidates:
                # å–æ‰€æœ‰è§£æåº¦çš„åœ–ç‰‡
                for candidate in candidates:
                    url = candidate.get("url", "")
                    if url and url not in images:
                        images.append(url)
        
        if "video_versions" in post and post["video_versions"]:
            for video in post["video_versions"]:
                url = video.get("url", "")
                if url and url not in videos:
                    videos.append(url)
        
        # è¼ªæ’­åª’é«”
        if "carousel_media" in post and post["carousel_media"]:
            for item in post["carousel_media"]:
                if "image_versions2" in item and item["image_versions2"]:
                    candidates = item["image_versions2"].get("candidates", [])
                    for candidate in candidates:
                        url = candidate.get("url", "")
                        if url and url not in images:
                            images.append(url)
                
                if "video_versions" in item and item["video_versions"]:
                    for video in item["video_versions"]:
                        url = video.get("url", "")
                        if url and url not in videos:
                            videos.append(url)
        
        # æ§‹å»ºçµæœ
        result = {
            "pk": pk,
            "code": code,
            "username": username,
            "content": content,
            "like_count": like_count,
            "comment_count": comment_count,
            "repost_count": repost_count,
            "share_count": share_count,
            "images": images,
            "videos": videos,
            "url": f"https://www.threads.com/@{username}/post/{code}" if username and code else "",
            "extracted_at": datetime.now().isoformat(),
            "raw_post_data": post
        }
        
        # é¡¯ç¤ºçµæœ
        print(f"      ğŸ“„ PK: {pk}")
        print(f"      ğŸ‘¤ ç”¨æˆ¶: @{username}")
        print(f"      ğŸ“ å…§å®¹: {len(content)} å­—ç¬¦")
        print(f"      ğŸ‘ è®šæ•¸: {like_count}")
        print(f"      ğŸ’¬ ç•™è¨€: {comment_count}")
        print(f"      ğŸ”„ è½‰ç™¼: {repost_count}")
        print(f"      ğŸ“¤ åˆ†äº«: {share_count}")
        print(f"      ğŸ–¼ï¸ åœ–ç‰‡: {len(images)} å€‹")
        print(f"      ğŸ¥ å½±ç‰‡: {len(videos)} å€‹")
        
        if content:
            print(f"      ğŸ“„ å…§å®¹é è¦½: {content[:100]}...")
        
        # ä¿å­˜çµæœ
        result_file = Path(f"final_extraction_result_{datetime.now().strftime('%H%M%S')}.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"      ğŸ“ å®Œæ•´çµæœå·²ä¿å­˜: {result_file}")
        
        return result

async def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ æœ€çµ‚å®Œæ•´çš„å…§å®¹æå–å™¨")
    
    auth_file = get_auth_file_path()
    if not auth_file.exists():
        print(f"âŒ èªè­‰æª”æ¡ˆ {auth_file} ä¸å­˜åœ¨ã€‚è«‹å…ˆåŸ·è¡Œ save_auth.pyã€‚")
        return
    
    extractor = FinalContentExtractor()
    
    # ç¬¬ä¸€æ­¥ï¼šæ””æˆªè¨ˆæ•¸æŸ¥è©¢
    print(f"\nğŸ“¡ ç¬¬ä¸€æ­¥ï¼šæ””æˆªè¨ˆæ•¸æŸ¥è©¢...")
    captured = await extractor.intercept_counts_query()
    
    if not captured:
        print(f"\nğŸ˜ æœªèƒ½æ””æˆªåˆ°è¨ˆæ•¸æŸ¥è©¢")
        return
    
    # ç¬¬äºŒæ­¥ï¼šæå–å®Œæ•´æ•¸æ“š
    print(f"\nğŸ¯ ç¬¬äºŒæ­¥ï¼šæå–å®Œæ•´æ•¸æ“š...")
    result = await extractor.extract_complete_post_data()
    
    if result:
        print(f"\nğŸ‰ æå–æˆåŠŸï¼")
        print(f"ğŸ’¡ é€™å€‹æ–¹æ³•å¯ä»¥:")
        print(f"   âœ… ç²å–å®Œæ•´çš„è¨ˆæ•¸æ•¸æ“š (è®šæ•¸ã€ç•™è¨€ã€è½‰ç™¼ã€åˆ†äº«)")
        print(f"   âœ… ç²å–å®Œæ•´çš„å…§å®¹æ–‡å­—")
        print(f"   âœ… ç²å–æ‰€æœ‰åœ–ç‰‡å’Œå½±ç‰‡ URL")
        print(f"   âœ… ç²å–ç”¨æˆ¶ä¿¡æ¯")
        print(f"   âœ… ä½¿ç”¨ç©©å®šçš„è¨ˆæ•¸æŸ¥è©¢API")
        print(f"\nğŸ”§ ç¾åœ¨å¯ä»¥å°‡æ­¤æ–¹æ³•æ•´åˆåˆ°ä¸»çˆ¬èŸ²ä¸­ï¼")
    else:
        print(f"\nğŸ˜ æå–å¤±æ•—")

if __name__ == "__main__":
    asyncio.run(main())