好的！讓我檢查URL收集階段是否可以單獨使用：
Read file: agents/playwright_crawler/playwright_logic.py

Read file: agents/playwright_crawler/extractors/url_extractor.py

Read file: agents/playwright_crawler/extractors/url_extractor.py

Read file: agents/playwright_crawler/helpers/scrolling.py

Ran tool

Read file: agents/playwright_crawler/playwright_logic.py

Ran tool

Read file: agents/playwright_crawler/helpers/scrolling.py

## 🔍 **URL收集階段分析結果**

根據對代碼的檢查，我發現：

### ✅ **URL收集階段完全可以單獨使用！**

## 📋 **現有的URL收集組件**

### **1. 傳統URL提取器** (`url_extractor.py`)
```python
# 簡單直接，最少依賴
async def get_ordered_post_urls_from_page(page: Page, username: str, max_posts: int) -> List[str]
```

**特點：**
- ✅ 獨立性高，依賴最少
- ✅ 簡單滾動 + DOM提取
- ✅ URL標準化和去重
- ✅ 保持時間順序

### **2. 智能滾動模式** (`playwright_logic.py`)
```python
# 高級功能，支持增量爬取
_smart_scroll_new_mode()   # NEW模式：補足新貼文
_smart_scroll_hist_mode()  # HIST模式：歷史回溯
```

**特點：**
- ✅ 錨點檢測（增量爬取）
- ✅ 動態停止條件
- ✅ 支持大量貼文收集

### **3. DOM級收集器** (`scrolling.py`)
```python
# 核心收集邏輯
collect_urls_from_dom()    # 從DOM提取URLs
extract_current_post_ids() # 提取當前頁面ID
```

## 💡 **純URL收集器實現方案**

### **方案A：輕量級URL收集器**
基於現有 `URLExtractor`，最簡單直接：

```python
# 純URL收集，無需數據庫、無需PostMetrics
async def collect_urls_only(username: str, max_posts: int) -> List[str]:
    # 只需要: playwright + 基本邏輯
    page = await context.new_page()
    urls = await url_extractor.get_ordered_post_urls_from_page(page, username, max_posts)
    return urls
```

### **方案B：進階URL收集器**
包含智能滾動和增量檢測：

```python
# 支持錨點、增量收集
async def smart_collect_urls(username: str, mode: str, anchor_id: str = None) -> List[str]:
    # 使用智能滾動邏輯
    # 支持NEW/HIST模式
    # 錨點檢測功能
```

## 🔧 **依賴關係分析**

### **最小依賴（方案A）：**
```
playwright_crawler/
├── extractors/url_extractor.py    # ✅ 核心組件
└── 依賴：
    ├── playwright.async_api        # ✅ 必需
    ├── asyncio, logging           # ✅ 標準庫
    └── 無其他依賴                 # ✅ 獨立性高
```

### **完整功能（方案B）：**
```
playwright_crawler/
├── helpers/scrolling.py           # ✅ 智能滾動
├── playwright_logic.py (部分)     # ✅ 智能模式
└── 依賴：
    ├── 需要existing_post_ids     # ⚠️ 可選，可設為空集合
    ├── 需要anchor_post_id        # ⚠️ 可選，可設為None
    └── 無數據庫依賴              # ✅ 可純內存操作
```

## 🎯 **結論**

### ✅ **完全可行！**

1. **現有組件支持**：URL收集階段已經被很好地模塊化
2. **依賴關係清晰**：核心邏輯獨立於數據庫和PostMetrics
3. **多種實現選項**：從簡單到進階都支持

### **建議實現**

**需要我為你創建一個純URL收集器嗎？**

可以選擇：
- **A. 簡單版**：基於現有URLExtractor，5分鐘實現
- **B. 完整版**：包含智能滾動，支持增量收集

你希望哪種？還是想先看看現有組件的使用方式？