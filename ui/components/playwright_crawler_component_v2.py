"""
Playwright çˆ¬èŸ²çµ„ä»¶ - V2 ç‰ˆæœ¬
æ¡ç”¨èˆ‡ crawler_component_refactored.py ç›¸åŒçš„æª”æ¡ˆè®€å¯«æ¶æ§‹
"""

import streamlit as st
import httpx
import json
import os
import uuid
import tempfile
import threading
import time
import requests
import shutil
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
import asyncio

from .playwright_utils import PlaywrightUtils
from .playwright_database_handler import PlaywrightDatabaseHandler
from .playwright_user_manager import PlaywrightUserManager

class PlaywrightCrawlerComponentV2:
    def __init__(self):
        self.agent_url = "http://localhost:8006/v1/playwright/crawl"
        self.sse_url = "http://localhost:8000/stream"
        
        # åˆå§‹åŒ–å­çµ„ä»¶
        self.db_handler = PlaywrightDatabaseHandler()
        self.user_manager = PlaywrightUserManager()
        
        # ä½¿ç”¨çµ±ä¸€çš„é…ç½®ç®¡ç†
        from common.config import get_auth_file_path
        self.auth_file_path = get_auth_file_path(from_project_root=True)
    
    # ---------- 1. é€²åº¦æª”æ¡ˆè®€å¯«å·¥å…· ----------
    def _write_progress(self, path: str, data: Dict[str, Any]):
        """
        ç·šç¨‹å®‰å…¨å¯«å…¥é€²åº¦ï¼š
        - ä½¿ç”¨ tempfile + shutil.move å¯¦ç¾åŸå­å¯«å…¥ï¼Œé¿å…è®€å–åˆ°ä¸å®Œæ•´çš„æª”æ¡ˆã€‚
        """
        old: Dict[str, Any] = {}
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    old = json.load(f)
            except Exception:
                pass

        # åˆä½µé‚è¼¯
        stage_priority = {
            "initialization": 0, "fetch_start": 1, "post_parsed": 2,
            "batch_parsed": 3, "fill_views_start": 4, "fill_views_completed": 5,
            "api_completed": 6, "completed": 7, "error": 8
        }
        old_stage = old.get("stage", "")
        new_stage = data.get("stage", old_stage)
        if stage_priority.get(new_stage, 0) < stage_priority.get(old_stage, 0):
            data.pop("stage", None)

        old.update(data)

        # åŸå­å¯«å…¥
        tmp_fd, tmp_path = tempfile.mkstemp(suffix=".json")
        try:
            with os.fdopen(tmp_fd, "w", encoding="utf-8") as f:
                json.dump(old, f, ensure_ascii=False, indent=2)
            shutil.move(tmp_path, path)
        except Exception:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
            raise

    def _read_progress(self, path: str) -> Dict[str, Any]:
        """è®€å–é€²åº¦æª”æ¡ˆ"""
        if not os.path.exists(path):
            return {}
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    
    def _cleanup_invalid_file_references(self):
        """æ¸…ç†ç„¡æ•ˆçš„æ–‡ä»¶å¼•ç”¨ï¼Œé¿å… MediaFileStorageError"""
        try:
            # æ¸…ç†å¯èƒ½å°è‡´ MediaFileStorageError çš„èˆŠæ–‡ä»¶å¼•ç”¨
            keys_to_check = list(st.session_state.keys())
            for key in keys_to_check:
                # è·³éé‡è¦çš„ç‹€æ…‹
                if key in ['playwright_results', 'playwright_crawl_status', 'show_playwright_history_analysis', 
                          'show_playwright_advanced_exports', 'playwright_results_saved']:
                    continue
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯æ–‡ä»¶ç›¸é—œçš„keyï¼Œä½†ä¿ç•™ç•¶å‰ä¸Šå‚³å™¨
                if ('file' in key.lower() or 'upload' in key.lower()) and key != "playwright_csv_uploader_v2":
                    try:
                        # å˜—è©¦è¨ªå•é€™å€‹å€¼ï¼Œå¦‚æœæœ‰å•é¡Œå°±åˆªé™¤
                        value = st.session_state[key]
                        # å¦‚æœæ˜¯æ–‡ä»¶å°è±¡ä¸”å·²ç¶“ç„¡æ•ˆï¼Œæ¸…ç†å®ƒ
                        if hasattr(value, 'file_id') or str(value).startswith('UploadedFile'):
                            del st.session_state[key]
                    except:
                        # å¦‚æœè¨ªå•æ™‚å‡ºéŒ¯ï¼Œç›´æ¥åˆªé™¤
                        try:
                            del st.session_state[key]
                        except:
                            pass
        except Exception:
            # å¦‚æœæ¸…ç†éç¨‹å‡ºéŒ¯ï¼Œå¿½ç•¥
            pass
    
    # ---------- 2. ä¸»æ¸²æŸ“æ–¹æ³• ----------
    def render(self):
        """æ¸²æŸ“Playwrightçˆ¬èŸ²çµ„ä»¶"""
        # åˆå§‹åŒ–æ™‚æ¸…ç†ç„¡æ•ˆçš„æ–‡ä»¶å¼•ç”¨ï¼Œé¿å… MediaFileStorageError
        self._cleanup_invalid_file_references()
        
        st.header("ğŸ­ Playwright æ™ºèƒ½çˆ¬èŸ² V2")
        st.markdown("**åŸºæ–¼æª”æ¡ˆè®€å¯«æ¶æ§‹ + ç‹€æ…‹æ©Ÿé©…å‹•çš„å¯¦æ™‚é€²åº¦é¡¯ç¤º**")
        
        # æª¢æŸ¥èªè­‰æ–‡ä»¶
        if not self._check_auth_file():
            st.error("âŒ æ‰¾ä¸åˆ°èªè­‰æª”æ¡ˆ")
            st.info("è«‹å…ˆåŸ·è¡Œ: `python tests/threads_fetch/save_auth.py` ä¾†ç”¢ç”Ÿèªè­‰æª”æ¡ˆ")
            return
        
        st.success("âœ… èªè­‰æª”æ¡ˆå·²å°±ç·’")
        
        # åˆå§‹åŒ–ç‹€æ…‹
        if "playwright_crawl_status" not in st.session_state:
            st.session_state.playwright_crawl_status = "idle"
        
        # æ ¹æ“šç‹€æ…‹æ¸²æŸ“ä¸åŒå…§å®¹
        if st.session_state.playwright_crawl_status == "idle":
            self._render_setup()
        elif st.session_state.playwright_crawl_status == "running":
            self._render_progress()
        elif st.session_state.playwright_crawl_status == "completed":
            self._render_results()
        elif st.session_state.playwright_crawl_status == "error":
            self._render_error()
    
    def _render_setup(self):
        """æ¸²æŸ“è¨­å®šé é¢"""
        # åƒæ•¸è¨­å®šå€åŸŸ - ä¿®å¾©ä½ˆå±€å•é¡Œ
        col_settings, col_stats = st.columns([1, 1])
        
        with col_settings:
            st.subheader("âš™ï¸ çˆ¬å–è¨­å®š")
            username = st.text_input(
                "ç›®æ¨™å¸³è™Ÿ", 
                value="gvmonthly",
                help="è¦çˆ¬å–çš„Threadså¸³è™Ÿç”¨æˆ¶å",
                key="playwright_username_v2"
            )
            
            max_posts = st.number_input(
                "çˆ¬å–æ•¸é‡", 
                min_value=1, 
                max_value=500, 
                value=50,
                help="è¦çˆ¬å–çš„è²¼æ–‡æ•¸é‡",
                key="playwright_max_posts_v2"
            )
            
            # çˆ¬å–æ¨¡å¼è¨­å®š
            crawl_mode = st.radio(
                "ğŸ”„ çˆ¬å–æ¨¡å¼",
                ["å¢é‡æ¨¡å¼", "å…¨é‡æ¨¡å¼"],
                index=0,  # é è¨­å¢é‡æ¨¡å¼
                help="å¢é‡æ¨¡å¼ï¼šåªçˆ¬å–æ–°è²¼æ–‡ï¼Œè·³éå·²å­˜åœ¨çš„è²¼æ–‡ï½œå…¨é‡æ¨¡å¼ï¼šé‡æ–°çˆ¬å–æ‰€æœ‰è²¼æ–‡ï¼Œæ›´æ–°ç¾æœ‰è³‡æ–™",
                key="playwright_crawl_mode_v2",
                horizontal=True
            )
            
            if crawl_mode == "å¢é‡æ¨¡å¼":
                st.info("ğŸ’¡ å¢é‡æ¨¡å¼ï¼šæ™ºèƒ½è·³éè³‡æ–™åº«ä¸­å·²å­˜åœ¨çš„è²¼æ–‡ï¼Œåªæ”¶é›†æ–°å…§å®¹")
            else:
                st.warning("âš ï¸ å…¨é‡æ¨¡å¼ï¼šå°‡é‡æ–°çˆ¬å–æ‰€æœ‰è²¼æ–‡ï¼Œå¯èƒ½æœƒç²å¾—é‡è¤‡æ•¸æ“šï¼Œé©ç”¨æ–¼è³‡æ–™æ›´æ–°éœ€æ±‚")
            
            # å»é‡è¨­å®š
            enable_deduplication = st.checkbox(
                "ğŸ§¹ å•Ÿç”¨å»é‡åŠŸèƒ½",
                value=False,
                help="é–‹å•Ÿæ™‚æœƒéæ¿¾ç›¸ä¼¼å…§å®¹çš„é‡è¤‡è²¼æ–‡ï¼Œä¿ç•™ä¸»è²¼æ–‡ï¼›é—œé–‰æ™‚ä¿ç•™æ‰€æœ‰æŠ“å–åˆ°çš„è²¼æ–‡",
                key="playwright_enable_dedup_v2"
            )
            
            if enable_deduplication:
                st.info("ğŸ’¡ å°‡æ ¹æ“šè§€çœ‹æ•¸ã€äº’å‹•æ•¸ã€å…§å®¹é•·åº¦ç­‰ç¶­åº¦ä¿ç•™ä¸»è²¼æ–‡ï¼Œéæ¿¾å›æ‡‰")
            else:
                st.warning("âš ï¸ é—œé–‰å»é‡å¯èƒ½æœƒç²å¾—å¤§é‡ç›¸ä¼¼å…§å®¹ï¼Œå»ºè­°åƒ…åœ¨ç‰¹æ®Šéœ€æ±‚æ™‚ä½¿ç”¨")
            
            # æ§åˆ¶æŒ‰éˆ•å€åŸŸ
            col1, col2, col3 = st.columns([1, 1, 2])
            
            with col1:
                if st.button("ğŸš€ é–‹å§‹çˆ¬å–", key="start_playwright_v2"):
                    # å•Ÿå‹•çˆ¬èŸ²
                    is_incremental = (crawl_mode == "å¢é‡æ¨¡å¼")
                    self._start_crawling(username, max_posts, enable_deduplication, is_incremental)
                    
            with col2:
                try:
                    uploaded_file = st.file_uploader(
                        "ğŸ“ è¼‰å…¥CSVæ–‡ä»¶", 
                        type=['csv'], 
                        key="playwright_csv_uploader_v2",
                        help="ä¸Šå‚³ä¹‹å‰å°å‡ºçš„CSVæ–‡ä»¶ä¾†æŸ¥çœ‹çµæœ"
                    )
                    if uploaded_file is not None:
                        self._load_csv_file(uploaded_file)
                except Exception as e:
                    # å¦‚æœæ–‡ä»¶ä¸Šå‚³å™¨å‡ºéŒ¯ï¼Œæ¸…ç†ä¸¦é‡æ–°é¡¯ç¤º
                    if "MediaFileStorageError" in str(e) or "file_id" in str(e):
                        st.warning("âš ï¸ åµæ¸¬åˆ°èˆŠçš„æ–‡ä»¶å¼•ç”¨ï¼Œæ­£åœ¨æ¸…ç†...")
                        # æ¸…ç†ç›¸é—œç‹€æ…‹
                        for key in list(st.session_state.keys()):
                            if 'uploader' in key.lower() or 'file' in key.lower():
                                try:
                                    del st.session_state[key]
                                except:
                                    pass
                        st.rerun()
                    else:
                        st.error(f"âŒ æ–‡ä»¶ä¸Šå‚³å™¨éŒ¯èª¤: {e}")
            
            with col3:
                if 'playwright_results' in st.session_state:
                    if st.button("ğŸ—‘ï¸ æ¸…é™¤çµæœ", key="clear_playwright_results_v2", help="æ¸…é™¤ç•¶å‰é¡¯ç¤ºçš„çµæœ"):
                        self._clear_results()
                
        with col_stats:
            col_title, col_refresh = st.columns([3, 1])
            with col_title:
                st.subheader("ğŸ“Š è³‡æ–™åº«çµ±è¨ˆ")
            with col_refresh:
                if st.button("ğŸ”„ åˆ·æ–°", key="refresh_playwright_db_stats_v2", help="åˆ·æ–°è³‡æ–™åº«çµ±è¨ˆä¿¡æ¯", type="secondary"):
                    if 'playwright_db_stats_cache' in st.session_state:
                        del st.session_state.playwright_db_stats_cache
                    st.success("ğŸ”„ æ­£åœ¨åˆ·æ–°çµ±è¨ˆ...")
                    st.rerun()
            
            self._display_database_stats()
        
        # é¡¯ç¤ºå·²è¼‰å…¥çš„ CSV çµæœï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if 'playwright_results' in st.session_state:
            st.divider()
            results = st.session_state.playwright_results
            st.info(f"ğŸ“ å·²è¼‰å…¥ CSV æ–‡ä»¶ï¼š{results.get('total_processed', 0)} ç­†è¨˜éŒ„")
            
            col_view, col_clear = st.columns([1, 1])
            with col_view:
                if st.button("ğŸ‘ï¸ æŸ¥çœ‹è¼‰å…¥çš„çµæœ", key="view_loaded_results"):
                    st.session_state.playwright_crawl_status = "completed"
                    st.rerun()
            
            with col_clear:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤è¼‰å…¥çš„çµæœ", key="clear_loaded_results"):
                    if 'playwright_results' in st.session_state:
                        del st.session_state.playwright_results
                    st.rerun()
    
    def _render_progress(self):
        """æ¸²æŸ“é€²åº¦é é¢ï¼ˆæ–°ç‰ˆæ¶æ§‹ï¼‰"""
        progress_file = st.session_state.get('playwright_progress_file', '')
        
        # -- æ•¸æ“šæ›´æ–°é‚è¼¯ --
        if progress_file and os.path.exists(progress_file):
            progress_data = self._read_progress(progress_file)
            
            if progress_data:
                # ç¸½æ˜¯ä»¥æœ€æ–°æª”æ¡ˆå…§å®¹æ›´æ–° session state
                st.session_state.playwright_progress = progress_data.get("progress", 0.0)
                st.session_state.playwright_current_work = progress_data.get("current_work", "")
                
                # æª¢æŸ¥æ˜¯å¦é”åˆ°éœ€è¦åˆ‡æ›é é¢çš„æœ€çµ‚ç‹€æ…‹
                stage = progress_data.get("stage")
                if stage in ("api_completed", "completed"):
                    st.session_state.playwright_crawl_status = "completed"
                    st.session_state.playwright_final_data = progress_data.get("final_data", {})
                    st.rerun() # åˆ‡æ›åˆ°çµæœé é¢
                elif stage == "error":
                    st.session_state.playwright_crawl_status = "error"
                    st.session_state.playwright_error_msg = progress_data.get("error", "æœªçŸ¥éŒ¯èª¤")
                    st.rerun() # åˆ‡æ›åˆ°éŒ¯èª¤é é¢

        # -- UI é¡¯ç¤ºé‚è¼¯ --
        target = st.session_state.get('playwright_target', {})
        username = target.get('username', 'unknown')
        progress = st.session_state.get('playwright_progress', 0.0)
        current_work = st.session_state.get('playwright_current_work', '')

        st.info(f"ğŸ”„ æ­£åœ¨çˆ¬å– @{username} çš„è²¼æ–‡...")
        st.progress(max(0.0, min(1.0, progress)), text=f"{progress:.1%} - {current_work}")
        
        # é¡¯ç¤ºè©³ç´°éšæ®µä¿¡æ¯
        if progress_file and os.path.exists(progress_file):
            progress_data = self._read_progress(progress_file)
            if progress_data:
                stage = progress_data.get("stage", "unknown")
                stage_names = {
                    # åˆå§‹éšæ®µ
                    "initialization": "ğŸ”§ åˆå§‹åŒ–çˆ¬èŸ²ç’°å¢ƒ",
                    "auth_loading": "ğŸ” è¼‰å…¥èªè­‰æª”æ¡ˆ",
                    "request_preparation": "ğŸ“‹ æº–å‚™APIè«‹æ±‚",
                    "api_request": "ğŸš€ ç™¼é€APIè«‹æ±‚",
                    "api_processing": "â³ APIè™•ç†ä¸­",
                    
                    # Playwright è™•ç†éšæ®µ
                    "browser_launch": "ğŸŒ å•Ÿå‹•ç€è¦½å™¨",
                    "page_navigation": "ğŸ§­ å°èˆªåˆ°ç”¨æˆ¶é é¢",
                    "page_loading": "â³ é é¢è¼‰å…¥ä¸­",
                    "scroll_start": "ğŸ“œ é–‹å§‹æ™ºèƒ½æ»¾å‹•",
                    "url_collection": "ğŸ”— æ”¶é›†è²¼æ–‡URLs",
                    "url_processing": "ğŸ”„ è™•ç†URLs",
                    
                    # æ•¸æ“šè£œé½Šéšæ®µ
                    "fill_details_start": "ğŸ” é–‹å§‹è£œé½Šè©³ç´°æ•¸æ“š",
                    "fill_details_progress": "ğŸ“ è£œé½Šè²¼æ–‡å…§å®¹å’Œäº’å‹•",
                    "fill_views_start": "ğŸ‘ï¸ é–‹å§‹è£œé½Šè§€çœ‹æ•¸",
                    "fill_views_progress": "ğŸ“Š è£œé½Šè§€çœ‹æ•¸æ“š",
                    "deduplication": "ğŸ§¹ å»é‡è™•ç†",
                    
                    # å®Œæˆéšæ®µ
                    "response_processing": "ğŸ“¦ è™•ç†APIéŸ¿æ‡‰",
                    "completed": "ğŸ‰ çˆ¬å–å®Œæˆ",
                    "error": "âŒ ç™¼ç”ŸéŒ¯èª¤"
                }
                stage_display = stage_names.get(stage, f"ğŸ”„ {stage}")
                
                # æ ¹æ“šé€²åº¦é¡¯ç¤ºä¸åŒçš„é¡è‰²å’Œæ¨£å¼
                if progress >= 0.9:
                    st.success(f"**ç•¶å‰éšæ®µ**: {stage_display}")
                elif progress >= 0.5:
                    st.info(f"**ç•¶å‰éšæ®µ**: {stage_display}")
                elif stage == "error":
                    st.error(f"**ç•¶å‰éšæ®µ**: {stage_display}")
                else:
                    st.warning(f"**ç•¶å‰éšæ®µ**: {stage_display}")
                
                # é¡¯ç¤ºé€²åº¦éšæ®µåœ–
                self._render_progress_stages(progress, stage)
                
                # é¡¯ç¤ºæ—¥èªŒ
                log_messages = progress_data.get("log_messages", [])
                if log_messages:
                    with st.expander("ğŸ“‹ çˆ¬å–éç¨‹æ—¥èªŒ", expanded=True):
                        recent_logs = log_messages[-30:] if len(log_messages) > 30 else log_messages
                        st.code('\n'.join(recent_logs), language='text')
        
        st.info("â±ï¸ é€²åº¦å°‡è‡ªå‹•æ›´æ–°ï¼Œç„¡éœ€æ‰‹å‹•æ“ä½œã€‚")

        # -- è‡ªå‹•åˆ·æ–°æ©Ÿåˆ¶ --
        # åªè¦é‚„åœ¨ running ç‹€æ…‹ï¼Œå°±å®‰æ’ä¸€å€‹å»¶é²åˆ·æ–°
        if st.session_state.playwright_crawl_status == 'running':
            time.sleep(1) # é™ä½åˆ·æ–°é »ç‡
            st.rerun()
    
    def _render_results(self):
        """æ¸²æŸ“çµæœé é¢"""
        st.subheader("âœ… çˆ¬å–å®Œæˆ")
        
        final_data = st.session_state.get('playwright_final_data', {})
        if not final_data:
            st.warning("æ²’æœ‰çˆ¬å–åˆ°æ•¸æ“š")
            if st.button("ğŸ”™ è¿”å›è¨­å®š"):
                st.session_state.playwright_crawl_status = "idle"
                # é‡ç½®ä¿å­˜æ¨™è¨˜ï¼Œæº–å‚™ä¸‹æ¬¡çˆ¬å–
                st.session_state.playwright_results_saved = False
                st.rerun()
            return
        
        # è™•ç†ä¸¦é¡¯ç¤ºçµæœ
        try:
            # è½‰æ›çµæœæ ¼å¼
            converted_results = PlaywrightUtils.convert_playwright_results(final_data)
            target = st.session_state.get('playwright_target', {})
            converted_results["target_username"] = target.get('username', 'unknown')
            
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“ä¿å­˜éï¼Œé¿å…é‡è¤‡ä¿å­˜
            if not st.session_state.get('playwright_results_saved', False):
                # ä¿å­˜JSONæ–‡ä»¶
                json_file_path = PlaywrightUtils.save_json_results(converted_results)
                st.session_state.playwright_results_saved = True  # æ¨™è¨˜ç‚ºå·²ä¿å­˜
            else:
                # å¦‚æœå·²ç¶“ä¿å­˜éï¼Œä¸å†é‡æ–°ä¿å­˜ï¼Œä½†ä»éœ€è¦é¡¯ç¤ºçµæœ
                json_file_path = None
            
            # è‡ªå‹•ä¿å­˜åˆ°è³‡æ–™åº«
            try:
                asyncio.run(self.db_handler.save_to_database_async(converted_results))
                converted_results["database_saved"] = True
                converted_results["database_saved_count"] = len(converted_results.get("results", []))
                st.success(f"âœ… å·²è‡ªå‹•ä¿å­˜ {converted_results['database_saved_count']} å€‹è²¼æ–‡åˆ°è³‡æ–™åº«")
            except Exception as db_error:
                converted_results["database_saved"] = False
                converted_results["database_saved_count"] = 0
                st.warning(f"âš ï¸ è‡ªå‹•ä¿å­˜åˆ°è³‡æ–™åº«å¤±æ•—: {db_error}")
                st.info("ğŸ’¡ æ‚¨å¯ä»¥ç¨å¾Œä½¿ç”¨ 'ğŸ’¾ å‚™ç”¨ä¿å­˜' æŒ‰éˆ•é‡è©¦")
            
            # é¡¯ç¤ºçµæœ
            self._show_results(converted_results)
            
        except Exception as e:
            st.error(f"âŒ è™•ç†çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # è¿”å›æŒ‰éˆ•
        if st.button("ğŸ”™ è¿”å›è¨­å®š"):
            st.session_state.playwright_crawl_status = "idle"
            st.rerun()
    
    def _render_error(self):
        """æ¸²æŸ“éŒ¯èª¤é é¢"""
        st.subheader("âŒ çˆ¬å–å¤±æ•—")
        
        error_msg = st.session_state.get('playwright_error_msg', 'æœªçŸ¥éŒ¯èª¤')
        st.error(f"éŒ¯èª¤ä¿¡æ¯: {error_msg}")
        
        # é¡¯ç¤ºè©³ç´°éŒ¯èª¤ä¿¡æ¯
        progress_file = st.session_state.get('playwright_progress_file', '')
        if progress_file and os.path.exists(progress_file):
            progress_data = self._read_progress(progress_file)
            if progress_data:
                st.subheader("ğŸ” è©³ç´°éŒ¯èª¤ä¿¡æ¯")
                
                # é¡¯ç¤ºéŒ¯èª¤è©³æƒ…
                if 'error' in progress_data:
                    st.code(progress_data['error'], language='text')
                
                # é¡¯ç¤ºæ—¥èªŒ
                log_messages = progress_data.get("log_messages", [])
                if log_messages:
                    with st.expander("ğŸ“‹ éŒ¯èª¤æ—¥èªŒ", expanded=True):
                        recent_logs = log_messages[-20:] if len(log_messages) > 20 else log_messages
                        st.code('\n'.join(recent_logs), language='text')
                
                # é¡¯ç¤ºå®Œæ•´é€²åº¦æ•¸æ“š
                with st.expander("ğŸ”§ èª¿è©¦ä¿¡æ¯", expanded=False):
                    st.json(progress_data)
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”™ è¿”å›è¨­å®š"):
                # æ¸…ç†é€²åº¦æª”æ¡ˆ
                if progress_file and os.path.exists(progress_file):
                    try:
                        os.remove(progress_file)
                    except:
                        pass
                st.session_state.playwright_crawl_status = "idle"
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ é‡è©¦"):
                # æ¸…ç†é€²åº¦æª”æ¡ˆ
                if progress_file and os.path.exists(progress_file):
                    try:
                        os.remove(progress_file)
                    except:
                        pass
                st.session_state.playwright_crawl_status = "idle"
                st.rerun()
    
    # ---------- 3. çˆ¬èŸ²å•Ÿå‹•é‚è¼¯ ----------
    def _start_crawling(self, username: str, max_posts: int, enable_deduplication: bool = True, is_incremental: bool = True):
        """å•Ÿå‹•çˆ¬èŸ²"""
        # è¨­å®šç›®æ¨™åƒæ•¸
        st.session_state.playwright_target = {
            'username': username,
            'max_posts': max_posts,
            'enable_deduplication': enable_deduplication,
            'is_incremental': is_incremental
        }
        
        # é‡ç½®ä¿å­˜æ¨™è¨˜ï¼Œå…è¨±æ–°çš„çˆ¬å–çµæœè¢«ä¿å­˜
        st.session_state.playwright_results_saved = False
        
        # å‰µå»ºé€²åº¦æª”æ¡ˆ
        task_id = str(uuid.uuid4())
        progress_file = f"temp_playwright_progress_{task_id}.json"
        st.session_state.playwright_progress_file = progress_file
        st.session_state.playwright_task_id = task_id
        
        # åˆå§‹åŒ–é€²åº¦æª”æ¡ˆ
        self._write_progress(progress_file, {
            "progress": 0.0,
            "stage": "initialization",
            "current_work": "æ­£åœ¨å•Ÿå‹•...",
            "log_messages": ["ğŸš€ çˆ¬èŸ²ä»»å‹™å·²å•Ÿå‹•..."]
        })
        
        # å•Ÿå‹•èƒŒæ™¯ç·šç¨‹
        task_thread = threading.Thread(
            target=self._background_crawler_worker,
            args=(username, max_posts, enable_deduplication, is_incremental, task_id, progress_file),
            daemon=True
        )
        task_thread.start()
        
        # åˆ‡æ›åˆ°é€²åº¦é é¢
        st.session_state.playwright_crawl_status = "running"
        st.rerun()
    
    def _background_crawler_worker(self, username: str, max_posts: int, enable_deduplication: bool, is_incremental: bool, task_id: str, progress_file: str):
        """èƒŒæ™¯çˆ¬èŸ²å·¥ä½œç·šç¨‹ - åªå¯«æª”æ¡ˆï¼Œä¸åšä»»ä½• st.* æ“ä½œ"""
        try:
            # éšæ®µ1: åˆå§‹åŒ– (0-5%)
            self._log_to_file(progress_file, "ğŸ”§ åˆå§‹åŒ–çˆ¬èŸ²ç’°å¢ƒ...")
            self._update_progress_file(progress_file, 0.02, "initialization", "åˆå§‹åŒ–çˆ¬èŸ²ç’°å¢ƒ...")
            
            # éšæ®µ2: è®€å–èªè­‰ (5-10%)
            self._log_to_file(progress_file, "ğŸ” è®€å–èªè­‰æª”æ¡ˆ...")
            self._update_progress_file(progress_file, 0.05, "auth_loading", "è®€å–èªè­‰æª”æ¡ˆ...")
            
            try:
                with open(self.auth_file_path, "r", encoding="utf-8") as f:
                    auth_content = json.load(f)
                self._log_to_file(progress_file, f"âœ… èªè­‰æª”æ¡ˆè®€å–æˆåŠŸï¼ŒåŒ…å« {len(auth_content.get('cookies', []))} å€‹ cookies")
            except Exception as e:
                self._update_progress_file(progress_file, 0.0, "error", f"âŒ è®€å–èªè­‰æª”æ¡ˆå¤±æ•—: {e}")
                return
            
            # éšæ®µ3: æº–å‚™è«‹æ±‚ (10-15%)
            self._log_to_file(progress_file, "ğŸ“‹ æ§‹å»ºAPIè«‹æ±‚åƒæ•¸...")
            self._update_progress_file(progress_file, 0.10, "request_preparation", "æ§‹å»ºAPIè«‹æ±‚...")
            
            payload = {
                "username": username,
                "max_posts": max_posts,
                "auth_json_content": auth_content,
                "enable_deduplication": enable_deduplication,
                "incremental": is_incremental
            }
            
            self._log_to_file(progress_file, f"ğŸ“Š ç›®æ¨™ç”¨æˆ¶: @{username}")
            self._log_to_file(progress_file, f"ğŸ“ ç›®æ¨™è²¼æ–‡æ•¸: {max_posts}")
            self._log_to_file(progress_file, f"ğŸ”„ çˆ¬å–æ¨¡å¼: {'å¢é‡æ¨¡å¼' if is_incremental else 'å…¨é‡æ¨¡å¼'}")
            self._log_to_file(progress_file, f"ğŸ§¹ å»é‡åŠŸèƒ½: {'å•Ÿç”¨' if enable_deduplication else 'é—œé–‰'}")
            
            # éšæ®µ4: ç™¼é€è«‹æ±‚ (15-20%)
            self._log_to_file(progress_file, "ğŸš€ ç™¼é€APIè«‹æ±‚åˆ°Playwright Agent...")
            self._update_progress_file(progress_file, 0.15, "api_request", "ç™¼é€APIè«‹æ±‚...")
            
            # ç™¼é€ API è«‹æ±‚ä¸¦ç›£æ§é€²åº¦
            try:
                import httpx
                import time
                
                # é–‹å§‹APIè«‹æ±‚
                start_time = time.time()
                
                with httpx.Client(timeout=600.0) as client:
                    # éšæ®µ5: ç­‰å¾…éŸ¿æ‡‰ (20-25%)
                    self._log_to_file(progress_file, "â³ ç­‰å¾…Playwrightè™•ç†...")
                    self._update_progress_file(progress_file, 0.20, "api_processing", "Playwrightæ­£åœ¨è™•ç†...")
                    
                    # æ¨¡æ“¬é€²åº¦æ›´æ–°ï¼ˆå› ç‚ºæˆ‘å€‘ç„¡æ³•ç›´æ¥ç›£æ§Playwrightçš„å…§éƒ¨é€²åº¦ï¼‰
                    self._simulate_processing_progress(progress_file, start_time)
                    
                    response = client.post(self.agent_url, json=payload)
                    response.raise_for_status()
                    result = response.json()
                
                # éšæ®µ9: è™•ç†éŸ¿æ‡‰ (95-100%)
                self._log_to_file(progress_file, "âœ… APIè«‹æ±‚æˆåŠŸï¼Œæ­£åœ¨è™•ç†éŸ¿æ‡‰...")
                self._update_progress_file(progress_file, 0.95, "response_processing", "è™•ç†APIéŸ¿æ‡‰...")
                
                posts_count = len(result.get('posts', []))
                self._log_to_file(progress_file, f"ğŸ“¦ ç²å–åˆ° {posts_count} ç¯‡è²¼æ–‡")
                
                # éšæ®µ10: å®Œæˆ (100%)
                self._log_to_file(progress_file, "ğŸ‰ çˆ¬å–ä»»å‹™å®Œæˆï¼")
                self._update_progress_file(progress_file, 1.0, "completed", "çˆ¬å–å®Œæˆ", final_data=result)
                
            except Exception as e:
                error_msg = f"APIè«‹æ±‚å¤±æ•—: {e}"
                self._log_to_file(progress_file, f"âŒ {error_msg}")
                self._update_progress_file(progress_file, 0.0, "error", error_msg, error=str(e))
                
        except Exception as e:
            error_msg = f"èƒŒæ™¯ä»»å‹™å¤±æ•—: {e}"
            self._log_to_file(progress_file, f"âŒ {error_msg}")
            self._update_progress_file(progress_file, 0.0, "error", error_msg, error=str(e))
    
    def _simulate_processing_progress(self, progress_file: str, start_time: float):
        """æ¨¡æ“¬è™•ç†é€²åº¦æ›´æ–°"""
        import time
        import threading
        
        def update_progress():
            stages = [
                (0.25, "browser_launch", "å•Ÿå‹•ç€è¦½å™¨..."),
                (0.30, "page_navigation", "å°èˆªåˆ°ç”¨æˆ¶é é¢..."),
                (0.35, "page_loading", "ç­‰å¾…é é¢åŠ è¼‰..."),
                (0.40, "scroll_start", "é–‹å§‹æ™ºèƒ½æ»¾å‹•..."),
                (0.50, "url_collection", "æ”¶é›†è²¼æ–‡URLs..."),
                (0.60, "url_processing", "è™•ç†è²¼æ–‡URLs..."),
                (0.65, "fill_details_start", "é–‹å§‹è£œé½Šè©³ç´°æ•¸æ“š..."),
                (0.75, "fill_details_progress", "è£œé½Šè²¼æ–‡å…§å®¹å’Œäº’å‹•æ•¸æ“š..."),
                (0.80, "fill_views_start", "é–‹å§‹è£œé½Šè§€çœ‹æ•¸..."),
                (0.85, "fill_views_progress", "è£œé½Šè§€çœ‹æ•¸æ“š..."),
                (0.90, "deduplication", "å»é‡è™•ç†...")
            ]
            
            for progress, stage, description in stages:
                elapsed = time.time() - start_time
                # å¦‚æœAPIå·²ç¶“å®Œæˆï¼Œå°±ä¸å†æ›´æ–°æ¨¡æ“¬é€²åº¦
                if elapsed > 300:  # 5åˆ†é˜å¾Œåœæ­¢æ¨¡æ“¬
                    break
                    
                self._log_to_file(progress_file, f"ğŸ“Š {description}")
                self._update_progress_file(progress_file, progress, stage, description)
                time.sleep(8)  # æ¯8ç§’æ›´æ–°ä¸€æ¬¡
        
        # åœ¨èƒŒæ™¯ç·šç¨‹ä¸­é‹è¡Œé€²åº¦æ¨¡æ“¬
        progress_thread = threading.Thread(target=update_progress, daemon=True)
        progress_thread.start()
    
    def _render_progress_stages(self, progress: float, current_stage: str):
        """æ¸²æŸ“é€²åº¦éšæ®µåœ–"""
        st.subheader("ğŸ“Š çˆ¬å–æµç¨‹é€²åº¦")
        
        # å®šç¾©éšæ®µåŠå…¶é€²åº¦ç¯„åœ
        stages = [
            ("ğŸ”§", "åˆå§‹åŒ–", 0.0, 0.10, ["initialization", "auth_loading"]),
            ("ğŸš€", "ç™¼é€è«‹æ±‚", 0.10, 0.20, ["request_preparation", "api_request"]),
            ("ğŸŒ", "ç€è¦½å™¨è™•ç†", 0.20, 0.40, ["api_processing", "browser_launch", "page_navigation", "page_loading"]),
            ("ğŸ“œ", "æ™ºèƒ½æ»¾å‹•", 0.40, 0.60, ["scroll_start", "url_collection", "url_processing"]),
            ("ğŸ“", "è£œé½Šæ•¸æ“š", 0.60, 0.90, ["fill_details_start", "fill_details_progress", "fill_views_start", "fill_views_progress", "deduplication"]),
            ("âœ…", "å®Œæˆè™•ç†", 0.90, 1.00, ["response_processing", "completed"])
        ]
        
        # å‰µå»ºéšæ®µé¡¯ç¤º
        cols = st.columns(len(stages))
        
        for i, (icon, name, start_progress, end_progress, stage_names) in enumerate(stages):
            with cols[i]:
                # åˆ¤æ–·éšæ®µç‹€æ…‹
                if current_stage in stage_names:
                    # ç•¶å‰éšæ®µ - é»ƒè‰²é€²è¡Œä¸­
                    st.markdown(f"""
                    <div style='text-align: center; padding: 10px; background-color: #FFF3CD; border: 2px solid #FFC107; border-radius: 8px; margin: 5px 0;'>
                        <div style='font-size: 24px;'>{icon}</div>
                        <div style='font-weight: bold; color: #856404;'>{name}</div>
                        <div style='font-size: 12px; color: #856404;'>é€²è¡Œä¸­...</div>
                    </div>
                    """, unsafe_allow_html=True)
                elif progress > end_progress:
                    # å·²å®Œæˆéšæ®µ - ç¶ è‰²
                    st.markdown(f"""
                    <div style='text-align: center; padding: 10px; background-color: #D4EDDA; border: 2px solid #28A745; border-radius: 8px; margin: 5px 0;'>
                        <div style='font-size: 24px;'>{icon}</div>
                        <div style='font-weight: bold; color: #155724;'>{name}</div>
                        <div style='font-size: 12px; color: #155724;'>âœ“ å®Œæˆ</div>
                    </div>
                    """, unsafe_allow_html=True)
                elif progress >= start_progress:
                    # éƒ¨åˆ†å®Œæˆéšæ®µ - è—è‰²
                    stage_progress = (progress - start_progress) / (end_progress - start_progress)
                    st.markdown(f"""
                    <div style='text-align: center; padding: 10px; background-color: #CCE5FF; border: 2px solid #007BFF; border-radius: 8px; margin: 5px 0;'>
                        <div style='font-size: 24px;'>{icon}</div>
                        <div style='font-weight: bold; color: #004085;'>{name}</div>
                        <div style='font-size: 12px; color: #004085;'>{stage_progress:.0%}</div>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    # æœªé–‹å§‹éšæ®µ - ç°è‰²
                    st.markdown(f"""
                    <div style='text-align: center; padding: 10px; background-color: #F8F9FA; border: 2px solid #DEE2E6; border-radius: 8px; margin: 5px 0;'>
                        <div style='font-size: 24px; opacity: 0.5;'>{icon}</div>
                        <div style='font-weight: bold; color: #6C757D;'>{name}</div>
                        <div style='font-size: 12px; color: #6C757D;'>ç­‰å¾…ä¸­</div>
                    </div>
                    """, unsafe_allow_html=True)
        
        # é¡¯ç¤ºç•¶å‰éšæ®µçš„è©³ç´°ä¿¡æ¯
        for icon, name, start_progress, end_progress, stage_names in stages:
            if current_stage in stage_names:
                stage_progress = (progress - start_progress) / (end_progress - start_progress) if end_progress > start_progress else 1.0
                stage_progress = max(0.0, min(1.0, stage_progress))
                
                st.info(f"ğŸ“ **{name}** éšæ®µé€²åº¦: {stage_progress:.1%}")
                st.progress(stage_progress)
                break
    
    def _update_progress_file(self, progress_file: str, progress: float, stage: str, current_work: str, final_data: Dict = None, error: str = None):
        """æ›´æ–°é€²åº¦æª”æ¡ˆ"""
        data = {
            "progress": progress,
            "stage": stage,
            "current_work": current_work
        }
        if final_data:
            data["final_data"] = final_data
        if error:
            data["error"] = error
        
        self._write_progress(progress_file, data)
    
    def _log_to_file(self, progress_file: str, message: str):
        """å°‡æ—¥èªŒå¯«å…¥æª”æ¡ˆ"""
        timestamp = PlaywrightUtils.get_current_taipei_time().strftime("%H:%M:%S")
        log_msg = f"[{timestamp}] {message}"
        
        # è®€å–ç¾æœ‰æ•¸æ“š
        existing_data = self._read_progress(progress_file)
        log_messages = existing_data.get("log_messages", [])
        log_messages.append(log_msg)
        
        # é™åˆ¶æ—¥èªŒæ•¸é‡
        if len(log_messages) > 100:
            log_messages = log_messages[-100:]
        
        # å¯«å›æª”æ¡ˆ
        self._write_progress(progress_file, {"log_messages": log_messages})
    
    # ---------- 4. è¼”åŠ©æ–¹æ³• ----------
    def _check_auth_file(self):
        """æª¢æŸ¥èªè­‰æª”æ¡ˆæ˜¯å¦å­˜åœ¨"""
        return self.auth_file_path.exists()
    
    def _display_database_stats(self):
        """é¡¯ç¤ºè³‡æ–™åº«çµ±è¨ˆä¿¡æ¯"""
        # æª¢æŸ¥æ˜¯å¦æœ‰ç·©å­˜çš„çµ±è¨ˆä¿¡æ¯
        if 'playwright_db_stats_cache' in st.session_state:
            self._render_cached_stats(st.session_state.playwright_db_stats_cache)
            return
        
        # ç²å–çµ±è¨ˆä¿¡æ¯
        stats = self.db_handler.get_database_stats()
        
        if "error" in stats:
            st.error(f"âŒ è³‡æ–™åº«éŒ¯èª¤: {stats['error']}")
            return
        
        # ä¿å­˜åˆ°ç·©å­˜
        st.session_state.playwright_db_stats_cache = stats
        
        # æ¸²æŸ“çµ±è¨ˆä¿¡æ¯
        self._render_cached_stats(stats)
    
    def _render_cached_stats(self, stats):
        """æ¸²æŸ“ Playwright å°ˆç”¨ç·©å­˜çµ±è¨ˆä¿¡æ¯"""
        # é¡¯ç¤ºç¸½é«”çµ±è¨ˆ
        total_stats = stats.get("total_stats", {})
        if total_stats:
            st.info(f"""
            **ğŸ­ Playwright çˆ¬èŸ²çµ±è¨ˆ**
            - ğŸ“Š ç¸½è²¼æ–‡æ•¸: {total_stats.get('total_posts', 0):,}
            - ğŸ‘¥ å·²çˆ¬å–ç”¨æˆ¶: {total_stats.get('total_users', 0)} å€‹
            - ğŸ”„ ç¸½çˆ¬å–æ¬¡æ•¸: {total_stats.get('total_crawls', 0):,}
            - â° æœ€å¾Œæ´»å‹•: {str(total_stats.get('latest_activity', 'N/A'))[:16] if total_stats.get('latest_activity') else 'N/A'}
            """)
        
        # é¡¯ç¤ºç”¨æˆ¶çµ±è¨ˆ
        user_stats = stats.get("user_stats", [])
        if user_stats:
            st.write("**ğŸ‘¥ å„ç”¨æˆ¶çµ±è¨ˆ (Playwright):**")
            
            import pandas as pd
            df_data = []
            for user in user_stats:
                latest = str(user.get('latest_crawl', 'N/A'))[:16] if user.get('latest_crawl') else 'N/A'
                crawl_id = user.get('latest_crawl_id', 'N/A')[:12] + '...' if user.get('latest_crawl_id') else 'N/A'
                df_data.append({
                    "ç”¨æˆ¶å": f"@{user.get('username', 'N/A')}",
                    "è²¼æ–‡æ•¸": f"{user.get('post_count', 0):,}",
                    "æœ€å¾Œçˆ¬å–": latest,
                    "æœ€æ–°çˆ¬å–ID": crawl_id
                })
            
            if df_data:
                df = pd.DataFrame(df_data)
                st.dataframe(
                    df, 
                    use_container_width=True,
                    hide_index=True,
                    height=min(300, len(df_data) * 35 + 38)
                )
                
                st.caption("ğŸ’¡ é€™æ˜¯ Playwright çˆ¬èŸ²çš„å°ˆç”¨çµ±è¨ˆï¼Œèˆ‡ Realtime çˆ¬èŸ²åˆ†é›¢å„²å­˜")
                
                # æ·»åŠ ç”¨æˆ¶è³‡æ–™ç®¡ç†åŠŸèƒ½ï¼ˆæŠ˜ç–Šå½¢å¼ï¼‰
                st.markdown("---")
                self.user_manager.manage_user_data(user_stats)
        else:
            st.warning("ğŸ“ Playwright è³‡æ–™åº«ä¸­æš«ç„¡çˆ¬å–è¨˜éŒ„")
    
    def _show_results(self, results: Dict):
        """é¡¯ç¤ºçˆ¬å–çµæœï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼‰"""
        posts = results.get("results", [])
        
        st.subheader("ğŸ“Š çˆ¬å–çµæœ")
        
        if not isinstance(posts, list):
            st.error("âŒ çµæœæ ¼å¼éŒ¯èª¤ï¼Œè«‹é‡æ–°è¼‰å…¥")
            return
        
        if not posts:
            st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½•çµæœ")
            return
        
        # è©³ç´°çµ±è¨ˆ
        total_posts = len(posts)
        success_posts = sum(1 for r in posts if r.get('success', False))
        content_posts = sum(1 for r in posts if r.get('content'))
        views_posts = sum(1 for r in posts if r.get('views_count') or r.get('views'))
        
        # çµ±è¨ˆå€åŸŸ
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç¸½è²¼æ–‡æ•¸", total_posts)
        with col2:
            st.metric("æˆåŠŸç²å–", success_posts)
        with col3:
            st.metric("æœ‰å…§å®¹", content_posts)
        with col4:
            st.metric("æœ‰è§€çœ‹æ•¸", views_posts)
        
        # äº’å‹•çµ±è¨ˆ
        if views_posts > 0:
            st.subheader("ğŸ“ˆ äº’å‹•çµ±è¨ˆ")
            
            total_views = 0
            total_likes = 0
            total_comments = 0
            total_reposts = 0
            
            for r in posts:
                views = self._safe_int(r.get('views_count', r.get('views', 0)))
                likes = self._safe_int(r.get('likes_count', r.get('likes', 0)))
                comments = self._safe_int(r.get('comments_count', r.get('comments', 0)))
                reposts = self._safe_int(r.get('reposts_count', r.get('reposts', 0)))
                
                total_views += views
                total_likes += likes
                total_comments += comments
                total_reposts += reposts
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ç¸½è§€çœ‹æ•¸", f"{total_views:,}")
            with col2:
                st.metric("ç¸½æŒ‰è®šæ•¸", f"{total_likes:,}")
            with col3:
                st.metric("ç¸½ç•™è¨€æ•¸", f"{total_comments:,}")
            with col4:
                st.metric("ç¸½åˆ†äº«æ•¸", f"{total_reposts:,}")
        
        # è©³ç´°çµæœè¡¨æ ¼
        if st.checkbox("ğŸ“‹ é¡¯ç¤ºè©³ç´°çµæœ", key="show_playwright_detailed_results_v2"):
            # å…§å®¹é¡¯ç¤ºé¸é …
            col_option1, col_option2 = st.columns([1, 1])
            with col_option1:
                show_full_content = st.checkbox("ğŸ“– é¡¯ç¤ºå®Œæ•´å…§å®¹", key="show_full_content_v2", help="å‹¾é¸å¾Œå°‡é¡¯ç¤ºå®Œæ•´è²¼æ–‡å…§å®¹ï¼Œè€Œéé è¦½")
            
            st.write("**ğŸ“‹ è©³ç´°çµæœ:**")
            
            table_data = []
            for i, r in enumerate(posts, 1):
                # è™•ç† tags é¡¯ç¤º
                tags = r.get('tags', [])
                tags_display = ", ".join(tags) if tags else "ç„¡"
                
                # è™•ç†åœ–ç‰‡æ•¸é‡
                images = r.get('images', [])
                images_count = len(images) if images else 0
                
                # è™•ç†å½±ç‰‡æ•¸é‡
                videos = r.get('videos', [])
                videos_count = len(videos) if videos else 0
                
                # è™•ç†æ™‚é–“é¡¯ç¤º - è½‰æ›ç‚ºå°åŒ—æ™‚é–“
                created_at = r.get('created_at', '')
                if created_at:
                    taipei_created = PlaywrightUtils.convert_to_taipei_time(created_at)
                    created_at = taipei_created.isoformat() if taipei_created else created_at
                
                published_at = r.get('post_published_at', '')
                if published_at:
                    taipei_published = PlaywrightUtils.convert_to_taipei_time(published_at)
                    published_at = taipei_published.isoformat() if taipei_published else published_at
                
                # æ ¼å¼åŒ–è¨ˆç®—åˆ†æ•¸
                calc_score = r.get('calculated_score', 'N/A')
                if calc_score != 'N/A' and calc_score is not None:
                    try:
                        calc_score_formatted = f"{float(calc_score):,.1f}"
                    except:
                        calc_score_formatted = str(calc_score)
                else:
                    calc_score_formatted = 'N/A'
                
                # æ ¼å¼åŒ–æ•¸é‡é¡¯ç¤º
                def format_count(value):
                    if value in [None, '', 'N/A']:
                        return 'N/A'
                    try:
                        return f"{int(value):,}"
                    except:
                        return str(value)
                
                table_data.append({
                    "#": i,
                    "è²¼æ–‡ID": r.get('post_id', 'N/A')[:20] + "..." if len(r.get('post_id', '')) > 20 else r.get('post_id', 'N/A'),
                    "ç”¨æˆ¶å": r.get('username', 'N/A'),
                    "å…§å®¹" if show_full_content else "å…§å®¹é è¦½": r.get('content', 'N/A') if show_full_content else ((r.get('content', '')[:60] + "...") if r.get('content') and len(r.get('content', '')) > 60 else r.get('content', 'N/A')),
                    "è§€çœ‹æ•¸": format_count(r.get('views_count', r.get('views', 'N/A'))),
                    "æŒ‰è®š": format_count(r.get('likes_count', r.get('likes', 'N/A'))),
                    "ç•™è¨€": format_count(r.get('comments_count', r.get('comments', 'N/A'))),
                    "è½‰ç™¼": format_count(r.get('reposts_count', r.get('reposts', 'N/A'))),
                    "åˆ†äº«": format_count(r.get('shares_count', r.get('shares', 'N/A'))),
                    "è¨ˆç®—åˆ†æ•¸": calc_score_formatted,
                    "æ¨™ç±¤": tags_display,
                    "åœ–ç‰‡æ•¸": images_count,
                    "å½±ç‰‡æ•¸": videos_count,
                    "ç™¼å¸ƒæ™‚é–“": published_at[:19] if published_at else 'N/A',
                    "çˆ¬å–æ™‚é–“": created_at[:19] if created_at else 'N/A',
                    "ç‹€æ…‹": "âœ…" if r.get('success') else "âŒ"
                })
            
            st.dataframe(table_data, use_container_width=True, height=400)
        
        # è³‡æ–™åº«ç‹€æ…‹
        db_saved = results.get('database_saved', False)
        saved_count = results.get('database_saved_count', 0)
        if db_saved:
            st.success(f"âœ… å·²ä¿å­˜åˆ°è³‡æ–™åº« ({saved_count} å€‹è²¼æ–‡)")
        else:
            col_info, col_save = st.columns([3, 1])
            with col_info:
                st.info("â„¹ï¸ å¦‚æœçµ±è¨ˆä¸­æ²’æœ‰çœ‹åˆ°æ–°æ•¸æ“šï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å‚™ç”¨ä¿å­˜åŠŸèƒ½")
            with col_save:
                if st.button("ğŸ’¾ å‚™ç”¨ä¿å­˜", key="save_playwright_to_database_v2"):
                    result = self.db_handler.save_results_to_database_sync(results)
                    if result.get("success"):
                        st.success(f"âœ… ä¿å­˜æˆåŠŸï¼ä¿å­˜äº† {result.get('saved_count', 0)} å€‹è²¼æ–‡")
                    else:
                        st.error(f"âŒ ä¿å­˜å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        st.divider()
        
        # æ›´å¤šå°å‡ºåŠŸèƒ½
        st.subheader("ğŸ“¤ æ›´å¤šå°å‡º")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # ç›´æ¥ä¸‹è¼‰JSONï¼ˆä½¿ç”¨å®‰å…¨çš„åºåˆ—åŒ–å™¨ï¼‰
            def safe_json_serializer(obj):
                from decimal import Decimal
                from datetime import datetime, date
                if isinstance(obj, Decimal):
                    return float(obj)
                elif isinstance(obj, (datetime, date)):
                    return obj.isoformat()
                raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
            
            json_content = json.dumps(results, ensure_ascii=False, indent=2, default=safe_json_serializer)
            timestamp = PlaywrightUtils.get_current_taipei_time().strftime('%Y%m%d_%H%M%S')
            download_filename = f"playwright_crawl_results_{timestamp}.json"
            
            st.download_button(
                label="ğŸ’¾ ä¸‹è¼‰JSON",
                data=json_content,
                file_name=download_filename,
                mime="application/json",
                help="ç›´æ¥ä¸‹è¼‰çˆ¬å–çµæœJSONæ–‡ä»¶",
                key="download_playwright_json_v2"
            )
        
        with col2:
            # ç›´æ¥ä¸‹è¼‰CSV
            if posts:
                import pandas as pd
                import io
                
                # æº–å‚™CSVæ•¸æ“šï¼ˆèˆ‡ JSON æ ¼å¼å®Œå…¨ä¸€è‡´ï¼‰
                csv_data = []
                for r in posts:
                    # è™•ç† tags é™£åˆ—
                    tags_str = "|".join(r.get('tags', [])) if r.get('tags') else ""
                    
                    # è™•ç† images é™£åˆ—
                    images_str = "|".join(r.get('images', [])) if r.get('images') else ""
                    
                    # è™•ç† videos é™£åˆ—
                    videos_str = "|".join(r.get('videos', [])) if r.get('videos') else ""
                    
                    csv_data.append({
                        "url": r.get('url', ''),
                        "post_id": r.get('post_id', ''),
                        "username": r.get('username', ''),
                        "content": r.get('content', ''),
                        "likes_count": r.get('likes_count', r.get('likes', '')),
                        "comments_count": r.get('comments_count', r.get('comments', '')),
                        "reposts_count": r.get('reposts_count', r.get('reposts', '')),
                        "shares_count": r.get('shares_count', r.get('shares', '')),
                        "views_count": r.get('views_count', r.get('views', '')),
                        "calculated_score": r.get('calculated_score', ''),
                        "created_at": r.get('created_at', ''),
                        "post_published_at": r.get('post_published_at', ''),
                        "tags": tags_str,
                        "images": images_str,
                        "videos": videos_str,
                        "source": r.get('source', 'playwright_agent'),
                        "crawler_type": r.get('crawler_type', 'playwright'),
                        "crawl_id": r.get('crawl_id', ''),
                        "extracted_at": r.get('extracted_at', ''),
                        "success": r.get('success', True)
                    })
                
                df = pd.DataFrame(csv_data)
                # ä¿®å¾© CSV ç·¨ç¢¼å•é¡Œ - ä½¿ç”¨å­—ç¯€æµç¢ºä¿æ­£ç¢ºç·¨ç¢¼
                import io
                output = io.BytesIO()
                df.to_csv(output, index=False, encoding='utf-8-sig')
                csv_content = output.getvalue()
                
                csv_filename = f"playwright_crawl_results_{timestamp}.csv"
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è¼‰CSV",
                    data=csv_content,
                    file_name=csv_filename,
                    mime="text/csv",
                    help="ç›´æ¥ä¸‹è¼‰çˆ¬å–çµæœCSVæ–‡ä»¶",
                    key="download_playwright_csv_v2"
                )
            else:
                st.button("ğŸ“Š ä¸‹è¼‰CSV", disabled=True, help="æ²’æœ‰æ•¸æ“šå¯ä¸‹è¼‰")
        
        with col3:
            if st.button("ğŸ“ˆ æ­·å²åˆ†æ", key="playwright_history_analysis_v2"):
                # åˆ‡æ›æ­·å²åˆ†æé¢æ¿çš„å¯è¦‹æ€§
                st.session_state.show_playwright_history_analysis = not st.session_state.get('show_playwright_history_analysis', False)
                st.rerun()
            
        # é¡¯ç¤ºæ­·å²åˆ†æé¢æ¿ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if st.session_state.get('show_playwright_history_analysis', False):
            self._show_history_analysis_options()
        
        with col4:
            if st.button("ğŸ” æ›´å¤šå°å‡º", key="playwright_more_exports_v2"):
                # åˆ‡æ›æ›´å¤šå°å‡ºé¢æ¿çš„å¯è¦‹æ€§
                st.session_state.show_playwright_advanced_exports = not st.session_state.get('show_playwright_advanced_exports', False)
                st.rerun()
            
        # é¡¯ç¤ºæ›´å¤šå°å‡ºé¢æ¿ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
        if st.session_state.get('show_playwright_advanced_exports', False):
            self._show_advanced_export_options()
    
    def _safe_int(self, value):
        """å®‰å…¨è½‰æ›ç‚ºæ•´æ•¸"""
        try:
            if isinstance(value, (int, float)):
                return int(value)
            if isinstance(value, str):
                # è™•ç† 1.2K, 1.5M æ ¼å¼
                value = value.replace(',', '').replace(' ', '')
                if 'K' in value:
                    return int(float(value.replace('K', '')) * 1000)
                elif 'M' in value:
                    return int(float(value.replace('M', '')) * 1000000)
                elif 'B' in value:
                    return int(float(value.replace('B', '')) * 1000000000)
                else:
                    return int(float(value))
            return 0
        except:
            return 0
    

    
    def _show_history_analysis_options(self):
        """é¡¯ç¤ºæ­·å²åˆ†æé¸é …"""
        # å˜—è©¦å¾å¤šå€‹ä¾†æºç²å–ç”¨æˆ¶å
        target_username = None
        
        # æ–¹æ³•1ï¼šå¾ç•¶å‰çµæœç²å–
        if 'playwright_results' in st.session_state:
            results = st.session_state.playwright_results
            if results:
                target_username = results.get('target_username')
        
        # æ–¹æ³•2ï¼šå¾ç•¶å‰çˆ¬å–ç›®æ¨™ç²å–
        if not target_username and 'playwright_target' in st.session_state:
            target = st.session_state.playwright_target
            if target:
                target_username = target.get('username')
        
        # æ–¹æ³•3ï¼šè®“ç”¨æˆ¶æ‰‹å‹•è¼¸å…¥
        if not target_username:
            st.info("ğŸ’¡ è«‹è¼¸å…¥è¦åˆ†æçš„å¸³è™Ÿåç¨±")
            target_username = st.text_input(
                "å¸³è™Ÿåç¨±", 
                placeholder="ä¾‹å¦‚: natgeo", 
                key="playwright_history_username_input"
            )
            
            if not target_username:
                st.warning("âš ï¸ è«‹è¼¸å…¥å¸³è™Ÿåç¨±ä»¥ç¹¼çºŒæ­·å²åˆ†æ")
                return
        
        with st.expander("ğŸ“ˆ æ­·å²æ•¸æ“šå°å‡ºé¸é …", expanded=True):
            # æ·»åŠ é—œé–‰æŒ‰éˆ•
            col_title, col_close = st.columns([4, 1])
            with col_title:
                st.write(f"**ç›®æ¨™å¸³è™Ÿ:** @{target_username}")
            with col_close:
                if st.button("âŒ é—œé–‰", key="close_playwright_history_analysis"):
                    st.session_state.show_playwright_history_analysis = False
                    st.rerun()
            
            # æ’åºé¸é …
            st.subheader("ğŸ“Š æ’åºè¨­å®š")
            col_sort1, col_sort2 = st.columns(2)
            
            with col_sort1:
                sort_by = st.selectbox(
                    "æ’åºä¾æ“š",
                    options=["fetched_at", "views_count", "likes_count", "comments_count", "calculated_score", "post_published_at"],
                    format_func=lambda x: {
                        "fetched_at": "çˆ¬å–æ™‚é–“",
                        "views_count": "è§€çœ‹æ•¸",
                        "likes_count": "æŒ‰è®šæ•¸", 
                        "comments_count": "ç•™è¨€æ•¸",
                        "calculated_score": "è¨ˆç®—åˆ†æ•¸",
                        "post_published_at": "ç™¼å¸ƒæ™‚é–“"
                    }.get(x, x),
                    key="playwright_history_sort_by"
                )
            
            with col_sort2:
                sort_order = st.selectbox(
                    "æ’åºé †åº",
                    options=["DESC", "ASC"],
                    format_func=lambda x: "é™åº (é«˜åˆ°ä½)" if x == "DESC" else "å‡åº (ä½åˆ°é«˜)",
                    key="playwright_history_sort_order"
                )
            
            st.divider()
            
            # å°å‡ºé¡å‹
            export_type = st.radio(
                "é¸æ“‡å°å‡ºé¡å‹",
                options=["æœ€è¿‘æ•¸æ“š", "å…¨éƒ¨æ­·å²", "çµ±è¨ˆåˆ†æ"],
                help="é¸æ“‡è¦å°å‡ºçš„æ­·å²æ•¸æ“šç¯„åœ",
                key="playwright_history_export_type"
            )
            
            col1, col2 = st.columns(2)
            
            if export_type == "æœ€è¿‘æ•¸æ“š":
                with col1:
                    days_back = st.number_input("å›æº¯å¤©æ•¸", min_value=1, max_value=365, value=7, key="playwright_days_back")
                with col2:
                    limit = st.number_input("æœ€å¤§è¨˜éŒ„æ•¸", min_value=10, max_value=10000, value=1000, key="playwright_limit_recent")
                
                if st.button("ğŸ“Š å°å‡ºæœ€è¿‘æ•¸æ“š", key="playwright_export_recent"):
                    self._export_history_data(target_username, "recent", 
                                            days_back=days_back, limit=limit, 
                                            sort_by=sort_by, sort_order=sort_order)
            
            elif export_type == "å…¨éƒ¨æ­·å²":
                with col1:
                    limit = st.number_input("æœ€å¤§è¨˜éŒ„æ•¸", min_value=100, max_value=50000, value=5000, key="playwright_limit_all")
                
                if st.button("ğŸ“Š å°å‡ºå…¨éƒ¨æ­·å²", key="playwright_export_all"):
                    self._export_history_data(target_username, "all", 
                                            limit=limit, sort_by=sort_by, sort_order=sort_order)
            
            elif export_type == "çµ±è¨ˆåˆ†æ":
                st.info("æŒ‰æ—¥æœŸçµ±è¨ˆçš„åˆ†æå ±å‘Šï¼ŒåŒ…å«å¹³å‡è§€çœ‹æ•¸ã€æˆåŠŸç‡ç­‰æŒ‡æ¨™")
                
                if st.button("ğŸ“ˆ å°å‡ºçµ±è¨ˆåˆ†æ", key="playwright_export_analysis"):
                    self._export_history_data(target_username, "analysis", 
                                            sort_by=sort_by, sort_order=sort_order)
    
    def _export_history_data(self, username: str, export_type: str, **kwargs):
        """å°å‡ºæ­·å²æ•¸æ“š"""
        try:
            import asyncio
            
            # ç²å–æ’åºåƒæ•¸
            sort_by = kwargs.get('sort_by', 'fetched_at')
            sort_order = kwargs.get('sort_order', 'DESC')
            
            with st.spinner(f"ğŸ”„ æ­£åœ¨å¾è³‡æ–™åº«ç²å– @{username} çš„{export_type}æ•¸æ“š..."):
                # ç•°æ­¥ç²å–è³‡æ–™åº«æ•¸æ“š
                posts_data = asyncio.run(self._fetch_history_from_db(username, export_type, **kwargs))
            
            if not posts_data:
                st.warning(f"âš ï¸ æ²’æœ‰æ‰¾åˆ°ç”¨æˆ¶ @{username} çš„æ­·å²æ•¸æ“š")
                return
            
            # æ’åºæ•¸æ“š
            def get_sort_key(post):
                value = post.get(sort_by, 0)
                if value is None:
                    return 0
                if isinstance(value, str):
                    try:
                        return float(value)
                    except:
                        return 0
                return value
            
            posts_data.sort(key=get_sort_key, reverse=(sort_order == 'DESC'))
            
            # æº–å‚™æ•¸æ“šçµæ§‹
            data = {
                "username": username,
                "export_type": export_type,
                "exported_at": PlaywrightUtils.get_current_taipei_time().isoformat(),
                "sort_by": sort_by,
                "sort_order": sort_order,
                "total_records": len(posts_data),
                "data": posts_data
            }
            
            # æ·»åŠ çµ±è¨ˆä¿¡æ¯
            if export_type == "analysis":
                data["summary"] = self._calculate_stats(posts_data)
            
            # åŒæ™‚æä¾› JSON å’Œ CSV ä¸‹è¼‰
            col1, col2 = st.columns(2)
            
            with col1:
                # JSON ä¸‹è¼‰
                import json
                from decimal import Decimal
                from datetime import datetime, date
                
                # è‡ªå®šç¾©JSONç·¨ç¢¼å™¨è™•ç†Decimalå’Œdatetimeé¡å‹
                def json_serializer(obj):
                    if isinstance(obj, Decimal):
                        return float(obj)
                    elif isinstance(obj, (datetime, date)):
                        return obj.isoformat()
                    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
                
                json_content = json.dumps(data, ensure_ascii=False, indent=2, default=json_serializer)
                timestamp = PlaywrightUtils.get_current_taipei_time().strftime('%Y%m%d_%H%M%S')
                json_filename = f"playwright_history_{username}_{export_type}_{timestamp}.json"
                
                st.download_button(
                    label=f"ğŸ“¥ ä¸‹è¼‰JSON ({len(posts_data)}ç­†)",
                    data=json_content,
                    file_name=json_filename,
                    mime="application/json",
                    help="ä¸‹è¼‰æ­·å²æ•¸æ“šJSONæ–‡ä»¶"
                )
            
            with col2:
                # CSV ä¸‹è¼‰
                csv_content = self._convert_to_csv(posts_data)
                csv_filename = f"playwright_history_{username}_{export_type}_{timestamp}.csv"
                
                st.download_button(
                    label=f"ğŸ“Š ä¸‹è¼‰CSV ({len(posts_data)}ç­†)",
                    data=csv_content,
                    file_name=csv_filename,
                    mime="text/csv",
                    help="ä¸‹è¼‰æ­·å²æ•¸æ“šCSVæ–‡ä»¶"
                )
            
            # é¡¯ç¤ºæ•¸æ“šé è¦½
            st.subheader("ğŸ“Š æ•¸æ“šé è¦½")
            if export_type == "analysis" and "summary" in data:
                col_s1, col_s2, col_s3, col_s4 = st.columns(4)
                summary = data["summary"]
                with col_s1:
                    st.metric("ç¸½è²¼æ–‡æ•¸", summary.get("total_posts", 0))
                with col_s2:
                    st.metric("å¹³å‡è§€çœ‹æ•¸", f"{summary.get('avg_views', 0):,.0f}")
                with col_s3:
                    st.metric("å¹³å‡æŒ‰è®šæ•¸", f"{summary.get('avg_likes', 0):,.0f}")
                with col_s4:
                    st.metric("æœ€é«˜åˆ†æ•¸", f"{summary.get('max_score', 0):,.0f}")
            
            # é¡¯ç¤ºå‰10ç­†æ•¸æ“š
            if posts_data:
                col_preview1, col_preview2 = st.columns([1, 1])
                with col_preview1:
                    st.write("**å‰10ç­†æ•¸æ“šï¼š**")
                with col_preview2:
                    show_full_history_content = st.checkbox("ğŸ“– é¡¯ç¤ºå®Œæ•´å…§å®¹", key="show_full_history_content_v2", help="å‹¾é¸å¾Œå°‡é¡¯ç¤ºå®Œæ•´è²¼æ–‡å…§å®¹")
                
                preview_data = []
                for i, post in enumerate(posts_data[:10], 1):
                    content = post.get('content', '')
                    content_display = content if show_full_history_content else ((content[:40] + "...") if content and len(content) > 40 else content or 'N/A')
                    
                    preview_data.append({
                        "#": i,
                        "è²¼æ–‡ID": post.get('post_id', 'N/A')[:20] + "..." if len(post.get('post_id', '')) > 20 else post.get('post_id', 'N/A'),
                        "å…§å®¹" if show_full_history_content else "å…§å®¹é è¦½": content_display,
                        "è§€çœ‹æ•¸": f"{post.get('views_count', 0):,}",
                        "æŒ‰è®šæ•¸": f"{post.get('likes_count', 0):,}",
                        "åˆ†æ•¸": f"{post.get('calculated_score', 0):,.1f}" if post.get('calculated_score') else 'N/A',
                        "çˆ¬å–æ™‚é–“": str(post.get('fetched_at', 'N/A'))[:19]
                    })
                st.dataframe(preview_data, use_container_width=True)
            
            st.success(f"âœ… {export_type}æ•¸æ“šå°å‡ºå®Œæˆï¼å…± {len(posts_data)} ç­†è¨˜éŒ„")
            
        except Exception as e:
            st.error(f"âŒ æ­·å²æ•¸æ“šå°å‡ºå¤±æ•—: {str(e)}")
    
    async def _fetch_history_from_db(self, username: str, export_type: str, **kwargs):
        """å¾è³‡æ–™åº«ç²å–æ­·å²æ•¸æ“š"""
        try:
            posts = await self.db_handler.get_user_posts_async(username)
            
            # è½‰æ›æ‰€æœ‰æ™‚é–“å­—æ®µç‚ºå°åŒ—æ™‚é–“
            for post in posts:
                for time_field in ['created_at', 'fetched_at', 'post_published_at']:
                    if post.get(time_field):
                        taipei_time = PlaywrightUtils.convert_to_taipei_time(post[time_field])
                        if taipei_time:
                            post[time_field] = taipei_time.isoformat()
            
            if export_type == "recent":
                days_back = kwargs.get('days_back', 7)
                limit = kwargs.get('limit', 1000)
                
                # éæ¿¾æœ€è¿‘çš„æ•¸æ“š
                from datetime import datetime, timedelta
                cutoff_date = PlaywrightUtils.get_current_taipei_time() - timedelta(days=days_back)
                
                filtered_posts = []
                for post in posts:
                    try:
                        if post.get('fetched_at'):
                            fetch_time = datetime.fromisoformat(str(post['fetched_at']).replace('Z', '+00:00'))
                            if fetch_time >= cutoff_date:
                                filtered_posts.append(post)
                    except:
                        continue
                
                return filtered_posts[:limit]
                
            elif export_type == "all":
                limit = kwargs.get('limit', 5000)
                return posts[:limit]
                
            elif export_type == "analysis":
                return posts
                
        except Exception as e:
            st.error(f"âŒ è³‡æ–™åº«æŸ¥è©¢å¤±æ•—: {e}")
            return []
    
    def _calculate_stats(self, posts_data):
        """è¨ˆç®—çµ±è¨ˆæ•¸æ“š"""
        if not posts_data:
            return {
                "total_posts": 0,
                "avg_views": 0,
                "avg_likes": 0,
                "avg_comments": 0,
                "max_score": 0,
                "min_score": 0
            }
        
        total_posts = len(posts_data)
        views = [post.get('views_count', 0) for post in posts_data if post.get('views_count')]
        likes = [post.get('likes_count', 0) for post in posts_data if post.get('likes_count')]
        comments = [post.get('comments_count', 0) for post in posts_data if post.get('comments_count')]
        scores = [post.get('calculated_score', 0) for post in posts_data if post.get('calculated_score')]
        
        return {
            "total_posts": total_posts,
            "avg_views": sum(views) / len(views) if views else 0,
            "avg_likes": sum(likes) / len(likes) if likes else 0,
            "avg_comments": sum(comments) / len(comments) if comments else 0,
            "max_score": max(scores) if scores else 0,
            "min_score": min(scores) if scores else 0
        }
    
    def _convert_to_csv(self, posts_data):
        """å°‡æ•¸æ“šè½‰æ›ç‚ºCSVæ ¼å¼"""
        import pandas as pd
        import io
        
        # æº–å‚™CSVæ•¸æ“šï¼Œèˆ‡ä¸»è¦å°å‡ºæ ¼å¼ä¸€è‡´
        csv_data = []
        for post in posts_data:
            # è™•ç†é™£åˆ—å­—æ®µ
            tags = post.get('tags', [])
            if isinstance(tags, str):
                try:
                    import json
                    tags = json.loads(tags)
                except:
                    tags = []
            tags_str = "|".join(tags) if tags else ""
            
            images = post.get('images', [])
            if isinstance(images, str):
                try:
                    import json
                    images = json.loads(images)
                except:
                    images = []
            images_str = "|".join(images) if images else ""
            
            videos = post.get('videos', [])
            if isinstance(videos, str):
                try:
                    import json
                    videos = json.loads(videos)
                except:
                    videos = []
            videos_str = "|".join(videos) if videos else ""
            
            # è™•ç†æ™‚é–“å­—æ®µ - è½‰æ›ç‚ºå°åŒ—æ™‚é–“
            created_at = post.get('created_at', '')
            if created_at:
                taipei_created = PlaywrightUtils.convert_to_taipei_time(created_at)
                created_at = taipei_created.isoformat() if taipei_created else created_at
            
            post_published_at = post.get('post_published_at', '')
            if post_published_at:
                taipei_published = PlaywrightUtils.convert_to_taipei_time(post_published_at)
                post_published_at = taipei_published.isoformat() if taipei_published else post_published_at
            
            fetched_at = post.get('fetched_at', '')
            if fetched_at:
                taipei_fetched = PlaywrightUtils.convert_to_taipei_time(fetched_at)
                fetched_at = taipei_fetched.isoformat() if taipei_fetched else fetched_at
            
            csv_data.append({
                "url": post.get('url', ''),
                "post_id": post.get('post_id', ''),
                "username": post.get('username', ''),
                "content": post.get('content', ''),
                "likes_count": post.get('likes_count', 0),
                "comments_count": post.get('comments_count', 0),
                "reposts_count": post.get('reposts_count', 0),
                "shares_count": post.get('shares_count', 0),
                "views_count": post.get('views_count', 0),
                "calculated_score": post.get('calculated_score', ''),
                "created_at": created_at,
                "post_published_at": post_published_at,
                "tags": tags_str,
                "images": images_str,
                "videos": videos_str,
                "source": post.get('source', 'playwright_agent'),
                "crawler_type": post.get('crawler_type', 'playwright'),
                "crawl_id": post.get('crawl_id', ''),
                "fetched_at": fetched_at
            })
        
        # è½‰æ›ç‚ºCSV
        df = pd.DataFrame(csv_data)
        output = io.BytesIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        return output.getvalue()
    
    def _show_advanced_export_options(self):
        """é¡¯ç¤ºé€²éšå°å‡ºé¸é …"""
        with st.expander("ğŸ” é€²éšå°å‡ºåŠŸèƒ½", expanded=True):
            # æ·»åŠ é—œé–‰æŒ‰éˆ•
            col_title, col_close = st.columns([4, 1])
            with col_title:
                st.markdown("**æ›´å¤šå°å‡ºé¸é …å’Œæ‰¹é‡æ“ä½œ**")
            with col_close:
                if st.button("âŒ é—œé–‰", key="close_playwright_advanced_exports"):
                    st.session_state.show_playwright_advanced_exports = False
                    st.rerun()
            
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š å°æ¯”å ±å‘Š", "ğŸ”„ æ‰¹é‡å°å‡º", "âš¡ å¿«é€Ÿå·¥å…·"])
            
            with tab1:
                st.subheader("ğŸ“Š å¤šæ¬¡çˆ¬å–å°æ¯”å ±å‘Š")
                st.info("æ¯”è¼ƒå¤šæ¬¡çˆ¬å–çµæœçš„æ•ˆèƒ½å’ŒæˆåŠŸç‡")
                
                # æŸ¥æ‰¾æ‰€æœ‰Playwright JSONæ–‡ä»¶
                import glob
                from pathlib import Path
                
                # æª¢æŸ¥æ–°çš„è³‡æ–™å¤¾ä½ç½®
                extraction_dir = Path("crawl_data")
                if extraction_dir.exists():
                    json_files = list(extraction_dir.glob("crawl_data_*.json"))
                else:
                    json_files = [Path(f) for f in glob.glob("crawl_data_*.json")]
                
                if len(json_files) >= 2:
                    st.write(f"ğŸ” æ‰¾åˆ° {len(json_files)} å€‹Playwrightçˆ¬å–çµæœæ–‡ä»¶ï¼š")
                    
                    # é¡¯ç¤ºæ–‡ä»¶åˆ—è¡¨
                    file_options = {}
                    for file in sorted(json_files, reverse=True)[:10]:  # æœ€æ–°çš„10å€‹
                        file_time = self._extract_time_from_filename(str(file))
                        display_name = f"{file.name} ({file_time})"
                        file_options[display_name] = str(file)
                    
                    selected_displays = st.multiselect(
                        "é¸æ“‡è¦æ¯”å°çš„æ–‡ä»¶ï¼ˆè‡³å°‘2å€‹ï¼‰ï¼š",
                        options=list(file_options.keys()),
                        default=[],
                        help="é¸æ“‡å¤šå€‹æ–‡ä»¶é€²è¡Œæ¯”å°åˆ†æ",
                        key="playwright_comparison_file_selector"
                    )
                    
                    selected_files = [file_options[display] for display in selected_displays]
                    
                    if len(selected_files) >= 2:
                        if st.button("ğŸ“Š ç”Ÿæˆå°æ¯”å ±å‘Š", key="playwright_generate_comparison", type="primary"):
                            self._generate_comparison_report(selected_files)
                    else:
                        st.info("ğŸ’¡ è«‹é¸æ“‡è‡³å°‘2å€‹æ–‡ä»¶é€²è¡Œæ¯”å°åˆ†æ")
                else:
                    st.warning("âš ï¸ éœ€è¦è‡³å°‘2å€‹Playwrightçˆ¬å–çµæœæ–‡ä»¶æ‰èƒ½é€²è¡Œå°æ¯”")
            
            with tab2:
                st.subheader("ğŸ”„ æ‰¹é‡å°å‡ºåŠŸèƒ½")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“¥ å°å‡ºæ‰€æœ‰æœ€æ–°çµæœ", key="playwright_export_all_latest"):
                        self._export_all_latest_results()
                
                with col2:
                    if st.button("ğŸ“ˆ å°å‡ºæ‰€æœ‰å¸³è™Ÿçµ±è¨ˆ", key="playwright_export_all_stats"):
                        self._export_all_account_stats()
            
            with tab3:
                st.subheader("âš¡ å¿«é€Ÿå·¥å…·")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("ğŸ§¹ æ¸…ç†æš«å­˜æª”æ¡ˆ", key="playwright_cleanup_temp"):
                        self._cleanup_temp_files()
                
                with col2:
                    if st.button("ğŸ“‹ è¤‡è£½çµæœæ‘˜è¦", key="playwright_copy_summary"):
                        if 'playwright_results' in st.session_state:
                            self._copy_results_summary()
                        else:
                            st.error("âŒ æ²’æœ‰å¯è¤‡è£½çš„çµæœ")
                
                with col3:
                    if st.button("ğŸ”— ç”Ÿæˆåˆ†äº«é€£çµ", key="playwright_share_link"):
                        self._generate_share_link()
    
    def _extract_time_from_filename(self, filename: str) -> str:
        """å¾æª”æ¡ˆåæå–æ™‚é–“"""
        import re
        match = re.search(r'(\d{8}_\d{6})', filename)
        if match:
            time_str = match.group(1)
            return f"{time_str[:4]}-{time_str[4:6]}-{time_str[6:8]} {time_str[9:11]}:{time_str[11:13]}"
        return "æœªçŸ¥æ™‚é–“"
    
    def _generate_comparison_report(self, selected_files: list):
        """ç”Ÿæˆå°æ¯”å ±å‘Š"""
        try:
            import pandas as pd
            
            comparison_data = []
            
            for file_path in selected_files:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                comparison_data.append({
                    "æª”æ¡ˆå": Path(file_path).name,
                    "æ™‚é–“æˆ³": data.get('timestamp', 'N/A'),
                    "ç”¨æˆ¶å": data.get('target_username', 'N/A'),
                    "çˆ¬èŸ²é¡å‹": data.get('crawler_type', 'playwright'),
                    "ç¸½è²¼æ–‡æ•¸": len(data.get('results', [])),
                    "æˆåŠŸæ•¸": data.get('api_success_count', 0),
                    "å¤±æ•—æ•¸": data.get('api_failure_count', 0),
                    "æˆåŠŸç‡": data.get('overall_success_rate', 0),
                })
            
            df = pd.DataFrame(comparison_data)
            
            st.subheader("ğŸ“Š å°æ¯”å ±å‘Š")
            st.dataframe(df, use_container_width=True)
            
            # æä¾›ä¸‹è¼‰
            csv_content = df.to_csv(index=False, encoding='utf-8-sig')
            timestamp = PlaywrightUtils.get_current_taipei_time().strftime('%Y%m%d_%H%M%S')
            filename = f"playwright_comparison_report_{timestamp}.csv"
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰å°æ¯”å ±å‘Š",
                data=csv_content,
                file_name=filename,
                mime="text/csv"
            )
            
        except Exception as e:
            st.error(f"âŒ ç”Ÿæˆå°æ¯”å ±å‘Šå¤±æ•—: {e}")
    
    def _export_all_latest_results(self):
        """å°å‡ºæ‰€æœ‰æœ€æ–°çµæœ"""
        st.info("ğŸ“¦ æ‰¹é‡å°å‡ºåŠŸèƒ½é–‹ç™¼ä¸­...")
    
    def _export_all_account_stats(self):
        """å°å‡ºæ‰€æœ‰å¸³è™Ÿçµ±è¨ˆ"""
        st.info("ğŸ“ˆ å¸³è™Ÿçµ±è¨ˆå°å‡ºåŠŸèƒ½é–‹ç™¼ä¸­...")
    
    def _cleanup_temp_files(self):
        """æ¸…ç†æš«å­˜æª”æ¡ˆ"""
        import glob
        temp_files = glob.glob("temp_playwright_progress_*.json")
        cleaned = 0
        for file in temp_files:
            try:
                os.remove(file)
                cleaned += 1
            except:
                pass
        st.success(f"ğŸ§¹ å·²æ¸…ç† {cleaned} å€‹æš«å­˜æª”æ¡ˆ")
    
    def _copy_results_summary(self):
        """è¤‡è£½çµæœæ‘˜è¦"""
        results = st.session_state.get('playwright_results', {})
        posts = results.get('results', [])
        
        summary = f"""Playwright çˆ¬èŸ²çµæœæ‘˜è¦
ç”¨æˆ¶: @{results.get('target_username', 'unknown')}
æ™‚é–“: {results.get('timestamp', 'N/A')}
ç¸½è²¼æ–‡: {len(posts)}
æˆåŠŸç‡: {results.get('overall_success_rate', 0):.1f}%
"""
        
        st.text_area("ğŸ“‹ çµæœæ‘˜è¦ï¼ˆè«‹è¤‡è£½ï¼‰", value=summary, key="playwright_summary_copy")
    
    def _generate_share_link(self):
        """ç”Ÿæˆåˆ†äº«é€£çµ"""
        st.info("ğŸ”— åˆ†äº«é€£çµåŠŸèƒ½é–‹ç™¼ä¸­...")
    
    def _clear_results(self):
        """æ¸…é™¤çµæœ"""
        if 'playwright_results' in st.session_state:
            del st.session_state.playwright_results
        if 'playwright_results_file' in st.session_state:
            del st.session_state.playwright_results_file
        # é‡ç½®ä¿å­˜æ¨™è¨˜
        st.session_state.playwright_results_saved = False
        st.success("ğŸ—‘ï¸ çµæœå·²æ¸…é™¤")
        st.rerun()
    
    def _load_csv_file(self, uploaded_file):
        """è¼‰å…¥CSVæ–‡ä»¶"""
        try:
            import pandas as pd
            import io
            
            # æ¸…ç†å¯èƒ½çš„èˆŠæ–‡ä»¶å¼•ç”¨ï¼Œé¿å… MediaFileStorageError
            if hasattr(st.session_state, 'get'):
                file_related_keys = [k for k in st.session_state.keys() if 'file' in k.lower() or 'upload' in k.lower()]
                for key in file_related_keys:
                    if key != "playwright_csv_uploader_v2":  # ä¿ç•™ç•¶å‰ä¸Šå‚³å™¨
                        try:
                            del st.session_state[key]
                        except:
                            pass
            
            # è®€å–CSVæ–‡ä»¶
            content = uploaded_file.getvalue()
            df = pd.read_csv(io.StringIO(content.decode('utf-8-sig')))
            
            # æª¢æŸ¥CSVæ ¼å¼æ˜¯å¦æ­£ç¢ºï¼ˆèˆ‡ JSON æ ¼å¼ä¸€è‡´ï¼‰
            required_columns = ['url', 'post_id', 'username', 'content']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                st.error(f"âŒ CSVæ ¼å¼ä¸æ­£ç¢ºï¼Œç¼ºå°‘æ¬„ä½: {', '.join(missing_columns)}")
                return
            
            # è½‰æ›ç‚ºçµæœæ ¼å¼
            results = []
            for _, row in df.iterrows():
                # è™•ç†é™£åˆ—å­—æ®µ (tags, images, videos)
                tags_str = str(row.get('tags', '')).strip()
                tags = tags_str.split('|') if tags_str else []
                
                images_str = str(row.get('images', '')).strip()
                images = images_str.split('|') if images_str else []
                
                videos_str = str(row.get('videos', '')).strip()
                videos = videos_str.split('|') if videos_str else []
                
                result = {
                    "url": str(row.get('url', '')).strip(),
                    "post_id": str(row.get('post_id', '')).strip(),
                    "username": str(row.get('username', '')).strip(),
                    "content": str(row.get('content', '')).strip(),
                    "likes_count": row.get('likes_count', 0) if pd.notna(row.get('likes_count')) else 0,
                    "comments_count": row.get('comments_count', 0) if pd.notna(row.get('comments_count')) else 0,
                    "reposts_count": row.get('reposts_count', 0) if pd.notna(row.get('reposts_count')) else 0,
                    "shares_count": row.get('shares_count', 0) if pd.notna(row.get('shares_count')) else 0,
                    "views_count": row.get('views_count', 0) if pd.notna(row.get('views_count')) else 0,
                    "calculated_score": row.get('calculated_score', 0) if pd.notna(row.get('calculated_score')) else 0,
                    "created_at": str(row.get('created_at', '')).strip(),
                    "post_published_at": str(row.get('post_published_at', '')).strip(),
                    "tags": tags,
                    "images": images,
                    "videos": videos,
                    "source": str(row.get('source', 'playwright_agent')).strip(),
                    "crawler_type": str(row.get('crawler_type', 'playwright')).strip(),
                    "crawl_id": str(row.get('crawl_id', '')).strip(),
                    "extracted_at": str(row.get('extracted_at', '')).strip(),
                    "success": row.get('success', True) if pd.notna(row.get('success')) else True
                }
                results.append(result)
            
            # åŒ…è£ç‚ºå®Œæ•´çµæœæ ¼å¼
            final_results = {
                            "crawl_id": f"imported_{PlaywrightUtils.get_current_taipei_time().strftime('%Y%m%d_%H%M%S')}",
            "timestamp": PlaywrightUtils.get_current_taipei_time().isoformat(),
                "target_username": results[0].get('username', '') if results else '',
                "source": "csv_import",
                "crawler_type": "playwright",
                "total_processed": len(results),
                "results": results
            }
            
            st.session_state.playwright_results = final_results
            st.session_state.playwright_crawl_status = "completed"  # è¨­ç½®ç‹€æ…‹ç‚ºå®Œæˆ
            st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(results)} ç­†è¨˜éŒ„")
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ è¼‰å…¥CSVå¤±æ•—: {e}")
