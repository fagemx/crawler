#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Readerå…§å®¹è§£æå™¨ - å¾Jina Readerè¿”å›çš„markdownä¸­æå–é—œéµæ•¸æ“š
"""

import re
import requests
from typing import Dict, Optional, List
import json

class ThreadsReaderParser:
    """Threadsè²¼æ–‡Readerè§£æå™¨"""
    
    def __init__(self, reader_base_url: str = "http://localhost:8880"):
        self.reader_base_url = reader_base_url
    
    def fetch_content(self, post_url: str) -> str:
        """å¾Readeræœå‹™ç²å–å…§å®¹"""
        reader_url = f"{self.reader_base_url}/{post_url}"
        try:
            response = requests.get(reader_url, timeout=30)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"âŒ ç²å–å…§å®¹å¤±æ•—: {e}")
            return ""
    
    def extract_post_content(self, markdown_content: str) -> Optional[str]:
        """æå–è²¼æ–‡å…§å®¹"""
        lines = markdown_content.split('\n')
        
        # æ–¹æ³•1: æŸ¥æ‰¾ç¬¬ä¸€æ®µæ­£æ–‡å…§å®¹ï¼ˆåœ¨===åˆ†éš”ç¬¦ä¹‹å‰ï¼‰
        content_lines = []
        in_content = False
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è·³éæ¨™é¡Œå’ŒURLè¡Œ
            if line.startswith("Title:") or line.startswith("URL Source:") or line.startswith("Markdown Content:"):
                continue
                
            # å¦‚æœé‡åˆ°åˆ†éš”ç¬¦ï¼Œåœæ­¢
            if "===============" in line or "---" in line:
                break
                
            # å¦‚æœæ˜¯è²¼æ–‡å…§å®¹ï¼ˆä¸æ˜¯é€£çµã€ä¸æ˜¯æŒ‰éˆ•æ–‡å­—ï¼‰
            if not line.startswith("[") and not line.startswith("!") and len(line) > 10:
                content_lines.append(line)
                if len(content_lines) >= 3:  # å–å‰å¹¾è¡Œä½œç‚ºå…§å®¹
                    break
        
        return ' '.join(content_lines) if content_lines else None
    
    def extract_views_count(self, markdown_content: str) -> Optional[str]:
        """æå–è§€çœ‹æ•¸ - æ–°æ ¼å¼ï¼šåœ¨Threadé€£çµä¸­"""
        # æ–°æ ¼å¼ï¼š[Thread ====== 313K views](...)
        patterns = [
            r'\[Thread\s*={2,}\s*(\d+(?:\.\d+)?[KMB]?)\s*views\]',
            r'Thread.*?(\d+(?:\.\d+)?[KMB]?)\s*views',
            r'(\d+(?:\.\d+)?[KMB]?)\s*views'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, markdown_content, re.IGNORECASE)
            if match:
                return f"{match.group(1)} views"
        
        return None
    
    def extract_engagement_numbers(self, markdown_content: str) -> Dict[str, str]:
        """æå–äº’å‹•æ•¸æ“šåºåˆ— - åŸºæ–¼ä½ç½®æ¨æ–·å«ç¾©"""
        lines = markdown_content.split('\n')
        
        # æ‰¾åˆ°è²¼æ–‡çš„ä¸»åœ–ç‰‡ï¼ˆä¸æ˜¯é ­åƒï¼‰
        for i, line in enumerate(lines):
            stripped = line.strip()
            # æ‰¾åˆ°è²¼æ–‡åœ–ç‰‡ï¼ˆé€šå¸¸åœ¨Translateä¹‹å¾Œï¼Œä¸”ä¸æ˜¯profile pictureï¼‰
            if (stripped.startswith('![Image') and 
                'profile picture' not in stripped and 
                i > 0 and any('Translate' in lines[k] for k in range(max(0, i-3), i+1))):
                
                numbers = []
                # åœ¨é€™å€‹åœ–ç‰‡å¾ŒæŸ¥æ‰¾é€£çºŒçš„æ•¸å­—
                for j in range(i + 1, min(i + 15, len(lines))):
                    candidate = lines[j].strip()
                    if re.match(r'^\d+(?:\.\d+)?[KMB]?$', candidate):
                        numbers.append(candidate)
                    elif candidate and candidate not in ["Pinned", "", "Translate"]:
                        # é‡åˆ°éæ•¸å­—è¡Œï¼Œåœæ­¢æ”¶é›†
                        break
                
                # æ ¹æ“šä½ç½®æ¨æ–·å«ç¾©
                engagement_data = {}
                if len(numbers) >= 1:
                    engagement_data['likes'] = numbers[0]
                if len(numbers) >= 2:
                    engagement_data['comments'] = numbers[1]  
                if len(numbers) >= 3:
                    engagement_data['reposts'] = numbers[2]
                if len(numbers) >= 4:
                    engagement_data['shares'] = numbers[3]
                
                # å¦‚æœæ‰¾åˆ°äº†æ•¸å­—åºåˆ—ï¼Œè¿”å›
                if len(numbers) >= 3:
                    return engagement_data
        
        return {}
    
    def extract_likes_count(self, markdown_content: str) -> Optional[str]:
        """æå–æŒ‰è®šæ•¸ - æ–°æ ¼å¼ï¼šåŸºæ–¼ä½ç½®æ¨æ–·"""
        engagement = self.extract_engagement_numbers(markdown_content)
        return engagement.get('likes')
    
    def parse_post(self, post_url: str) -> Dict:
        """è§£æå–®ç¯‡è²¼æ–‡ï¼Œè¿”å›çµæ§‹åŒ–æ•¸æ“š"""
        print(f"ğŸ¯ é–‹å§‹è§£æè²¼æ–‡: {post_url}")
        
        # ç²å–å…§å®¹
        content = self.fetch_content(post_url)
        if not content:
            return {"error": "ç„¡æ³•ç²å–å…§å®¹"}
        
        print(f"ğŸ“„ ç²å–åˆ° {len(content)} å­—ç¬¦çš„å…§å®¹")
        
        # æå–å„é …æ•¸æ“š
        engagement = self.extract_engagement_numbers(content)
        
        result = {
            "url": post_url,
            "content": self.extract_post_content(content),
            "views": self.extract_views_count(content),
            "likes": engagement.get('likes'),
            "comments": engagement.get('comments'),
            "reposts": engagement.get('reposts'),
            "shares": engagement.get('shares'),
            "raw_numbers": list(engagement.values()) if engagement else [],
            "raw_length": len(content)
        }
        
        return result
    
    def debug_content(self, post_url: str, save_raw: bool = True):
        """èª¿è©¦æ¨¡å¼ï¼šé¡¯ç¤ºåŸå§‹å…§å®¹ä»¥ä¾¿åˆ†æ"""
        content = self.fetch_content(post_url)
        if not content:
            return
        
        print("ğŸ” åŸå§‹å…§å®¹åˆ†æ:")
        print("=" * 50)
        
        lines = content.split('\n')
        for i, line in enumerate(lines[:30]):  # åªé¡¯ç¤ºå‰30è¡Œ
            print(f"{i+1:2d}: {line}")
        
        print(f"\n... (ç¸½å…± {len(lines)} è¡Œ)")
        
        if save_raw:
            filename = f"reader_raw_content_{post_url.split('/')[-1]}.txt"
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"ğŸ’¾ åŸå§‹å…§å®¹å·²ä¿å­˜åˆ°: {filename}")

def main():
    """æ¸¬è©¦è§£æå™¨"""
    parser = ThreadsReaderParser()
    
    # æ¸¬è©¦è²¼æ–‡
    test_url = "https://www.threads.com/@ttshow.tw/post/DMfOVeqSkM5"
    
    print("ğŸ§ª æ¸¬è©¦Readerè§£æå™¨")
    print("=" * 50)
    
    # èª¿è©¦æ¨¡å¼ï¼šæŸ¥çœ‹åŸå§‹å…§å®¹
    print("ğŸ“‹ èª¿è©¦æ¨¡å¼ - æŸ¥çœ‹åŸå§‹å…§å®¹:")
    parser.debug_content(test_url)
    
    print("\n" + "=" * 50)
    
    # è§£ææ¨¡å¼ï¼šæå–çµæ§‹åŒ–æ•¸æ“š
    print("ğŸ“Š è§£ææ¨¡å¼ - æå–çµæ§‹åŒ–æ•¸æ“š:")
    result = parser.parse_post(test_url)
    
    print(f"ğŸ“ è²¼æ–‡å…§å®¹: {result.get('content', 'N/A')}")
    print(f"ğŸ‘ï¸ è§€çœ‹æ•¸: {result.get('views', 'N/A')}")
    print(f"ğŸ‘ æŒ‰è®šæ•¸: {result.get('likes', 'N/A')}")
    print(f"ğŸ’¬ ç•™è¨€æ•¸: {result.get('comments', 'N/A')}")
    print(f"ğŸ”„ è½‰ç™¼æ•¸: {result.get('reposts', 'N/A')}")  
    print(f"ğŸ“¤ åˆ†äº«æ•¸: {result.get('shares', 'N/A')}")
    print(f"ğŸ”¢ åŸå§‹æ•¸å­—åºåˆ—: {result.get('raw_numbers', [])}")
    print(f"ğŸ“„ åŸå§‹é•·åº¦: {result.get('raw_length', 0)} å­—ç¬¦")
    
    # ä¿å­˜çµæœ
    with open('reader_parse_result.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print("ğŸ’¾ è§£æçµæœå·²ä¿å­˜åˆ°: reader_parse_result.json")

if __name__ == "__main__":
    main()