#!/usr/bin/env python3
"""
åˆ†æèª¿è©¦æ–‡ä»¶ï¼Œæ‰¾å‡ºå•é¡Œæ‰€åœ¨
"""

def analyze_debug_file(filename, label):
    """åˆ†æå–®å€‹èª¿è©¦æ–‡ä»¶"""
    print(f"\nğŸ“„ åˆ†æ {label}")
    print("-" * 50)
    
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        
        print(f"æª”æ¡ˆå¤§å°: {len(content):,} å­—ç¬¦")
        print(f"ç¸½è¡Œæ•¸: {len(lines)}")
        
        # æŸ¥æ‰¾é—œéµå­—
        keywords = {
            "Thread ======": content.count("Thread ======"),
            "views": content.count("views"),
            "è§€çœ‹": content.count("è§€çœ‹"),
            "Related threads": content.count("Related threads"),
            "post": content.count("/post/"),
            "Like": content.count("Like"),
            "Comment": content.count("Comment"),
            "Repost": content.count("Repost"),
            "Share": content.count("Share"),
        }
        
        print("é—œéµå­—çµ±è¨ˆ:")
        for keyword, count in keywords.items():
            if count > 0:
                print(f"   â€¢ {keyword}: {count} æ¬¡")
        
        # æŸ¥æ‰¾è§€çœ‹æ•¸æ¨¡å¼
        import re
        view_patterns = [
            r'Thread\s*={6}\s*([0-9,\.]+[KMB]?)\s*views?',
            r'Thread\s*={6}\s*([0-9,\.]+[KMB]?)',
            r'(\d+(?:\.\d+)?[KMB]?)\s*views?',
        ]
        
        found_views = []
        for pattern in view_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                found_views.extend(matches)
        
        if found_views:
            print(f"æ‰¾åˆ°è§€çœ‹æ•¸: {found_views}")
        else:
            print("âŒ æœªæ‰¾åˆ°è§€çœ‹æ•¸")
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«å…¶ä»– post_id
        original_post_id = "DMfOVeqSkM5"
        other_post_ids = re.findall(r'/post/([A-Za-z0-9_-]+)', content)
        other_unique_ids = list(set(other_post_ids) - {original_post_id})
        
        if other_unique_ids:
            print(f"ç™¼ç¾å…¶ä»– post_id: {other_unique_ids[:5]}")
        else:
            print("âœ… åªåŒ…å«ç›®æ¨™ post_id")
        
        # æŸ¥çœ‹å…§å®¹çµæ§‹
        print("\nå‰ 20 è¡Œé‡è¦å…§å®¹:")
        important_lines = []
        for i, line in enumerate(lines):
            line = line.strip()
            if line and not line.startswith('=') and not line.startswith('[Image'):
                important_lines.append(f"L{i+1}: {line}")
                if len(important_lines) >= 20:
                    break
        
        for line in important_lines:
            print(f"   {line}")
        
        return found_views, len(other_unique_ids) > 1
        
    except Exception as e:
        print(f"âŒ ç„¡æ³•è®€å–æ–‡ä»¶: {e}")
        return [], True

def main():
    print("ğŸ” åˆ†æ Reader èª¿è©¦æ–‡ä»¶")
    print("=" * 80)
    
    files_to_analyze = [
        ("debug_content_åŸå§‹è«‹æ±‚_20250803_224922.txt", "åŸå§‹è«‹æ±‚"),
        ("debug_content_å¢å¼·_Headers_20250803_224936.txt", "å¢å¼· Headers"),
        ("debug_content_ç„¡å¿«å–_20250803_224953.txt", "ç„¡å¿«å–")
    ]
    
    results = {}
    
    for filename, label in files_to_analyze:
        views, is_aggregated = analyze_debug_file(filename, label)
        results[label] = {
            'views': views,
            'is_aggregated': is_aggregated,
            'success': len(views) > 0 and not is_aggregated
        }
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ç¸½çµåˆ†æ")
    print("=" * 80)
    
    for label, result in results.items():
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
        print(f"{status} {label}:")
        print(f"   è§€çœ‹æ•¸: {result['views'] if result['views'] else 'æœªæ‰¾åˆ°'}")
        print(f"   èšåˆé é¢: {'æ˜¯' if result['is_aggregated'] else 'å¦'}")
    
    # çµ¦å‡ºå»ºè­°
    print("\nğŸ’¡ åˆ†æå»ºè­°:")
    
    successful = [label for label, result in results.items() if result['success']]
    if successful:
        print(f"âœ… ä»¥ä¸‹ç­–ç•¥æœ‰æ•ˆ: {', '.join(successful)}")
        print("   å»ºè­°åœ¨ä¸»ç¨‹å¼ä¸­æ¡ç”¨ç›¸æ‡‰çš„ headers")
    else:
        print("âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±æ•—äº†")
        print("   å¯èƒ½çš„åŸå› :")
        print("   1. Reader æœå‹™æœ¬èº«æœ‰å•é¡Œ")
        print("   2. Threads.com å®Œå…¨é˜»æ­¢äº†è‡ªå‹•åŒ–è¨ªå•")
        print("   3. éœ€è¦æ›´è¤‡é›œçš„åæª¢æ¸¬æªæ–½")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å…§å®¹ä½†æ²’æœ‰è§€çœ‹æ•¸
        has_content = any(not result['is_aggregated'] for result in results.values())
        if has_content:
            print("   ğŸ“„ æœ‰å…§å®¹ä½†ç„¡è§€çœ‹æ•¸ â†’ å¯èƒ½æ˜¯è§€çœ‹æ•¸æå–é‚è¼¯å•é¡Œ")
        else:
            print("   ğŸ“„ å…¨éƒ¨éƒ½æ˜¯èšåˆé é¢ â†’ ç¢ºå®šæ˜¯ Reader/Threads çš„å•é¡Œ")

if __name__ == '__main__':
    main()