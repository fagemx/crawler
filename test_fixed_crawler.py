#!/usr/bin/env python3
"""
æ¸¬è©¦ä¿®å¾©å¾Œçš„ Playwright Crawler
å°ˆæ³¨æ–¼é©—è­‰è§€çœ‹æ•¸è£œé½ŠåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import json
import logging
import sys
import os
from pathlib import Path

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# è·¯å¾‘è¨­å®š
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from agents.playwright_crawler.playwright_logic import PlaywrightLogic
    from common.models import PostMetricsBatch
except ModuleNotFoundError as e:
    logging.error(f"âŒ æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

# æ¸¬è©¦åƒæ•¸
TARGET_USERNAME = "natgeo"
MAX_POSTS_TO_CRAWL = 3  # æ¸›å°‘æ•¸é‡ä»¥å¿«é€Ÿæ¸¬è©¦
AUTH_FILE_PATH = Path(project_root) / "agents" / "playwright_crawler" / "auth.json"

async def test_fixed_crawler():
    """æ¸¬è©¦ä¿®å¾©å¾Œçš„çˆ¬èŸ²"""
    print("ğŸ§ª === æ¸¬è©¦ä¿®å¾©å¾Œçš„ Playwright Crawler ===")

    # æª¢æŸ¥èªè­‰æª”æ¡ˆ
    if not AUTH_FILE_PATH.exists():
        print(f"âŒ æ‰¾ä¸åˆ°èªè­‰æª”æ¡ˆ {AUTH_FILE_PATH}")
        return
        
    try:
        with open(AUTH_FILE_PATH, 'r', encoding='utf-8') as f:
            auth_json_content = json.load(f)
        print(f"âœ… æˆåŠŸè®€å–èªè­‰æª”æ¡ˆ")
    except Exception as e:
        print(f"âŒ è®€å–èªè­‰æª”æ¡ˆå¤±æ•—: {e}")
        return

    # åˆå§‹åŒ–çˆ¬èŸ²
    crawler = PlaywrightLogic()
    print("âœ… PlaywrightLogic åˆå§‹åŒ–å®Œæˆ")

    # åŸ·è¡Œçˆ¬å–
    print(f"ğŸš€ é–‹å§‹æ¸¬è©¦çˆ¬å– '{TARGET_USERNAME}' çš„æœ€è¿‘ {MAX_POSTS_TO_CRAWL} ç¯‡è²¼æ–‡...")
    
    try:
        result_batch: PostMetricsBatch = await crawler.fetch_posts(
            username=TARGET_USERNAME,
            max_posts=MAX_POSTS_TO_CRAWL,
            auth_json_content=auth_json_content,
            task_id="test_fixed_crawler"
        )
        
        print("\nâœ… === çˆ¬å–å®Œæˆ ===")
        
        if not result_batch or not result_batch.posts:
            print("âŒ çµæœç‚ºç©ºï¼Œæ²’æœ‰çˆ¬å–åˆ°ä»»ä½•è²¼æ–‡")
            return
            
        print(f"ğŸ“Š å…±çˆ¬å–åˆ° {len(result_batch.posts)} ç¯‡è²¼æ–‡")
        
        # æª¢æŸ¥è§€çœ‹æ•¸è£œé½Šæƒ…æ³
        print("\nğŸ” === è§€çœ‹æ•¸è£œé½Šæª¢æŸ¥ ===")
        views_success = 0
        views_failed = 0
        views_null = 0
        
        for i, post in enumerate(result_batch.posts, 1):
            print(f"è²¼æ–‡ {i}: {post.url.split('/')[-1]}")
            print(f"  è§€çœ‹æ•¸: {post.views_count}")
            print(f"  è£œé½Šæ™‚é–“: {post.views_fetched_at}")
            
            if post.views_count is None:
                print("  ç‹€æ…‹: âšªï¸ æœªè£œé½Šï¼ˆå¯èƒ½ API å·²æœ‰æ•¸æ“šï¼‰")
                views_null += 1
            elif post.views_count == -1:
                print("  ç‹€æ…‹: âŒ è£œé½Šå¤±æ•—")
                views_failed += 1
            elif post.views_count > 0:
                print("  ç‹€æ…‹: âœ… è£œé½ŠæˆåŠŸ")
                views_success += 1
            else:
                print("  ç‹€æ…‹: âšªï¸ è§€çœ‹æ•¸ç‚º 0")
                views_success += 1
            print()
        
        # çµ±è¨ˆçµæœ
        total = len(result_batch.posts)
        print("ğŸ“Š === è£œé½Šçµ±è¨ˆ ===")
        print(f"æˆåŠŸè£œé½Š: {views_success}/{total}")
        print(f"è£œé½Šå¤±æ•—: {views_failed}/{total}")
        print(f"æœªéœ€è£œé½Š: {views_null}/{total}")
        
        if views_success > 0:
            print("ğŸ‰ è§€çœ‹æ•¸è£œé½ŠåŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
        elif views_failed == total:
            print("âŒ æ‰€æœ‰è§€çœ‹æ•¸è£œé½Šéƒ½å¤±æ•—ï¼Œå¯èƒ½æ˜¯ selector æˆ–ç¶²è·¯å•é¡Œ")
        else:
            print("âš ï¸ éƒ¨åˆ†è§€çœ‹æ•¸è£œé½ŠæˆåŠŸï¼Œéœ€è¦é€²ä¸€æ­¥èª¿è©¦")
            
    except Exception as e:
        logging.error(f"âŒ æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(test_fixed_crawler())