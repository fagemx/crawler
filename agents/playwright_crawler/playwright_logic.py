import asyncio
import json
import logging
import random
import re
import tempfile
import uuid
from pathlib import Path
from typing import Dict, List, Optional, AsyncIterable

from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError

from common.settings import get_settings
from common.a2a import stream_text, stream_data, stream_status, stream_error, TaskState
from common.models import PostMetrics, PostMetricsBatch

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- GraphQL API è©³ç´°è³‡è¨Š ---
GRAPHQL_RE = re.compile(r"/graphql/query")
# ä¿ç•™ç”¨ä¾† debugï¼›å¯¦éš›é‚è¼¯æ”¹æˆã€Œçœ‹çµæ§‹ã€å³å¯
POST_QUERY_NAMES = set()

# --- å¼·å¥çš„æ¬„ä½å°ç…§è¡¨ ---
FIELD_MAP = {
    "like_count": [
        "like_count", "likeCount", 
        ["feedback_info", "aggregated_like_count"],
        ["like_info", "count"]
    ],
    "comment_count": [
        ["text_post_app_info", "direct_reply_count"],
        "comment_count", "commentCount",
        ["reply_info", "count"]
    ],
    "share_count": [
        ["text_post_app_info", "repost_count"],
        "repostCount", "share_count", "shareCount"
    ],
    "content": [
        ["caption", "text"],
        "caption", "text", "content"
    ],
    "author": [
        ["user", "username"], 
        ["owner", "username"],
        ["user", "handle"]
    ],
    "created_at": [
        "taken_at", "taken_at_timestamp", 
        "publish_date", "created_time"
    ],
    "post_id": [
        "pk", "id", "post_id"
    ],
    "code": [
        "code", "shortcode", "media_code"
    ]
}

def first_of(obj, *keys):
    """
    å¤šéµ fallback æ©Ÿåˆ¶ï¼šä¾åºå˜—è©¦å¤šå€‹å¯èƒ½çš„éµåï¼Œå›å‚³ç¬¬ä¸€å€‹éç©ºå€¼ã€‚
    æ”¯æ´å·¢ç‹€éµï¼š["parent", "child"] æœƒå– obj["parent"]["child"]
    """
    for key in keys:
        try:
            if isinstance(key, (list, tuple)):
                # å·¢ç‹€éµè™•ç†
                value = obj
                for sub_key in key:
                    if not isinstance(value, dict) or sub_key not in value:
                        value = None
                        break
                    value = value[sub_key]
            else:
                # å–®ä¸€éµè™•ç†
                value = obj.get(key) if isinstance(obj, dict) else None
            
            # æª¢æŸ¥å€¼æ˜¯å¦æœ‰æ•ˆï¼ˆé Noneã€ç©ºå­—ä¸²ã€ç©ºåˆ—è¡¨ã€ç©ºå­—å…¸ï¼‰
            if value not in (None, "", [], {}):
                return value
        except (KeyError, TypeError, AttributeError):
            continue
    return None


def find_post_dict(item: dict) -> Optional[dict]:
    """
    åœ¨ thread_item è£¡è‡ªå‹•æ‰¾åˆ°çœŸæ­£çš„è²¼æ–‡ dictã€‚
    æ”¯æ´ä¸åŒç‰ˆæœ¬çš„ GraphQL çµæ§‹è®ŠåŒ–ã€‚
    å›å‚³å«æœ‰ pk/id çš„é‚£å±¤ã€‚
    """
    # 1) å‚³çµ±çµæ§‹
    if 'post' in item and isinstance(item['post'], dict):
        return item['post']
        
    # 2) æ–°ç‰ˆçµæ§‹ï¼špost_info / postInfo / postV2
    for key in ('post_info', 'postInfo', 'postV2', 'media_data', 'thread_data'):
        if key in item and isinstance(item[key], dict):
            return item[key]
    
    # 3) æ·±åº¦æœå°‹ï¼šæ‰¾ç¬¬ä¸€å€‹æœ‰ pk æˆ– id çš„å­ dict
    def search_for_post(obj, max_depth=3):
        if max_depth <= 0:
            return None
            
        if isinstance(obj, dict):
            # æª¢æŸ¥ç•¶å‰å±¤æ˜¯å¦ç‚ºè²¼æ–‡ç‰©ä»¶
            if ('pk' in obj or 'id' in obj) and 'user' in obj:
                return obj
            # éæ­¸æœå°‹å­ç‰©ä»¶
            for value in obj.values():
                result = search_for_post(value, max_depth - 1)
                if result:
                    return result
        elif isinstance(obj, list) and obj:
            # æœå°‹åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹å…ƒç´ 
            return search_for_post(obj[0], max_depth - 1)
            
        return None
    
    return search_for_post(item)


def parse_post_data(post_data: dict, username: str) -> Optional[PostMetrics]:
    """
    å¼·å¥çš„è²¼æ–‡è§£æå™¨ï¼Œä½¿ç”¨å¤šéµ fallback æ©Ÿåˆ¶è™•ç†æ¬„ä½è®Šå‹•ã€‚
    æ”¯æ´ Threads GraphQL API çš„ä¸åŒç‰ˆæœ¬å’Œæ¬„ä½å‘½åè®ŠåŒ–ã€‚
    """
    # ä½¿ç”¨æ™ºèƒ½æœå°‹æ‰¾åˆ°çœŸæ­£çš„è²¼æ–‡ç‰©ä»¶
    post = find_post_dict(post_data)
    
    if not post:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ post ç‰©ä»¶ï¼Œæ”¶åˆ°çš„è³‡æ–™éµ: {list(post_data.keys())}")
        logging.info(f"âŒ post_data å…§å®¹ç¯„ä¾‹: {str(post_data)[:300]}...")
        
        # è‡ªå‹•å„²å­˜ç¬¬ä¸€ç­† raw JSON ä¾›åˆ†æ
        try:
            from .config import DEBUG_FAILED_ITEM_FILE
            if not DEBUG_FAILED_ITEM_FILE.exists():
                DEBUG_FAILED_ITEM_FILE.write_text(json.dumps(post_data, indent=2, ensure_ascii=False))
                logging.info(f"ğŸ“ å·²å„²å­˜å¤±æ•—ç¯„ä¾‹è‡³ {DEBUG_FAILED_ITEM_FILE}")
        except Exception:
            pass
            
        return None

    # ä½¿ç”¨å¼·å¥çš„æ¬„ä½è§£æ
    post_id = first_of(post, *FIELD_MAP["post_id"])
    code = first_of(post, *FIELD_MAP["code"])
    
    if not post_id:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ post_idï¼Œå¯ç”¨æ¬„ä½: {list(post.keys())}")
        return None
        
    if not code:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ codeï¼Œå¯ç”¨æ¬„ä½: {list(post.keys())}")
        return None

    url = f"https://www.threads.net/t/{code}"

    # ä½¿ç”¨å¤šéµ fallback è§£ææ‰€æœ‰æ¬„ä½
    author = first_of(post, *FIELD_MAP["author"]) or username
    content = first_of(post, *FIELD_MAP["content"]) or ""
    like_count = first_of(post, *FIELD_MAP["like_count"]) or 0
    comment_count = first_of(post, *FIELD_MAP["comment_count"]) or 0
    share_count = first_of(post, *FIELD_MAP["share_count"]) or 0
    created_at = first_of(post, *FIELD_MAP["created_at"])
    
    # åµæ¸¬æœªçŸ¥æ¬„ä½ï¼ˆç”¨æ–¼èª¿è©¦å’Œæ”¹é€²ï¼‰
    unknown_keys = set(post.keys()) - {
        'pk', 'id', 'post_id', 'code', 'shortcode', 'media_code',
        'user', 'owner', 'caption', 'text', 'content',
        'like_count', 'likeCount', 'feedback_info', 'like_info',
        'text_post_app_info', 'comment_count', 'commentCount', 'reply_info',
        'taken_at', 'taken_at_timestamp', 'publish_date', 'created_time',
        # å¸¸è¦‹ä½†ä¸é‡è¦çš„æ¬„ä½
        'media_type', 'has_liked', 'image_versions2', 'video_versions',
        'carousel_media', 'location', 'user_tags', 'usertags'
    }
    
    if unknown_keys:
        logging.debug(f"ğŸ” ç™¼ç¾æœªçŸ¥æ¬„ä½: {unknown_keys}")
        # å¯ä»¥é¸æ“‡å¯«å…¥æª”æ¡ˆä»¥ä¾›åˆ†æ
        try:
            with open("unknown_fields.log", "a", encoding="utf-8") as f:
                f.write(f"{json.dumps(list(unknown_keys))}\n")
        except Exception:
            pass  # å¯«æª”å¤±æ•—ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½

    # æˆåŠŸè§£æï¼Œè¨˜éŒ„éƒ¨åˆ†è³‡è¨Šä¾›é™¤éŒ¯
    logging.info(f"âœ… æˆåŠŸè§£æè²¼æ–‡ {post_id}: ä½œè€…={author}, è®šæ•¸={like_count}, å…§å®¹å‰50å­—={content[:50]}...")
    
    return PostMetrics(
        url=url,
        post_id=str(post_id),
        username=username,
        source="playwright",
        processing_stage="playwright_crawled",
        likes_count=int(like_count) if isinstance(like_count, (int, str)) and str(like_count).isdigit() else 0,
        comments_count=int(comment_count) if isinstance(comment_count, (int, str)) and str(comment_count).isdigit() else 0,
        reposts_count=int(share_count) if isinstance(share_count, (int, str)) and str(share_count).isdigit() else 0,
        content=content,
        created_at=created_at,
    )


class PlaywrightLogic:
    """
    ä½¿ç”¨ Playwright é€²è¡Œçˆ¬èŸ²çš„æ ¸å¿ƒé‚è¼¯ã€‚
    """
    def __init__(self):
        self.settings = get_settings().playwright
        self.known_queries = set()  # è¿½è¹¤å·²è¦‹éçš„æŸ¥è©¢åç¨±

    def _build_response_handler(self, username: str, posts: dict, task_id: str, max_posts: int, stream_callback):
        """å»ºç«‹ GraphQL å›æ‡‰è™•ç†å™¨ - ä½¿ç”¨çµæ§‹åˆ¤æ–·è€Œéåç¨±ç™½åå–®"""
        async def _handle_response(res):
            if not GRAPHQL_RE.search(res.url):
                return
                
            qname = res.request.headers.get("x-fb-friendly-name", "UNKNOWN")
            try:
                data = await res.json()
            except Exception:
                return  # é JSON å›æ‡‰ï¼Œç›´æ¥è·³é
                
            # çµæ§‹åˆ¤æ–·ï¼šåªè¦æœ‰ data.mediaData.edges å°±æ˜¯è²¼æ–‡è³‡æ–™
            edges = data.get("data", {}).get("mediaData", {}).get("edges", [])
            if not edges:
                return  # è·Ÿè²¼æ–‡ç„¡é—œï¼Œå¿½ç•¥
                
            # è§£æè²¼æ–‡ - æ”¯æ´æ–°èˆŠçµæ§‹çš„ fallback
            new_count = 0
            for edge in edges:
                # æ”¯æ´ thread_items / items çš„ fallback
                node = edge.get("node", {})
                thread_items = node.get("thread_items") or node.get("items") or []
                
                # è‡ªå‹•å„²å­˜ç¬¬ä¸€ç­†æˆåŠŸçš„ thread_item ä¾›åˆ†æ
                if thread_items and new_count == 0:
                    try:
                        from .config import SAMPLE_THREAD_ITEM_FILE
                        if not SAMPLE_THREAD_ITEM_FILE.exists():
                            SAMPLE_THREAD_ITEM_FILE.write_text(json.dumps(thread_items[0], indent=2, ensure_ascii=False))
                            logging.info(f"ğŸ“ å·²å„²å­˜æˆåŠŸç¯„ä¾‹è‡³ {SAMPLE_THREAD_ITEM_FILE}")
                    except Exception:
                        pass

                for item in thread_items:
                    parsed_post = parse_post_data(item, username)
                    if parsed_post and parsed_post.post_id not in posts:
                        posts[parsed_post.post_id] = parsed_post
                        new_count += 1
                        
            if new_count > 0:
                logging.info(f"âœ… [{qname}] +{new_count} (ç¸½ {len(posts)}/{max_posts})")
                # ä½¿ç”¨å›èª¿å‡½æ•¸ç™¼é€ä¸²æµè¨Šæ¯
                stream_callback(f"âœ… å¾ {qname} è§£æåˆ° {new_count} å‰‡æ–°è²¼æ–‡ï¼Œç¸½æ•¸: {len(posts)}")
                
            # è¨˜éŒ„æ–°ç™¼ç¾çš„æŸ¥è©¢åç¨±ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
            if qname not in self.known_queries:
                self.known_queries.add(qname)
                # å¯é¸ï¼šå¯«å…¥æª”æ¡ˆä»¥ä¾›æ—¥å¾Œåˆ†æ
                try:
                    from pathlib import Path
                    with open("seen_queries.txt", "a", encoding="utf-8") as f:
                        f.write(f"{qname}\n")
                except Exception:
                    pass  # å¯«æª”å¤±æ•—ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½
                    
        return _handle_response

    async def fetch_posts(
        self,
        username: str,
        max_posts: int,
        auth_json_content: Dict,
        task_id: str = None
    ) -> AsyncIterable[Dict]:
        """
        ä½¿ç”¨æŒ‡å®šçš„èªè­‰å…§å®¹çˆ¬å–è²¼æ–‡ã€‚

        Args:
            username: ç›®æ¨™ä½¿ç”¨è€…åç¨± (ä¸å« @)
            max_posts: æœ€å¤§è²¼æ–‡æ•¸
            auth_json_content: auth.json çš„å…§å®¹
            task_id: ä»»å‹™ ID

        Yields:
            ä¸²æµå›å‚³çš„ç‹€æ…‹å’Œè³‡æ–™
        """
        target_url = f"https://www.threads.com/@{username}"
        posts = {}
        
        # 1. å®‰å…¨åœ°è™•ç† auth.json
        # ä½¿ç”¨æœ‰å”¯ä¸€æ€§çš„è‡¨æ™‚æª”æ¡ˆï¼Œä¸¦ç¢ºä¿ä»»å‹™çµæŸå¾Œåˆªé™¤
        auth_file = Path(tempfile.gettempdir()) / f"{task_id or uuid.uuid4()}_auth.json"
        
        try:
            with open(auth_file, "w") as f:
                json.dump(auth_json_content, f)

            yield stream_status(TaskState.RUNNING, "Playwright çˆ¬èŸ²æº–å‚™ä¸­...", 0.1)

            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=self.settings.headless,
                    timeout=self.settings.navigation_timeout,
                    args=["--no-sandbox", "--disable-dev-shm-usage"]
                )
                ctx = await browser.new_context(
                    storage_state=str(auth_file),
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
                    viewport={"width": 1920, "height": 1080},
                    locale="en-US",
                    has_touch=True,
                    accept_downloads=False
                )
                page = await ctx.new_page()

                # ä¿®æ­£ console handlerï¼ˆ.text æ˜¯å±¬æ€§ä¸æ˜¯æ–¹æ³•ï¼‰
                page.on("console", lambda m: logging.info(f"CONSOLE [{m.type}] {m.text}"))

                # å»ºç«‹ä¸²æµå›èª¿å‡½æ•¸ï¼ˆç”¨ list å„²å­˜è¨Šæ¯ä¾›å¾ŒçºŒ yieldï¼‰
                stream_messages = []
                def add_stream_message(message):
                    stream_messages.append(stream_text(message))

                # å…ˆæ›è¼‰ response listenerï¼ˆåœ¨ goto ä¹‹å‰ï¼‰
                response_handler = self._build_response_handler(
                    username, posts, task_id, max_posts, add_stream_message
                )
                page.on("response", response_handler)

                yield stream_text(f"å°è¦½è‡³ç›®æ¨™é é¢: {target_url}")
                await page.goto(target_url, wait_until="networkidle", timeout=self.settings.navigation_timeout)

                # æª¢æŸ¥ç™»å…¥ç‹€æ…‹
                try:
                    current_url = page.url
                    is_login_page = "/login" in current_url or await page.locator("text=Log in").count() > 0
                    if is_login_page:
                        yield stream_text("âš ï¸ åµæ¸¬åˆ°ç™»å…¥é é¢ï¼Œèªè­‰å¯èƒ½å·²éæœŸ")
                        logging.warning(f"ç›®å‰ URL: {current_url}ï¼Œå¯èƒ½éœ€è¦é‡æ–°ç”¢ç”Ÿ auth.json")
                    else:
                        yield stream_text("âœ… æˆåŠŸè¼‰å…¥ä½¿ç”¨è€…é é¢")
                except Exception as e:
                    logging.warning(f"æª¢æŸ¥ç™»å…¥ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

                yield stream_text("é é¢è¼‰å…¥å®Œæˆï¼Œé–‹å§‹æ»¾å‹•...")

                # --- æ»¾å‹•èˆ‡å»¶é²é‚è¼¯ ---
                scroll_attempts_without_new_posts = 0
                max_retries = 5

                while len(posts) < max_posts:
                    posts_before_scroll = len(posts)
                    
                    await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")

                    try:
                        # ç­‰å¾… GraphQL è«‹æ±‚ï¼Œå¢åŠ ç©©å®šæ€§
                        async with page.expect_response(lambda res: GRAPHQL_RE.search(res.url), timeout=10000):
                            pass
                    except PlaywrightTimeoutError:
                        logging.warning(f"â³ [Task: {task_id}] æ»¾å‹•å¾Œç­‰å¾…ç¶²è·¯å›æ‡‰é€¾æ™‚ã€‚")

                    # åŠ å…¥æ‚¨æŒ‡å®šçš„éš¨æ©Ÿå»¶é²
                    delay = random.uniform(2.0, 3.5)
                    await asyncio.sleep(delay)

                    # ç™¼é€ç´¯ç©çš„ä¸²æµè¨Šæ¯
                    for message in stream_messages:
                        yield message
                    stream_messages.clear()

                    if len(posts) == posts_before_scroll:
                        scroll_attempts_without_new_posts += 1
                        yield stream_text(f"æ»¾å‹•å¾Œæœªç™¼ç¾æ–°è²¼æ–‡ (å˜—è©¦ {scroll_attempts_without_new_posts}/{max_retries})")
                        if scroll_attempts_without_new_posts >= max_retries:
                            yield stream_text("å·²é”é é¢æœ«ç«¯æˆ–ç„¡æ–°å…§å®¹ï¼Œåœæ­¢æ»¾å‹•ã€‚")
                            break
                    else:
                        scroll_attempts_without_new_posts = 0



                await ctx.close()

            # --- æ•´ç†ä¸¦å›å‚³çµæœ ---
            final_posts = list(posts.values())
            logging.info(f"ğŸ”„ [Task: {task_id}] æº–å‚™ç™¼é€æœ€çµ‚è³‡æ–™ï¼šå…± {len(final_posts)} å‰‡è²¼æ–‡")
            
            batch = PostMetricsBatch(
                posts=final_posts[:max_posts], # ç¢ºä¿ä¸æœƒè¶…éè«‹æ±‚çš„æ•¸é‡
                username=username,
                total_count=len(final_posts),
                processing_stage="playwright_completed"
            )
            
            logging.info(f"ğŸ“¤ [Task: {task_id}] ç™¼é€ PostMetricsBatchï¼š{len(batch.posts)} å‰‡è²¼æ–‡")
            yield stream_data(batch.dict(), final=True)
            logging.info(f"âœ… [Task: {task_id}] æœ€çµ‚è³‡æ–™å·²ç™¼é€å®Œæˆ")

        except Exception as e:
            logging.error(f"âŒ [Task: {task_id}] Playwright çˆ¬å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            yield stream_error(f"Playwright çˆ¬å–å¤±æ•—: {e}")
        finally:
            # æš«æ™‚è¨»è§£æ‰ï¼Œä»¥ä¾¿é™¤éŒ¯
            # if auth_file.exists():
            #     auth_file.unlink()
            #     logging.info(f"ğŸ—‘ï¸ [Task: {task_id}] å·²åˆªé™¤è‡¨æ™‚èªè­‰æª”æ¡ˆ: {auth_file}")
            pass 