import uuid
import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional
import json
import datetime
from pathlib import Path
import logging

from .playwright_logic import PlaywrightLogic
from common.models import PostMetricsBatch
from common.a2a import stream_error, TaskState
from common.mcp_client import agent_startup, agent_shutdown, get_mcp_client
from common.settings import get_settings

@asynccontextmanager
async def lifespan(app: FastAPI):
    """æ‡‰ç”¨ç”Ÿå‘½é€±æœŸç®¡ç†"""
    # å•Ÿå‹•æ™‚è¨»å†Šåˆ° MCP Server
    settings = get_settings()
    
    capabilities = {
        "browser_automation": True,
        "dynamic_content": True,
        "threads_scraping": True,
        "auth_handling": True
    }
    
    metadata = {
        "version": "1.0.0",
        "author": "AI Assistant",
        "max_concurrent_crawls": 3,
        "supported_platforms": ["threads"],
        "requires_auth": True
    }
    
    success = await agent_startup(capabilities, metadata)
    if success:
        print("âœ… Playwright Crawler Agent registered to MCP Server")
    else:
        print("âŒ Failed to register Playwright Crawler Agent to MCP Server")
    
    yield
    
    # é—œé–‰æ™‚æ¸…ç†
    await agent_shutdown()
    print("ğŸ›‘ Playwright Crawler Agent shutdown completed")


app = FastAPI(
    title="Playwright Crawler Agent",
    version="1.0.0",
    description="ä½¿ç”¨ Playwright å’Œä½¿ç”¨è€…æä¾›çš„èªè­‰ç‹€æ…‹ä¾†çˆ¬å– Threads è²¼æ–‡ã€‚",
    lifespan=lifespan
)

def json_serializer(obj):
    """JSON serializer for objects not serializable by default json code"""
    if isinstance(obj, (datetime.datetime, datetime.date)):
        return obj.isoformat()
    raise TypeError ("Type %s not serializable" % type(obj))

class CrawlRequest(BaseModel):
    username: str = Field(..., description="è¦çˆ¬å–çš„ Threads ä½¿ç”¨è€…åç¨± (ä¸å« @)")
    max_posts: int = Field(default=100, gt=0, le=500, description="è¦çˆ¬å–çš„æœ€å¤§è²¼æ–‡æ•¸é‡")
    auth_json_content: Dict[str, Any] = Field(..., description="åŒ…å«èªè­‰ cookies å’Œç‹€æ…‹çš„ auth.json å…§å®¹")
    task_id: Optional[str] = Field(default=None, description="ä»»å‹™ IDï¼Œç”¨æ–¼é€²åº¦è¿½è¹¤")

# --- Agent Instance ---
playwright_logic = PlaywrightLogic()

# --- API Endpoints ---
@app.post("/v1/playwright/crawl", response_model=PostMetricsBatch, tags=["Plan F"])
async def crawl_and_get_batch(request: CrawlRequest):
    """
    æ¥æ”¶çˆ¬å–è«‹æ±‚ï¼ŒåŸ·è¡Œ Playwright çˆ¬èŸ²ï¼Œä¸¦ä¸€æ¬¡æ€§è¿”å›å®Œæ•´çš„ PostMetricsBatchã€‚
    èªè­‰å…§å®¹ç”±è«‹æ±‚æ–¹åœ¨ request body ä¸­æä¾›ã€‚
    """
    # ä½¿ç”¨å‚³å…¥çš„ task_idï¼Œå¦‚æœæ²’æœ‰å‰‡ç”Ÿæˆæ–°çš„
    task_id = request.task_id or str(uuid.uuid4())
    logic = PlaywrightLogic()

    try:
        batch = await logic.fetch_posts(
            username=request.username,
            max_posts=request.max_posts,
            auth_json_content=request.auth_json_content, # ä½¿ç”¨å‚³å…¥çš„èªè­‰å…§å®¹
            task_id=task_id
        )
        return batch
    except Exception as e:
        logging.error(f"Crawling failed in main: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health", tags=["Monitoring"])
async def health_check():
    """
    åŸ·è¡Œå¥åº·æª¢æŸ¥ã€‚
    æœªä¾†å¯ä»¥æ“´å……æ­¤æª¢æŸ¥ä»¥é©—è­‰ Playwright ç’°å¢ƒæ˜¯å¦æ­£å¸¸ã€‚
    """
    return {"status": "healthy", "service": "Playwright Crawler Agent"}

# MCP æ•´åˆç«¯é»
@app.get("/mcp/capabilities", tags=["MCP"])
async def get_capabilities():
    """ç²å– Agent èƒ½åŠ›"""
    return {
        "browser_automation": True,
        "dynamic_content": True,
        "threads_scraping": True,
        "auth_handling": True,
        "max_concurrent": 3,
        "supported_formats": ["PostMetricsBatch"]
    }

@app.get("/mcp/discover", tags=["MCP"])
async def discover_other_agents():
    """ç™¼ç¾å…¶ä»– Agent"""
    try:
        mcp_client = get_mcp_client()
        
        # ç™¼ç¾ vision agent ç”¨æ–¼å¾ŒçºŒè™•ç†
        vision_agents = await mcp_client.discover_agents(role="vision", status="ONLINE")
        analysis_agents = await mcp_client.discover_agents(role="analysis", status="ONLINE")
        
        return {
            "vision_agents": vision_agents,
            "analysis_agents": analysis_agents,
            "total_discovered": len(vision_agents) + len(analysis_agents)
        }
    except Exception as e:
        logging.error(f"Failed to discover agents: {e}")
        return {"error": str(e), "vision_agents": [], "analysis_agents": []}

@app.post("/mcp/request-media-download", tags=["MCP"])
async def request_media_download(
    post_url: str,
    media_urls: list[str],
    background_tasks: BackgroundTasks
):
    """è«‹æ±‚ MCP Server ä¸‹è¼‰åª’é«”æª”æ¡ˆ"""
    try:
        mcp_client = get_mcp_client()
        result = await mcp_client.download_media(post_url, media_urls)
        
        logging.info(f"Media download requested for {post_url}: {len(media_urls)} files")
        return result
        
    except Exception as e:
        logging.error(f"Failed to request media download: {e}")
        raise HTTPException(status_code=500, detail=str(e)) 