"""
è²¼æ–‡æ•¸æ“šè§£æå™¨

è² è²¬å¾ GraphQL API éŸ¿æ‡‰ä¸­è§£æå‡º PostMetrics å°è±¡
ä½¿ç”¨å¼·å¥çš„å¤šéµ fallback æ©Ÿåˆ¶è™•ç†æ¬„ä½è®Šå‹•
"""

import json
import logging
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any

from common.models import PostMetrics
from common.utils import first_of, parse_thread_item, generate_post_url
from .number_parser import parse_number
from ..config.field_mappings import FIELD_MAP


# èª¿è©¦æª”æ¡ˆè·¯å¾‘
DEBUG_DIR = Path(__file__).parent.parent / "debug"
DEBUG_DIR.mkdir(exist_ok=True)
DEBUG_FAILED_ITEM_FILE = DEBUG_DIR / "failed_post_sample.json"


def parse_post_data(thread_item: Dict[str, Any], username: str) -> Optional[PostMetrics]:
    """
    å¼·å¥çš„è²¼æ–‡è§£æå™¨ï¼Œä½¿ç”¨å¤šéµ fallback æ©Ÿåˆ¶è™•ç†æ¬„ä½è®Šå‹•ã€‚
    æ”¯æ´ Threads GraphQL API çš„ä¸åŒç‰ˆæœ¬å’Œæ¬„ä½å‘½åè®ŠåŒ–ã€‚
    """
    # ä½¿ç”¨æ™ºèƒ½æœå°‹æ‰¾åˆ°çœŸæ­£çš„è²¼æ–‡ç‰©ä»¶
    post = parse_thread_item(thread_item)
    
    if not post:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ post ç‰©ä»¶ï¼Œæ”¶åˆ°çš„è³‡æ–™éµ: {list(thread_item.keys())}")
        logging.info(f"âŒ thread_item å…§å®¹ç¯„ä¾‹: {str(thread_item)[:300]}...")
        
        # è‡ªå‹•å„²å­˜ç¬¬ä¸€ç­† raw JSON ä¾›åˆ†æ
        try:
            if not DEBUG_FAILED_ITEM_FILE.exists():
                DEBUG_FAILED_ITEM_FILE.write_text(
                    json.dumps(thread_item, indent=2, ensure_ascii=False),
                    encoding="utf-8" # æ˜ç¢ºæŒ‡å®š UTF-8
                )
                logging.info(f"ğŸ“ å·²å„²å­˜å¤±æ•—ç¯„ä¾‹è‡³ {DEBUG_FAILED_ITEM_FILE}")
        except Exception:
            pass  # å¯«æª”å¤±æ•—ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½
            
        return None

    # ä½¿ç”¨å¼·å¥çš„æ¬„ä½è§£æ
    post_id = first_of(post, *FIELD_MAP["post_id"])
    code = first_of(post, *FIELD_MAP["code"])
    
    if not post_id:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ post_idï¼Œå¯ç”¨æ¬„ä½: {list(post.keys())}")
        return None
        
    if not code:
        logging.info(f"âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ codeï¼Œå¯ç”¨æ¬„ä½: {list(post.keys())}")
        return None

    # --- URL ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºçš„æ ¼å¼ ---
    # èˆŠæ ¼å¼ (éŒ¯èª¤): f"https://www.threads.net/t/{code}"
    # æ–°æ ¼å¼ (æ­£ç¢º): f"https://www.threads.com/@{username}/post/{code}"
    url = generate_post_url(username, code)

    # ä½¿ç”¨å¤šéµ fallback è§£ææ‰€æœ‰æ¬„ä½
    author = first_of(post, *FIELD_MAP["author"]) or username
    content = first_of(post, *FIELD_MAP["content"]) or ""
    like_count = parse_number(first_of(post, *FIELD_MAP["like_count"]))
    comment_count = parse_number(first_of(post, *FIELD_MAP["comment_count"]))
    share_count = parse_number(first_of(post, *FIELD_MAP["share_count"]))
    repost_count = parse_number(first_of(post, *FIELD_MAP["repost_count"]))
    created_at = first_of(post, *FIELD_MAP["created_at"])
    
    # ğŸ”¥ èª¿è©¦ä¿¡æ¯ï¼šæª¢æŸ¥åŸå§‹æ•¸æ“š
    logging.debug(f"ğŸ”¥ like={first_of(post, *FIELD_MAP['like_count'])!r} comment={first_of(post, *FIELD_MAP['comment_count'])!r} from raw post_id={post_id}")
    logging.debug(f"ğŸ”¥ è§£æå¾Œ: like={like_count} comment={comment_count} share={share_count} repost={repost_count}")
    
    # åµæ¸¬æœªçŸ¥æ¬„ä½ï¼ˆç”¨æ–¼èª¿è©¦å’Œæ”¹é€²ï¼‰
    unknown_keys = set(post.keys()) - {
        'pk', 'id', 'post_id', 'code', 'shortcode', 'media_code',
        'user', 'owner', 'caption', 'text', 'content',
        'like_count', 'likeCount', 'feedback_info', 'like_info',
        'text_post_app_info', 'comment_count', 'commentCount', 'reply_info',
        'taken_at', 'taken_at_timestamp', 'publish_date', 'created_time',
        # å¸¸è¦‹ä½†ä¸é‡è¦çš„æ¬„ä½
        'media_type', 'has_liked', 'image_versions2', 'video_versions',
        'carousel_media', 'location', 'user_tags', 'usertags'
    }
    
    if unknown_keys:
        logging.debug(f"ğŸ” ç™¼ç¾æœªçŸ¥æ¬„ä½: {unknown_keys}")
        # å¯ä»¥é¸æ“‡å¯«å…¥æª”æ¡ˆä»¥ä¾›åˆ†æ
        try:
            with open("unknown_fields.log", "a", encoding="utf-8") as f:
                f.write(f"{json.dumps(list(unknown_keys))}\n")
        except Exception:
            pass  # å¯«æª”å¤±æ•—ä¸å½±éŸ¿ä¸»è¦åŠŸèƒ½

    # --- MEDIA -------------------------------------------------------------
    images, videos = [], []

    def append_image(url):
        if url and url not in images:
            images.append(url)

    def append_video(url):
        if url and url not in videos:
            videos.append(url)

    def best_candidate(candidates: list[dict], prefer_mp4=False):
        """
        å¾ image_versions2 æˆ– video_versions è£¡æŒ‘ã€Œå¯¬åº¦æœ€å¤§çš„é‚£å€‹ã€URL
        """
        if not candidates:
            return None
        key = "url"
        return max(candidates, key=lambda c: c.get("width", 0)).get(key)

    # 1) å–®åœ– / å–®ç‰‡
    if "image_versions2" in post:
        append_image(best_candidate(post["image_versions2"].get("candidates", [])))
    if "video_versions" in post:
        append_video(best_candidate(post.get("video_versions", []), prefer_mp4=True))

    # 2) è¼ªæ’­ carousel_media (åŠ å…¥ None çš„å®‰å…¨è™•ç†)
    for media in post.get("carousel_media") or []:
        if "image_versions2" in media:
            append_image(best_candidate(media["image_versions2"].get("candidates", [])))
        if "video_versions" in media:
            append_video(best_candidate(media.get("video_versions", []), prefer_mp4=True))
    # -----------------------------------------------------------------------

    # æˆåŠŸè§£æï¼Œè¨˜éŒ„éƒ¨åˆ†è³‡è¨Šä¾›é™¤éŒ¯
    logging.info(f"âœ… æˆåŠŸè§£æè²¼æ–‡ {post_id}: ä½œè€…={author}, è®šæ•¸={like_count}, åœ–ç‰‡={len(images)}, å½±ç‰‡={len(videos)}")
    
    # çµ±ä¸€ post_id æ ¼å¼ï¼šä½¿ç”¨ username_code è€Œä¸æ˜¯åŸå§‹çš„æ•¸å­— ID
    unified_post_id = f"{username}_{code}"
    
    # çµ±ä¸€å°åŒ—æ™‚é–“ï¼štimestampâ†’UTCâ†’å°åŒ—ï¼Œæˆ–ç„¡å€¼æ™‚ç”¨å°åŒ—ç¾åœ¨
    if created_at and isinstance(created_at, (int, float)):
        utc_dt = datetime.fromtimestamp(created_at, tz=timezone.utc)
        created_taipei = utc_dt.astimezone(timezone(timedelta(hours=8))).replace(tzinfo=None)
    else:
        created_taipei = datetime.now(timezone(timedelta(hours=8))).replace(tzinfo=None)

    return PostMetrics(
        url=url,
        post_id=unified_post_id,  # ä½¿ç”¨çµ±ä¸€æ ¼å¼çš„ post_id
        username=username,
        source="playwright",
        processing_stage="playwright_crawled",
        likes_count=like_count,      # å·²ç¶“é€šé parse_number() è™•ç†
        comments_count=comment_count, # å·²ç¶“é€šé parse_number() è™•ç†
        reposts_count=repost_count,   # å·²ç¶“é€šé parse_number() è™•ç†
        shares_count=share_count,     # å·²ç¶“é€šé parse_number() è™•ç†
        content=content,
        created_at=created_taipei,
        images=images,
        videos=videos,
        # æ–°å¢ï¼šç›´æ¥å¾ API è§£æ views_countï¼ˆæŒ‰æŒ‡å¼•å„ªå…ˆå˜—è©¦ APIï¼‰
        views_count=parse_number(first_of(post, *FIELD_MAP["view_count"])),
    )