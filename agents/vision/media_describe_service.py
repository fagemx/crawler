from typing import List, Dict, Any, Optional
import asyncio
import json

from common.db_client import get_db_client
from services.rustfs_client import get_rustfs_client
from agents.vision.gemini_vision import GeminiVisionAnalyzer
from common.image_primary_filter import compute_rule_score, decide_is_primary


class MediaDescribeService:
    """提供媒體描述的清單生成與執行（寫回 media_descriptions）。"""

    def __init__(self):
        self.analyzer = GeminiVisionAnalyzer()

    async def get_account_describe_stats(self, limit: int = 50) -> List[Dict[str, Any]]:
        """統計各帳號媒體描述現況（待描述/已描述）。"""
        db = await get_db_client()
        query = f"""
        WITH mf AS (
            SELECT id, post_url, media_type
            FROM media_files
            WHERE download_status = 'completed'
        ),
        pwm AS (
            SELECT url, username FROM playwright_post_metrics
        ),
        joined AS (
            SELECT p.username, m.id AS media_id, m.media_type
            FROM mf m
            JOIN pwm p ON p.url = m.post_url
        ),
        joined_d AS (
            SELECT j.username, j.media_id, j.media_type,
                   CASE WHEN d.media_id IS NULL THEN 0 ELSE 1 END AS is_desc
            FROM joined j
            LEFT JOIN media_descriptions d ON d.media_id = j.media_id
        )
        SELECT username,
               COUNT(*) FILTER (WHERE media_type='image' AND is_desc=0) AS pending_images,
               COUNT(*) FILTER (WHERE media_type='video' AND is_desc=0) AS pending_videos,
               COUNT(*) FILTER (WHERE media_type='image' AND is_desc=1) AS completed_images,
               COUNT(*) FILTER (WHERE media_type='video' AND is_desc=1) AS completed_videos,
               COUNT(*) FILTER (WHERE is_desc=0) AS pending_total,
               COUNT(*) FILTER (WHERE is_desc=1) AS completed_total
        FROM joined_d
        GROUP BY username
        ORDER BY pending_total DESC, completed_total DESC
        LIMIT {limit}
        """
        return await db.fetch_all(query)

    async def build_describe_plan(
        self,
        username: str,
        media_types: List[str],
        sort_by: str = "none",
        top_k: Optional[int] = None,
        only_undesc: bool = True,
        only_primary: bool = True,
        primary_threshold: float = 0.7,
    ) -> List[Dict[str, Any]]:
        """建立描述清單，回傳含 media_id/post_url/original_url/media_type 的列表。"""
        db = await get_db_client()

        # 先取貼文集合（排序 Top-N）
        post_filter_cte = ""
        if sort_by and sort_by != "none" and top_k and isinstance(top_k, int):
            # 使用 COALESCE 避免 NULL 影響排序
            sort_expr = {
                "views": "COALESCE(views_count, 0)",
                "likes": "COALESCE(likes_count, 0)",
                "comments": "COALESCE(comments_count, 0)",
                "reposts": "COALESCE(reposts_count, 0)",
            }.get(sort_by, None)
            if sort_expr:
                post_filter_cte = f"""
                , top_posts AS (
                    SELECT url
                    FROM playwright_post_metrics
                    WHERE replace(lower(username),'@','') = replace(lower($1),'@','')
                    ORDER BY {sort_expr} DESC NULLS LAST
                    LIMIT {top_k}
                )
                """

        base_posts = "WHERE replace(lower(username),'@','') = replace(lower($1),'@','')" if not post_filter_cte else "WHERE url IN (SELECT url FROM top_posts)"
        query = f"""
        WITH
        {post_filter_cte}
        base AS (
            SELECT url, username FROM playwright_post_metrics {base_posts}
        )
        , completed AS (
            SELECT mf.*
            FROM media_files mf
            WHERE mf.download_status = 'completed'
        )
        , described AS (
            SELECT d.media_id FROM media_descriptions d
        )
        SELECT mf.id AS media_id, mf.post_url, mf.original_url, mf.media_type, mf.rustfs_url,
               mf.width, mf.height, mf.file_size,
               COALESCE((mf.metadata->>'primary_score')::float, NULL) AS primary_score,
               COALESCE((mf.metadata->>'is_primary')::bool, NULL) AS is_primary
        FROM completed mf
        JOIN base b ON b.url = mf.post_url
        WHERE mf.media_type = ANY($2)
        """

        mt_array = media_types
        rows = await db.fetch_all(query, username, mt_array)

        if only_undesc and rows:
            # 直接過濾掉已存在描述的 media_id（用 IN 子查詢避免佔位）
            ids = [r["media_id"] for r in rows]
            if ids:
                placeholders = ",".join([str(int(i)) for i in ids])
                desc_rows = await db.fetch_all(
                    f"SELECT media_id FROM media_descriptions WHERE media_id IN ({placeholders})"
                )
                described = {d["media_id"] for d in desc_rows}
                rows = [r for r in rows if r["media_id"] not in described]

        # 規則篩選（第一段）：若 only_primary
        if only_primary and rows:
            # 對缺少標記的項目進行規則打分，並即時寫回 metadata
            to_update = []
            for r in rows:
                if r.get("is_primary") is None and r.get("media_type") == 'image':
                    score, reason = compute_rule_score(r)
                    r["primary_score"] = score
                    r["primary_reason"] = reason
                    r["is_primary"] = decide_is_primary(score, primary_threshold)
                    to_update.append((r["media_id"], score, r["is_primary"], reason))

            if to_update:
                async with (await get_db_client()).get_connection() as conn:
                    for media_id, score, is_primary, reason in to_update:
                        # 合併寫入 metadata 欄位
                        await conn.execute(
                            """
                            UPDATE media_files
                            SET metadata = COALESCE(metadata, '{}'::jsonb) ||
                                           jsonb_build_object('primary_score', $2::text, 'is_primary', $3::text, 'primary_reason', $4::text)
                            WHERE id = $1
                            """,
                            media_id, str(score), 'true' if is_primary else 'false', reason
                        )

            # 最終按照標記/分數過濾
            filtered = []
            for r in rows:
                score = r.get("primary_score")
                is_primary = r.get("is_primary")
                if is_primary is True:
                    filtered.append(r)
                elif is_primary is False:
                    continue
                elif score is not None and score >= primary_threshold:
                    filtered.append(r)
            rows = filtered

        return rows

    async def run_describe(self, items: List[Dict[str, Any]], overwrite: bool = True, attach_post_text: bool = True) -> Dict[str, Any]:
        """執行媒體描述，寫入 media_descriptions。"""
        db = await get_db_client()
        client = await get_rustfs_client()  # 若需要從 RustFS 讀回檔案可擴充

        success, failed = 0, 0
        details: List[Dict[str, Any]] = []

        # 預讀 post 內容（圖片描述要附主貼文內文）
        post_text_cache: Dict[str, str] = {}

        async with db.get_connection() as conn:
            for item in items:
                media_id = item["media_id"]
                post_url = item["post_url"]
                original_url = item["original_url"]
                media_type = item["media_type"]
                try:
                    # 0. 實時重複檢查（防止並發競爭導致重複描述）
                    if not overwrite:
                        existing = await conn.fetchrow("SELECT id FROM media_descriptions WHERE media_id = $1", media_id)
                        if existing:
                            details.append({"media_id": media_id, "status": "skipped", "reason": "already_described"})
                            continue

                    # 1. 若為圖片且標記為非主貼圖，則跳過
                    if item.get("media_type") == 'image':
                        is_primary = item.get("is_primary")
                        if is_primary is False:
                            details.append({"media_id": media_id, "status": "skipped", "reason": "not_primary"})
                            continue

                    # 1. 下載媒體（優先 RustFS，失敗回原始 URL）
                    import httpx
                    media_bytes = None
                    mime = ""

                    rustfs_url = item.get("rustfs_url")
                    if rustfs_url:
                        # 將資料庫中的 URL 轉為可讀的（優先 presigned）
                        try:
                            # 解析出 key：{base}/{bucket}/{key}
                            prefix = f"{client.base_url}/{client.bucket_name}/"
                            key = rustfs_url[len(prefix):] if rustfs_url.startswith(prefix) else None
                            presigned = client.get_public_or_presigned_url(key or '', prefer_presigned=True) if key else rustfs_url
                            async with httpx.AsyncClient(timeout=60.0) as http:
                                resp = await http.get(presigned, follow_redirects=True)
                                resp.raise_for_status()
                                media_bytes = resp.content
                                mime = resp.headers.get("content-type", "") or mime
                        except Exception:
                            media_bytes = None

                    if media_bytes is None:
                        async with httpx.AsyncClient(timeout=60.0) as http:
                            resp = await http.get(original_url, follow_redirects=True)
                            resp.raise_for_status()
                            media_bytes = resp.content
                            mime = resp.headers.get("content-type", "") or mime

                    # 2. 準備提示（圖片附主貼文內文）
                    extra_text = ""
                    if attach_post_text and media_type == 'image':
                        if post_url not in post_text_cache:
                            row = await conn.fetchrow("SELECT content FROM playwright_post_metrics WHERE url = $1", post_url)
                            post_text_cache[post_url] = (row["content"] if row and row["content"] else "")
                        if post_text_cache[post_url]:
                            extra_text = f"貼文內文：\n{post_text_cache[post_url]}"

                    # 3. 呼叫 Gemini
                    if media_type == 'image':
                        # 將貼文原文作為 extra_text 提供給模型，改善情境判讀
                        result = await self.analyzer.analyze_media(media_bytes, mime or 'image/jpeg', extra_text=extra_text)
                        prompt_text = self.analyzer.image_prompt + ("\n\n" + (f"貼文原文：\n{extra_text}" if extra_text else ""))
                    else:
                        result = await self.analyzer.analyze_media(media_bytes, mime or 'video/mp4')
                        prompt_text = self.analyzer.video_prompt

                    # 4. 規整輸出為 JSON（允許模型回傳文字時包裝）
                    if not isinstance(result, (dict, list)):
                        try:
                            result = json.loads(str(result))
                        except Exception:
                            result = {"raw": str(result)}

                    # 5. 原子性覆蓋或新增（使用 transaction + advisory lock 防止並發重複）
                    async with conn.transaction():
                        # 每個 media_id 拿一把交易級別鎖，序列化同一資源的並發寫入
                        await conn.execute("SELECT pg_advisory_xact_lock($1)", media_id)

                        if overwrite:
                            # 覆蓋模式：先刪除，再插入
                            await conn.execute(
                                """
                                DELETE FROM media_descriptions WHERE media_id = $1
                                """,
                                media_id
                            )
                            await conn.execute(
                                """
                                INSERT INTO media_descriptions
                                (media_id, post_url, username, media_type, model, prompt, response_json, language, status, created_at)
                                SELECT $1, mf.post_url, pwm.username, $2, $3, $4, $5, 'zh-TW', 'completed', NOW()
                                FROM media_files mf
                                JOIN playwright_post_metrics pwm ON pwm.url = mf.post_url
                                WHERE mf.id = $1
                                """,
                                media_id, media_type, "gemini-2.5-pro", prompt_text, json.dumps(result, ensure_ascii=False)
                            )
                        else:
                            # 非覆蓋：僅在不存在時插入
                            await conn.execute(
                                """
                                INSERT INTO media_descriptions
                                (media_id, post_url, username, media_type, model, prompt, response_json, language, status, created_at)
                                SELECT $1, mf.post_url, pwm.username, $2, $3, $4, $5, 'zh-TW', 'completed', NOW()
                                FROM media_files mf
                                JOIN playwright_post_metrics pwm ON pwm.url = mf.post_url
                                WHERE mf.id = $1
                                  AND NOT EXISTS (SELECT 1 FROM media_descriptions d WHERE d.media_id = $1)
                                """,
                                media_id, media_type, "gemini-2.5-pro", prompt_text, json.dumps(result, ensure_ascii=False)
                            )

                    success += 1
                    details.append({"media_id": media_id, "status": "completed"})
                except Exception as e:
                    failed += 1
                    details.append({"media_id": media_id, "status": "failed", "error": str(e)})

        return {"total": len(items), "success": success, "failed": failed, "details": details}


    async def get_undesc_summary_by_user(self, username: str, media_types: List[str], limit: int = 20) -> List[Dict[str, Any]]:
        """查詢某帳號尚未描述的貼文摘要（每貼文未描述媒體數）。"""
        db = await get_db_client()
        query = """
        SELECT mf.post_url,
               COUNT(*) FILTER (WHERE mf.media_type='image') AS pending_images,
               COUNT(*) FILTER (WHERE mf.media_type='video') AS pending_videos,
               COUNT(*) AS pending_total
        FROM media_files mf
        JOIN playwright_post_metrics pwm ON pwm.url = mf.post_url
        WHERE replace(lower(pwm.username),'@','') = replace(lower($1),'@','')
          AND mf.download_status = 'completed'
          AND mf.media_type = ANY($2)
          AND NOT EXISTS (
            SELECT 1 FROM media_descriptions d WHERE d.media_id = mf.id
          )
        GROUP BY mf.post_url
        ORDER BY pending_total DESC
        LIMIT $3
        """
        return await db.fetch_all(query, username, media_types, limit)

    async def get_descriptions_by_post(self, post_url: str) -> List[Dict[str, Any]]:
        """取得單篇貼文的描述結果列表。"""
        db = await get_db_client()
        query = """
        SELECT d.media_id, d.post_url, d.media_type, d.model, d.prompt, d.response_json, d.status, d.created_at,
               mf.original_url, mf.rustfs_url
        FROM media_descriptions d
        JOIN media_files mf ON mf.id = d.media_id
        WHERE d.post_url = $1
        ORDER BY d.created_at DESC
        """
        return await db.fetch_all(query, post_url)

    async def get_recent_descriptions_by_user(self, username: str, media_types: List[str], limit: int = 50) -> List[Dict[str, Any]]:
        """取得某帳號最近的描述結果（瀏覽成果用）。"""
        db = await get_db_client()
        query = """
        SELECT d.media_id, d.post_url, d.media_type, d.model, d.response_json, d.status, d.created_at,
               mf.original_url, mf.rustfs_url
        FROM media_descriptions d
        JOIN media_files mf ON mf.id = d.media_id
        JOIN playwright_post_metrics pwm ON pwm.url = d.post_url
        WHERE replace(lower(pwm.username),'@','') = replace(lower($1),'@','')
          AND d.media_type = ANY($2)
        ORDER BY d.created_at DESC
        LIMIT $3
        """
        return await db.fetch_all(query, username, media_types, limit)

    async def get_pending_media_by_user(self, username: str, media_types: List[str], limit: int = 50) -> List[Dict[str, Any]]:
        """取得某帳號尚未描述的媒體（瀏覽內容用）。"""
        db = await get_db_client()
        query = """
        SELECT mf.id AS media_id, mf.post_url, mf.media_type, mf.original_url, mf.rustfs_url,
               mf.width, mf.height, mf.file_size
        FROM media_files mf
        JOIN playwright_post_metrics pwm ON pwm.url = mf.post_url
        WHERE replace(lower(pwm.username),'@','') = replace(lower($1),'@','')
          AND mf.download_status = 'completed'
          AND mf.media_type = ANY($2)
          AND NOT EXISTS (SELECT 1 FROM media_descriptions d WHERE d.media_id = mf.id)
        ORDER BY mf.id DESC
        LIMIT $3
        """
        return await db.fetch_all(query, username, media_types, limit)

    async def describe_single_post(self,
        post_url: str,
        media_types: List[str],
        only_primary: bool = True,
        primary_threshold: float = 0.7,
        overwrite: bool = True,
    ) -> Dict[str, Any]:
        """針對單篇貼文建立清單並執行描述。"""
        db = await get_db_client()

        def _normalize_threads_url(u: str) -> str:
            try:
                u = u.strip()
                # 域名 threads.com → threads.net
                u = u.replace("threads.com", "threads.net")
                # 去掉尾端多餘斜線
                if u.endswith('/'):
                    u = u[:-1]
            except Exception:
                pass
            return u

        norm_url = _normalize_threads_url(post_url)

        async def _fetch_by_exact(url: str):
            # 單篇立即描述：放寬為不強制已完成下載，允許直接用 original_url 描述
            return await db.fetch_all(
                """
                SELECT id AS media_id, post_url, original_url, media_type, rustfs_url,
                       width, height, file_size,
                       COALESCE((metadata->>'primary_score')::float, NULL) AS primary_score,
                       COALESCE((metadata->>'is_primary')::bool, NULL) AS is_primary
                FROM media_files
                WHERE post_url = $1 AND media_type = ANY($2)
                """,
                url, media_types
            )

        rows = await _fetch_by_exact(norm_url)

        # 若找不到，嘗試以 shortcode 模糊查找
        if not rows:
            try:
                from urllib.parse import urlparse
                p = urlparse(norm_url)
                parts = [seg for seg in p.path.split('/') if seg]
                shortcode = parts[-1] if parts else None
            except Exception:
                shortcode = None

            if shortcode:
                rows = await db.fetch_all(
                    """
                    SELECT id AS media_id, post_url, original_url, media_type, rustfs_url,
                           width, height, file_size,
                           COALESCE((metadata->>'primary_score')::float, NULL) AS primary_score,
                           COALESCE((metadata->>'is_primary')::bool, NULL) AS is_primary
                    FROM media_files
                    WHERE media_type = ANY($1)
                      AND (post_url ILIKE '%'||$2||'%' OR original_url ILIKE '%'||$2||'%')
                    ORDER BY id DESC
                    LIMIT 50
                    """,
                    media_types, shortcode
                )

        # 過濾未描述的：僅在非覆蓋模式時才排除已描述
        if rows and not overwrite:
            ids = [r["media_id"] for r in rows]
            placeholders = ",".join([str(int(i)) for i in ids])
            desc_rows = await db.fetch_all(
                f"SELECT media_id FROM media_descriptions WHERE media_id IN ({placeholders})"
            )
            described = {d["media_id"] for d in desc_rows}
            rows = [r for r in rows if r["media_id"] not in described]

        # 主貼圖篩選（僅影響圖片，影片不受限）
        if only_primary and rows:
            filtered = []
            for r in rows:
                if r.get("media_type") != 'image':
                    filtered.append(r)
                    continue
                score = r.get("primary_score")
                is_primary = r.get("is_primary")
                if is_primary is True or (score is not None and score >= primary_threshold):
                    filtered.append(r)
            rows = filtered

        return await self.run_describe(rows, overwrite=overwrite)

