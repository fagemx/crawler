"""
çµæ§‹æ¨¡æ¿ç”Ÿæˆå™¨
ç‚ºæ¯å€‹è­˜åˆ¥å‡ºçš„çµæ§‹æ¨¡å¼ç”Ÿæˆè©³ç´°çš„å‰µä½œæ¨¡æ¿
"""

import json
from typing import List, Dict, Any

from common.llm_manager import chat_completion
from common.llm_client import parse_llm_json_response


class StructureTemplater:
    """çµæ§‹æ¨¡æ¿ç”Ÿæˆå™¨"""
    
    def __init__(self):
        pass
    
    async def generate_structure_templates(self, posts_content: List[str], 
                                         pattern_analysis: Dict[str, Any],
                                         corpus_features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç‚ºæ¯å€‹çµæ§‹æ¨¡å¼ç”Ÿæˆå‰µä½œæ¨¡æ¿"""
        templates = []
        patterns = pattern_analysis.get("identified_patterns", [])
        
        for pattern in patterns:
            pattern_name = pattern.get("pattern_name", "æœªçŸ¥æ¨¡å¼")
            structure_chars = pattern.get("structure_characteristics", {})
            sample_indices = pattern.get("sample_indices", [])
            confidence = pattern.get("confidence", 0.5)
            post_indices_all = pattern.get("post_indices", [])
            
            try:
                template = await self._generate_adaptive_structure_template(
                    pattern_name, structure_chars, posts_content, 
                    sample_indices, corpus_features, confidence,
                    post_indices_all=post_indices_all
                )
                
                templates.append({
                    "pattern_id": pattern.get("pattern_id"),
                    "pattern_name": pattern_name,
                    "template_type": "adaptive",
                    "confidence": confidence,
                    "structure_template": template
                })
                
            except Exception as e:
                print(f"çµæ§‹æ¨¡æ¿ç”ŸæˆéŒ¯èª¤ - æ¨¡å¼ {pattern_name}: {e}")
                continue
        
        return templates
    
    async def _generate_adaptive_structure_template(self, pattern_name: str, 
                                                   structure_chars: Dict[str, Any],
                                                   posts_content: List[str], 
                                                   sample_indices: List[int],
                                                   corpus_features: Dict[str, Any],
                                                   confidence: float,
                                                   post_indices_all: List[int] = None) -> Dict[str, Any]:
        """ç”Ÿæˆè‡ªé©æ‡‰çµæ§‹æ¨¡æ¿"""
        
        # ç²å–æ¨£æœ¬è²¼æ–‡
        sample_posts = []
        for idx in sample_indices:
            if 0 <= idx - 1 < len(posts_content):
                sample_posts.append(posts_content[idx - 1])
        
        samples_text = "\n".join([f"æ¨£æœ¬{i+1}: {post}" for i, post in enumerate(sample_posts)])
        
        # æ ¹æ“šèªæ–™åº«ç‰¹å¾µæ±ºå®šé‡é»åˆ†æç¶­åº¦
        analysis_focus = self._determine_analysis_focus(structure_chars, corpus_features)
        
        prompt = f"""
æ ¹æ“šçµæ§‹æ¨¡å¼ã€Œ{pattern_name}ã€çš„ç‰¹å¾µï¼Œè«‹åˆ†ææ¨£æœ¬ä¸¦ç”Ÿæˆã€çµæ§‹-å‰µä½œæŒ‡å¼•ã€JSONã€‚
ä¿¡å¿ƒåº¦ï¼š{confidence:.1%}

ğŸ§© çµæ§‹çµ±è¨ˆç‰¹å¾µï¼š
{json.dumps(structure_chars, ensure_ascii=False)}

ğŸ“š æ¨£æœ¬è²¼æ–‡ï¼š
{samples_text}

ğŸ“– èªæ–™åº«èƒŒæ™¯ï¼š
{self._build_corpus_context(corpus_features)}

ğŸ¯ å»ºè­°é¦–è¦åˆ†æç¶­åº¦ï¼š{analysis_focus or "æ¨¡å‹è‡ªè¡Œåˆ¤æ–·"}

åƒ…è«‡ã€Œçµæ§‹ã€èˆ‡ã€Œè¡¨ç¾æ‰‹æ³•ã€ï¼Œåš´ç¦å¼•ç”¨å…·é«”ä¸»é¡Œæˆ–æƒ…ç¯€ã€‚

================ã€€JSONã€€================
{{
  "structure_guide": {{
    "length_profile": {{ 
      "ç¸½å¥æ•¸ç¯„åœ": "X-Yå¥", 
      "å¹³å‡æ¯å¥å­—æ•¸": "A-Bå­—",
      "ç¸½å­—æ•¸": "M-Nå­—"
    }},
    "organization": {{ 
      "æ®µè½æ•¸é‡": "N1-N2æ®µ", 
      "æ¯æ®µå¥æ•¸": "S1-S2å¥",
      "ç‰¹æ®Šçµ„ç¹”": "åˆ—é»/å°è©±/å¼•ç”¨â€¦(è‹¥æœ‰)"
    }},
    "rhythm": {{ 
      "ç¯€å¥": "å¿«/ä¸­/æ…¢ç­‰", 
      "æ¨™é»æ¨¡å¼": "é€—è™Ÿ/å†’è™Ÿ/ç ´æŠ˜è™Ÿ/çœç•¥è™Ÿâ€¦"
    }},
    "coherence": {{ 
      "é€£è²«ç­–ç•¥": ["æ™‚é–“é †åº","å› æœ","å°æ¯”","æ‰¿æ¥è©â€¦"]
    }},
    "macro_blueprint": {{
      "structure_chain_example": ["åŠŸèƒ½1â†’åŠŸèƒ½2â†’åŠŸèƒ½3"],
      "micro_arc": "è§¸ç™¼â†’åæ‡‰ / æƒ…ç·’â†’å…·é«”åŒ– (è‹¥é©ç”¨)",
      "tension": "å°æ¯”/åœé “/å¼·èª¿è© (è‹¥é©ç”¨)",
      "completeness": "å¼•ç”¨/é‹ªé™³/æ”¶æŸä¸‰è¦ç´  (è‹¥é©ç”¨)"
    }},
    "density": "è³‡è¨Šæˆ–æƒ…ç·’å¯†åº¦å»ºè­° (è‹¥é©ç”¨)",
    "special_features": "æœ¬æ¨¡å¼ç¨æœ‰çš„çµæ§‹ç‰¹å¾µ",
    "sentence_types": {{ 
      "é™³è¿°": "P-Q%", "ç–‘å•": "R-S%", "æ„Ÿå˜†": "T-U%"
    }}
  }},

  "paragraph_steps": [
    {{
      "åŠŸèƒ½": "æ­¤æ®µè½/å¥ç¾¤çš„è§’è‰²å®šä½",
      "æ¨™æº–å¯«æ³•": "å¸¸è¦‹æªè¾­æˆ–èªæ°£",
      "é€£è²«èª": ["ä¾‹å¦‚","æ­¤å¤–","æœ€å¾Œ"],
      "ç¤ºä¾‹ç‰‡æ®µ": "ã€å ä½ç¬¦ï¼šä¸å«ä»»ä½•ä¸»é¡Œè©ã€‘"
    }}
  ],

  "analysis_elements": {{
    "é•·å¥åŠŸèƒ½åˆ†é¡": ["æ•˜äº‹","è©•è«–","æ¨è«–"],
    "é•·å¥çµ„ç¹”æ¨¡å¼": ["ä¸»å¥+ç´°ç¯€+æƒ…ç·’", "å› æœ/è½‰æŠ˜"],
    "çŸ­å¥æ‡‰ç”¨å ´æ™¯": ["æ”¶å°¾å¼·èª¿","ç¯€å¥åˆ‡æ›"],
    "é€£è²«ç­–ç•¥è£œå……": ["æ¯3-5å¥ä½¿ç”¨æ‰¿æ¥è©", "æ®µé¦–è½‰æŠ˜"]
  }},

  "creation_guidance": {{
    "writing_steps": ["æ­¥é©Ÿ1","æ­¥é©Ÿ2","æ­¥é©Ÿ3"],
    "style_constraints": ["å­—æ•¸/èªæ°£/ç”¨è©é™åˆ¶"],
    "common_pitfalls": ["å¸¸éŒ¯1","å¸¸éŒ¯2"],
    "optimization_tips": ["æŠ€å·§1","æŠ€å·§2"]
  }},

  "applicability": {{
    "é©ç”¨å ´æ™¯": ["å¯ç”¨æ–¼â€¦"],
    "ä¸é©ç”¨": ["ä¸å»ºè­°æ–¼â€¦"],
    "confidence_level": {confidence:.2f}
  }},

  "notes": "ä¿¡å¿ƒåº¦ã€è³‡æ–™åå·®æˆ–å…¶ä»–è£œå……"
}}

âš ï¸ è¦å‰‡ï¼ˆåƒ… 4 æ¢ï¼Œæ¸›å°‘æŸç¸›ï¼‰
1. åªæœ‰ã€Œç¢ºå¯¦è§€å¯Ÿåˆ°ã€çš„æ¬„ä½æ‰è¼¸å‡ºï¼›ç„¡å‰‡çœç•¥ã€‚
2. æ•¸å€¼ä¸€å¾‹ç”¨ã€ç¯„åœã€è¡¨ç¤º (å¦‚ 8-15å­—)ã€‚
3. å…¨æ–‡ä¸å¾—å‡ºç¾å…·é«”ä¸»é¡Œè©/å°ˆæœ‰åè©ã€‚
4. è‹¥ä¿¡å¿ƒåº¦ < 0.65ï¼Œnotes ä¸­æ¨™ç¤ºã€çµæ§‹å¯é æ€§ä¸è¶³ã€ä¸¦ç°¡è¿°åŸå› ã€‚
"""

        messages = [
            {"role": "system", "content": "ä½ æ˜¯å°ˆæ¥­çš„çµæ§‹åˆ†æå¸«ï¼Œè«‹ä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºï¼Œåªé—œæ³¨ã€çµæ§‹èˆ‡è¡¨ç¾æ‰‹æ³•ã€ï¼Œåš´ç¦æ¶‰åŠä¸»é¡Œ/æƒ…ç¯€å…§å®¹ã€‚"},
            {"role": "user", "content": prompt}
        ]
        
        try:
            content = await chat_completion(
                messages=messages,
                model="gemini-2.0-flash",
                temperature=0.2,
                max_tokens=2000,
                provider="gemini"
            )
            parsed = parse_llm_json_response(content)
            # å°‡æ¨£æœ¬ä¸€ä½µå›å‚³ï¼Œä¾¿æ–¼å¾ŒçºŒæ‘˜è¦ä¸éœ€å†æŸ¥è³‡æ–™
            if isinstance(parsed, dict):
                parsed.setdefault("sample_indices", sample_indices)
                parsed_samples = []
                for idx in sample_indices:
                    if 0 <= idx - 1 < len(posts_content):
                        parsed_samples.append({
                            "index": idx,
                            "content": posts_content[idx - 1]
                        })
                parsed.setdefault("samples", parsed_samples)
                # åŒæ­¥å›å‚³æ­¤æ¨¡å¼è¦†è“‹çš„æ‰€æœ‰è²¼æ–‡æ¨£æœ¬ï¼Œä¾›æ‘˜è¦ä½¿ç”¨
                all_samples = []
                if post_indices_all:
                    for idx in post_indices_all:
                        if 0 <= idx - 1 < len(posts_content):
                            all_samples.append({
                                "index": idx,
                                "content": posts_content[idx - 1]
                            })
                parsed.setdefault("all_indices", post_indices_all or [])
                parsed.setdefault("all_samples", all_samples)
            return parsed
        except Exception as e:
            print(f"è‡ªé©æ‡‰çµæ§‹æ¨¡æ¿ç”ŸæˆéŒ¯èª¤: {e}")
            return {"error": f"ç„¡æ³•ç”Ÿæˆçµæ§‹æ¨¡æ¿: {str(e)}"}
    
    def _determine_analysis_focus(self, structure_chars: Dict[str, Any], 
                                corpus_features: Dict[str, Any]) -> str:
        """æ ¹æ“šçµæ§‹ç‰¹å¾µå’Œèªæ–™åº«ç‰¹å¾µæ±ºå®šåˆ†æé‡é»"""
        focus_areas = []
        
        # æ ¹æ“šä¸»å°ç‰¹å¾µæ±ºå®šé‡é»
        dominant_feature = structure_chars.get("dominant_feature", "")
        
        if "å°è©±" in dominant_feature:
            focus_areas.append("å°è©±ç¯€å¥èˆ‡åœé “")
        if "åˆ—é»" in dominant_feature:
            focus_areas.append("åˆ—é»çµ„ç¹”èˆ‡é‚è¼¯")
        if "å¼•ç”¨" in dominant_feature:
            focus_areas.append("å¼•ç”¨æ•´åˆèˆ‡å±¤æ¬¡")
        if "å¤šæ®µ" in dominant_feature:
            focus_areas.append("æ®µè½éŠœæ¥èˆ‡å¼§ç·š")
        if "å–®æ®µ" in dominant_feature:
            focus_areas.append("é€£è²«æ€§èˆ‡å¯†åº¦")
        
        # æ ¹æ“šèªæ–™åº«æ•´é«”ç‰¹å¾µèª¿æ•´
        avg_length = corpus_features.get("avg_length", 0)
        if avg_length <= 50:
            focus_areas.append("å¾®å¼§ç·šèˆ‡å¼µåŠ›")
        elif avg_length >= 200:
            focus_areas.append("æ•˜äº‹å¼§ç·šèˆ‡æ·±åº¦")
        
        return "ã€".join(focus_areas) if focus_areas else "åŸºæœ¬çµæ§‹ç‰¹å¾µ"
    
    def _build_corpus_context(self, corpus_features: Dict[str, Any]) -> str:
        """æ§‹å»ºèªæ–™åº«èƒŒæ™¯æè¿°"""
        context_parts = []
        
        total_posts = corpus_features.get("total_posts", 0)
        avg_length = corpus_features.get("avg_length", 0)
        
        context_parts.append(f"èªæ–™åº«è¦æ¨¡ï¼š{total_posts}ç¯‡ï¼Œå¹³å‡é•·åº¦{avg_length:.0f}å­—")
        
        # ä¸»è¦ç‰¹å¾µ
        main_features = []
        if corpus_features.get("has_dialogue"):
            main_features.append("å«å°è©±")
        if corpus_features.get("has_bullet_points"):
            main_features.append("å«åˆ—é»")
        if corpus_features.get("has_multi_paragraph"):
            main_features.append("å¤šæ®µç‚ºä¸»")
        else:
            main_features.append("å–®æ®µç‚ºä¸»")
        
        if main_features:
            context_parts.append(f"ä¸»è¦ç‰¹å¾µï¼š{', '.join(main_features)}")
        
        return "ï¼›".join(context_parts)
