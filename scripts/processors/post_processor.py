#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è²¼æ–‡è™•ç†å™¨
è™•ç†APIè«‹æ±‚å’Œè²¼æ–‡è§£æ
"""

import requests
import concurrent.futures
from typing import Dict, Optional, Tuple
from datetime import datetime

from ..extractors import ContentExtractor, MetricsExtractor
from ..utils.helpers import safe_print

class PostProcessor:
    """è²¼æ–‡è™•ç†å™¨"""
    
    def __init__(self, target_username: str = None):
        self.target_username = target_username
        
        # APIè¨­å®š
        self.official_reader_url = "https://r.jina.ai"
        self.official_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'X-Return-Format': 'markdown'
        }
        
        # æœ¬åœ°Readeré…ç½®
        self.local_reader_url = "http://localhost:8880"
        self.local_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
            'x-wait-for-selector': 'article',
            'x-timeout': '25'
        }
        
        # æå–å™¨
        self.content_extractor = ContentExtractor(target_username)
        self.metrics_extractor = MetricsExtractor()
    
    def fetch_content_jina_api(self, url: str) -> Tuple[bool, str]:
        """å¾Jina APIç²å–å…§å®¹"""
        try:
            response = requests.get(f"{self.official_reader_url}/{url}", headers=self.official_headers, timeout=60)
            if response.status_code == 200:
                return True, response.text
            else:
                return False, f"HTTP {response.status_code}"
        except Exception as e:
            return False, str(e)
    
    def fetch_content_local(self, url: str, use_cache: bool = True, max_retries: int = 2) -> Tuple[bool, str]:
        """ä½¿ç”¨æœ¬åœ°Readerç²å–å…§å®¹ - å¿«é€Ÿé‡è©¦æ©Ÿåˆ¶"""
        headers = self.local_headers.copy()
        if not use_cache: 
            headers['x-no-cache'] = 'true'
        
        for attempt in range(max_retries + 1):
            try:
                # é™ä½timeoutï¼Œå¿«é€Ÿå¤±æ•—
                timeout = 15 if attempt == 0 else 10  # ç¬¬ä¸€æ¬¡15sï¼Œé‡è©¦10s
                response = requests.get(f"{self.local_reader_url}/{url}", headers=headers, timeout=timeout)
                if response.status_code == 200:
                    return True, response.text
                else:
                    if attempt < max_retries:
                        continue  # é‡è©¦
                    return False, f"HTTP {response.status_code}"
            except Exception as e:
                if attempt < max_retries:
                    # çŸ­æš«ç­‰å¾…å¾Œé‡è©¦
                    import time
                    time.sleep(0.5)
                    continue
                return False, f"æœ€çµ‚å¤±æ•—: {str(e)}"
        
        return False, "é‡è©¦è€—ç›¡"
    
    def fetch_content_local_fast(self, url: str) -> Tuple[bool, str]:
        """å¿«é€Ÿæœ¬åœ°Reader - å°ˆé–€ç‚ºå›é€€è¨­è¨ˆ"""
        def try_single_request(instance_id):
            """å˜—è©¦å–®å€‹Readerå¯¦ä¾‹"""
            headers = self.local_headers.copy()
            headers['x-no-cache'] = 'true'  # å¼·åˆ¶ç„¡å¿«å–
            try:
                # è¶…çŸ­timeoutï¼Œå¿«é€Ÿå¤±æ•—
                response = requests.get(f"{self.local_reader_url}/{url}", headers=headers, timeout=8)
                return (True, response.text, instance_id) if response.status_code == 200 else (False, f"HTTP {response.status_code}", instance_id)
            except Exception as e:
                return (False, str(e), instance_id)
        
        # å¹³è¡Œå˜—è©¦å¤šå€‹å¯¦ä¾‹ï¼ˆæ¨¡æ“¬è² è¼‰å‡è¡¡ï¼‰
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # æäº¤2å€‹å¹³è¡Œè«‹æ±‚ï¼ˆæ¨¡æ“¬é‡è©¦ï¼‰
            futures = [executor.submit(try_single_request, i) for i in range(2)]
            
            # ç­‰å¾…ç¬¬ä¸€å€‹æˆåŠŸçš„çµæœ
            for future in concurrent.futures.as_completed(futures, timeout=12):
                try:
                    success, content, instance_id = future.result()
                    if success:
                        # å–æ¶ˆå…¶ä»–æ­£åœ¨é€²è¡Œçš„è«‹æ±‚
                        for f in futures:
                            f.cancel()
                        return True, content
                except Exception as e:
                    continue
        
        return False, "æ‰€æœ‰å¿«é€Ÿè«‹æ±‚éƒ½å¤±æ•—äº†"
    
    def parse_post(self, url: str, content: str) -> Dict:
        """è§£æè²¼æ–‡å…§å®¹"""
        try:
            post_id = url.split('/')[-1] if '/' in url else url
            
            # æå–å„ç¨®æŒ‡æ¨™
            views = self.metrics_extractor.extract_views_count(content, post_id)
            main_content = self.content_extractor.extract_post_content(content)
            likes = self.metrics_extractor.extract_likes_count(content)
            comments = self.metrics_extractor.extract_comments_count(content)
            reposts = self.metrics_extractor.extract_reposts_count(content)
            shares = self.metrics_extractor.extract_shares_count(content)
            
            # æ§‹å»ºçµæœ
            result = {
                'post_id': post_id,
                'url': url,
                'views': views,
                'content': main_content,
                'source': 'unknown',  # æœƒåœ¨èª¿ç”¨æ–¹è¨­ç½®
                'likes': likes,
                'comments': comments,
                'reposts': reposts,
                'shares': shares,
                'success': bool(views or main_content),
                'has_views': bool(views),
                'has_content': bool(main_content),
                'has_likes': bool(likes),
                'has_comments': bool(comments),
                'has_reposts': bool(reposts),
                'has_shares': bool(shares),
                'content_length': len(content),
                'extracted_at': datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            safe_print(f"âŒ è§£æè²¼æ–‡å¤±æ•— {url}: {e}")
            return {
                'post_id': url.split('/')[-1] if '/' in url else url,
                'url': url,
                'views': None,
                'content': None,
                'source': 'parse_error',
                'likes': None,
                'comments': None,
                'reposts': None,
                'shares': None,
                'success': False,
                'has_views': False,
                'has_content': False,
                'has_likes': False,
                'has_comments': False,
                'has_reposts': False,
                'has_shares': False,
                'content_length': 0,
                'extracted_at': datetime.now().isoformat(),
                'error': str(e)
            }
    
    async def process_url_realtime(self, url: str, index: int, total: int) -> Optional[Dict]:
        """å¯¦æ™‚è™•ç†å–®å€‹URL"""
        post_id = url.split('/')[-1] if '/' in url else url
        safe_print(f"ğŸ”„ [{index+1}/{total}] è™•ç†: {post_id}")
        
        # å…ˆå˜—è©¦Jina APIï¼ˆå®˜æ–¹ï¼Œé€šå¸¸æ›´ç©©å®šï¼‰
        try:
            safe_print(f"   ğŸ“¡ [{index+1}] å˜—è©¦ Jina API...")
            success, content = self.fetch_content_jina_api(url)
            
            if success:
                safe_print(f"   âœ… [{index+1}] Jina API æˆåŠŸ ({len(content)} å­—ç¬¦)")
                result = self.parse_post(url, content)
                result['source'] = 'jina_api'
                return result
            else:
                safe_print(f"   âŒ [{index+1}] Jina API å¤±æ•—: {content}")
        
        except Exception as e:
            safe_print(f"   âŒ [{index+1}] Jina API ç•°å¸¸: {e}")
        
        # APIå¤±æ•—ï¼Œå˜—è©¦æœ¬åœ°Reader
        try:
            safe_print(f"   ğŸ”„ [{index+1}] å›é€€åˆ°æœ¬åœ°Reader...")
            success, content = self.fetch_content_local_fast(url)
            
            if success:
                safe_print(f"   âœ… [{index+1}] æœ¬åœ°Reader æˆåŠŸ ({len(content)} å­—ç¬¦)")
                result = self.parse_post(url, content)
                result['source'] = 'local_reader'
                return result
            else:
                safe_print(f"   âŒ [{index+1}] æœ¬åœ°Reader å¤±æ•—: {content}")
        
        except Exception as e:
            safe_print(f"   âŒ [{index+1}] æœ¬åœ°Reader ç•°å¸¸: {e}")
        
        # éƒ½å¤±æ•—äº†
        safe_print(f"   ğŸ’€ [{index+1}] æ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—äº†")
        result = self.parse_post(url, "")
        result['source'] = 'all_failed'
        return result